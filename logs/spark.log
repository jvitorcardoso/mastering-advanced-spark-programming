2025-12-21T23:26:27,016 [main] INFO  org.apache.spark.deploy.master.Master [] - Started daemon with process name: 43@1bde61be40a8
2025-12-21T23:26:27,028 [main] INFO  org.apache.spark.util.SignalUtils [] - Registering signal handler for TERM
2025-12-21T23:26:27,029 [main] INFO  org.apache.spark.util.SignalUtils [] - Registering signal handler for HUP
2025-12-21T23:26:27,030 [main] INFO  org.apache.spark.util.SignalUtils [] - Registering signal handler for INT
2025-12-21T23:26:27,067 [main] INFO  org.apache.spark.deploy.worker.Worker [] - Started daemon with process name: 41@1b3c1c32cfa1
2025-12-21T23:26:27,078 [main] INFO  org.apache.spark.util.SignalUtils [] - Registering signal handler for TERM
2025-12-21T23:26:27,080 [main] INFO  org.apache.spark.util.SignalUtils [] - Registering signal handler for HUP
2025-12-21T23:26:27,081 [main] INFO  org.apache.spark.util.SignalUtils [] - Registering signal handler for INT
2025-12-21T23:26:27,090 [main] INFO  org.apache.spark.deploy.worker.Worker [] - Started daemon with process name: 41@3f9623515a95
2025-12-21T23:26:27,102 [main] INFO  org.apache.spark.util.SignalUtils [] - Registering signal handler for TERM
2025-12-21T23:26:27,104 [main] INFO  org.apache.spark.util.SignalUtils [] - Registering signal handler for HUP
2025-12-21T23:26:27,104 [main] INFO  org.apache.spark.util.SignalUtils [] - Registering signal handler for INT
2025-12-21T23:26:27,109 [main] INFO  org.apache.spark.deploy.worker.Worker [] - Started daemon with process name: 41@6cc12a12e10d
2025-12-21T23:26:27,122 [main] INFO  org.apache.spark.util.SignalUtils [] - Registering signal handler for TERM
2025-12-21T23:26:27,123 [main] INFO  org.apache.spark.util.SignalUtils [] - Registering signal handler for HUP
2025-12-21T23:26:27,124 [main] INFO  org.apache.spark.util.SignalUtils [] - Registering signal handler for INT
2025-12-21T23:26:27,298 [main] INFO  org.apache.spark.SecurityManager [] - Changing view acls to: spark
2025-12-21T23:26:27,300 [main] INFO  org.apache.spark.SecurityManager [] - Changing modify acls to: spark
2025-12-21T23:26:27,301 [main] INFO  org.apache.spark.SecurityManager [] - Changing view acls groups to: 
2025-12-21T23:26:27,303 [main] INFO  org.apache.spark.SecurityManager [] - Changing modify acls groups to: 
2025-12-21T23:26:27,304 [main] INFO  org.apache.spark.SecurityManager [] - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
2025-12-21T23:26:27,349 [main] INFO  org.apache.spark.SecurityManager [] - Changing view acls to: spark
2025-12-21T23:26:27,350 [main] INFO  org.apache.spark.SecurityManager [] - Changing modify acls to: spark
2025-12-21T23:26:27,351 [main] INFO  org.apache.spark.SecurityManager [] - Changing view acls groups to: 
2025-12-21T23:26:27,354 [main] INFO  org.apache.spark.SecurityManager [] - Changing modify acls groups to: 
2025-12-21T23:26:27,355 [main] INFO  org.apache.spark.SecurityManager [] - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
2025-12-21T23:26:27,369 [main] INFO  org.apache.spark.SecurityManager [] - Changing view acls to: spark
2025-12-21T23:26:27,370 [main] INFO  org.apache.spark.SecurityManager [] - Changing modify acls to: spark
2025-12-21T23:26:27,372 [main] INFO  org.apache.spark.SecurityManager [] - Changing view acls groups to: 
2025-12-21T23:26:27,373 [main] INFO  org.apache.spark.SecurityManager [] - Changing modify acls groups to: 
2025-12-21T23:26:27,374 [main] INFO  org.apache.spark.SecurityManager [] - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
2025-12-21T23:26:27,456 [main] INFO  org.apache.spark.SecurityManager [] - Changing view acls to: spark
2025-12-21T23:26:27,457 [main] INFO  org.apache.spark.SecurityManager [] - Changing modify acls to: spark
2025-12-21T23:26:27,459 [main] INFO  org.apache.spark.SecurityManager [] - Changing view acls groups to: 
2025-12-21T23:26:27,462 [main] INFO  org.apache.spark.SecurityManager [] - Changing modify acls groups to: 
2025-12-21T23:26:27,463 [main] INFO  org.apache.spark.SecurityManager [] - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
2025-12-21T23:26:27,524 [main] WARN  org.apache.hadoop.util.NativeCodeLoader [] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2025-12-21T23:26:27,664 [main] WARN  org.apache.hadoop.util.NativeCodeLoader [] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2025-12-21T23:26:27,665 [main] WARN  org.apache.hadoop.util.NativeCodeLoader [] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2025-12-21T23:26:27,812 [main] WARN  org.apache.hadoop.util.NativeCodeLoader [] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2025-12-21T23:26:28,195 [main] INFO  org.apache.spark.util.Utils [] - Successfully started service 'sparkMaster' on port 7077.
2025-12-21T23:26:28,222 [dispatcher-event-loop-1] INFO  org.apache.spark.deploy.master.Master [] - Starting Spark master at spark://1bde61be40a8:7077
2025-12-21T23:26:28,230 [dispatcher-event-loop-1] INFO  org.apache.spark.deploy.master.Master [] - Running Spark version 3.5.0
2025-12-21T23:26:28,261 [main] INFO  org.apache.spark.util.Utils [] - Successfully started service 'sparkWorker' on port 38813.
2025-12-21T23:26:28,264 [main] INFO  org.apache.spark.deploy.worker.Worker [] - Worker decommissioning not enabled.
2025-12-21T23:26:28,278 [main] INFO  org.apache.spark.util.Utils [] - Successfully started service 'sparkWorker' on port 42003.
2025-12-21T23:26:28,281 [main] INFO  org.apache.spark.deploy.worker.Worker [] - Worker decommissioning not enabled.
2025-12-21T23:26:28,283 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.util.log [] - Logging initialized @2961ms to org.sparkproject.jetty.util.log.Slf4jLog
2025-12-21T23:26:28,335 [main] INFO  org.apache.spark.util.Utils [] - Successfully started service 'sparkWorker' on port 40341.
2025-12-21T23:26:28,340 [dispatcher-event-loop-1] INFO  org.apache.spark.ui.JettyUtils [] - Start Jetty 0.0.0.0:8080 for MasterUI
2025-12-21T23:26:28,341 [main] INFO  org.apache.spark.deploy.worker.Worker [] - Worker decommissioning not enabled.
2025-12-21T23:26:28,357 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.Server [] - jetty-9.4.52.v20230823; built: 2023-08-23T19:29:37.669Z; git: abdcda73818a1a2c705da276edb0bf6581e7997e; jvm 17.0.10+13-LTS
2025-12-21T23:26:28,384 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.Server [] - Started @3062ms
2025-12-21T23:26:28,463 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.AbstractConnector [] - Started ServerConnector@3d417ba4{HTTP/1.1, (http/1.1)}{0.0.0.0:8080}
2025-12-21T23:26:28,464 [dispatcher-event-loop-1] INFO  org.apache.spark.util.Utils [] - Successfully started service 'MasterUI' on port 8080.
2025-12-21T23:26:28,522 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@433d02c6{/app,null,AVAILABLE,@Spark}
2025-12-21T23:26:28,531 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@50d28d8f{/app/json,null,AVAILABLE,@Spark}
2025-12-21T23:26:28,534 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@39379c8c{/,null,AVAILABLE,@Spark}
2025-12-21T23:26:28,538 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@30667d91{/json,null,AVAILABLE,@Spark}
2025-12-21T23:26:28,549 [dispatcher-event-loop-1] INFO  org.apache.spark.deploy.worker.Worker [] - Starting Spark worker 172.21.0.4:38813 with 2 cores, 3.0 GiB RAM
2025-12-21T23:26:28,556 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@262898ba{/static,null,AVAILABLE,@Spark}
2025-12-21T23:26:28,561 [dispatcher-event-loop-1] INFO  org.apache.spark.deploy.worker.Worker [] - Running Spark version 3.5.0
2025-12-21T23:26:28,559 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@162f23d9{/app/kill,null,AVAILABLE,@Spark}
2025-12-21T23:26:28,563 [dispatcher-event-loop-1] INFO  org.apache.spark.deploy.worker.Worker [] - Spark home: /opt/bitnami/spark
2025-12-21T23:26:28,566 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@345d8f34{/driver/kill,null,AVAILABLE,@Spark}
2025-12-21T23:26:28,570 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@ce85768{/workers/kill,null,AVAILABLE,@Spark}
2025-12-21T23:26:28,575 [dispatcher-event-loop-1] INFO  org.apache.spark.deploy.master.ui.MasterWebUI [] - Bound MasterWebUI to 0.0.0.0, and started at http://1bde61be40a8:8080
2025-12-21T23:26:28,599 [dispatcher-event-loop-1] INFO  org.apache.spark.deploy.worker.Worker [] - Starting Spark worker 172.21.0.5:42003 with 2 cores, 3.0 GiB RAM
2025-12-21T23:26:28,605 [dispatcher-event-loop-1] INFO  org.apache.spark.resource.ResourceUtils [] - ==============================================================
2025-12-21T23:26:28,606 [dispatcher-event-loop-1] INFO  org.apache.spark.resource.ResourceUtils [] - No custom resources configured for spark.worker.
2025-12-21T23:26:28,608 [dispatcher-event-loop-1] INFO  org.apache.spark.resource.ResourceUtils [] - ==============================================================
2025-12-21T23:26:28,608 [dispatcher-event-loop-1] INFO  org.apache.spark.deploy.worker.Worker [] - Running Spark version 3.5.0
2025-12-21T23:26:28,609 [dispatcher-event-loop-1] INFO  org.apache.spark.deploy.worker.Worker [] - Spark home: /opt/bitnami/spark
2025-12-21T23:26:28,639 [dispatcher-event-loop-1] INFO  org.apache.spark.resource.ResourceUtils [] - ==============================================================
2025-12-21T23:26:28,639 [dispatcher-event-loop-1] INFO  org.apache.spark.resource.ResourceUtils [] - No custom resources configured for spark.worker.
2025-12-21T23:26:28,640 [dispatcher-event-loop-1] INFO  org.apache.spark.resource.ResourceUtils [] - ==============================================================
2025-12-21T23:26:28,669 [dispatcher-event-loop-1] INFO  org.apache.spark.deploy.worker.Worker [] - Starting Spark worker 172.21.0.6:40341 with 2 cores, 3.0 GiB RAM
2025-12-21T23:26:28,679 [dispatcher-event-loop-1] INFO  org.apache.spark.deploy.worker.Worker [] - Running Spark version 3.5.0
2025-12-21T23:26:28,680 [dispatcher-event-loop-1] INFO  org.apache.spark.deploy.worker.Worker [] - Spark home: /opt/bitnami/spark
2025-12-21T23:26:28,701 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.util.log [] - Logging initialized @3387ms to org.sparkproject.jetty.util.log.Slf4jLog
2025-12-21T23:26:28,710 [dispatcher-event-loop-1] INFO  org.apache.spark.resource.ResourceUtils [] - ==============================================================
2025-12-21T23:26:28,711 [dispatcher-event-loop-1] INFO  org.apache.spark.resource.ResourceUtils [] - No custom resources configured for spark.worker.
2025-12-21T23:26:28,712 [dispatcher-event-loop-1] INFO  org.apache.spark.resource.ResourceUtils [] - ==============================================================
2025-12-21T23:26:28,714 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.util.log [] - Logging initialized @3424ms to org.sparkproject.jetty.util.log.Slf4jLog
2025-12-21T23:26:28,784 [dispatcher-event-loop-1] INFO  org.apache.spark.ui.JettyUtils [] - Start Jetty 0.0.0.0:8081 for WorkerUI
2025-12-21T23:26:28,794 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.util.log [] - Logging initialized @3356ms to org.sparkproject.jetty.util.log.Slf4jLog
2025-12-21T23:26:28,805 [dispatcher-event-loop-1] INFO  org.apache.spark.ui.JettyUtils [] - Start Jetty 0.0.0.0:8081 for WorkerUI
2025-12-21T23:26:28,814 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.Server [] - jetty-9.4.52.v20230823; built: 2023-08-23T19:29:37.669Z; git: abdcda73818a1a2c705da276edb0bf6581e7997e; jvm 17.0.10+13-LTS
2025-12-21T23:26:28,831 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.Server [] - jetty-9.4.52.v20230823; built: 2023-08-23T19:29:37.669Z; git: abdcda73818a1a2c705da276edb0bf6581e7997e; jvm 17.0.10+13-LTS
2025-12-21T23:26:28,844 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@1c9eb27c{/metrics/master/json,null,AVAILABLE,@Spark}
2025-12-21T23:26:28,849 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@76d62e4b{/metrics/applications/json,null,AVAILABLE,@Spark}
2025-12-21T23:26:28,853 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.Server [] - Started @3565ms
2025-12-21T23:26:28,865 [dispatcher-event-loop-1] INFO  org.apache.spark.ui.JettyUtils [] - Start Jetty 0.0.0.0:8081 for WorkerUI
2025-12-21T23:26:28,879 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.Server [] - Started @3567ms
2025-12-21T23:26:28,881 [dispatcher-event-loop-1] INFO  org.apache.spark.deploy.master.Master [] - I have been elected leader! New state: ALIVE
2025-12-21T23:26:28,894 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.Server [] - jetty-9.4.52.v20230823; built: 2023-08-23T19:29:37.669Z; git: abdcda73818a1a2c705da276edb0bf6581e7997e; jvm 17.0.10+13-LTS
2025-12-21T23:26:28,919 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.AbstractConnector [] - Started ServerConnector@2a3c68b8{HTTP/1.1, (http/1.1)}{0.0.0.0:8081}
2025-12-21T23:26:28,919 [dispatcher-event-loop-1] INFO  org.apache.spark.util.Utils [] - Successfully started service 'WorkerUI' on port 8081.
2025-12-21T23:26:28,923 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.Server [] - Started @3486ms
2025-12-21T23:26:28,939 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.AbstractConnector [] - Started ServerConnector@2a3c68b8{HTTP/1.1, (http/1.1)}{0.0.0.0:8081}
2025-12-21T23:26:28,939 [dispatcher-event-loop-1] INFO  org.apache.spark.util.Utils [] - Successfully started service 'WorkerUI' on port 8081.
2025-12-21T23:26:28,961 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@2d210f40{/logPage,null,AVAILABLE,@Spark}
2025-12-21T23:26:28,965 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@14239357{/logPage/json,null,AVAILABLE,@Spark}
2025-12-21T23:26:28,966 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@e10bc8f{/,null,AVAILABLE,@Spark}
2025-12-21T23:26:28,971 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@5f984594{/json,null,AVAILABLE,@Spark}
2025-12-21T23:26:28,979 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.AbstractConnector [] - Started ServerConnector@767ccd34{HTTP/1.1, (http/1.1)}{0.0.0.0:8081}
2025-12-21T23:26:28,979 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@2d210f40{/logPage,null,AVAILABLE,@Spark}
2025-12-21T23:26:28,980 [dispatcher-event-loop-1] INFO  org.apache.spark.util.Utils [] - Successfully started service 'WorkerUI' on port 8081.
2025-12-21T23:26:28,984 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@14239357{/logPage/json,null,AVAILABLE,@Spark}
2025-12-21T23:26:28,986 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@5b8b856d{/static,null,AVAILABLE,@Spark}
2025-12-21T23:26:28,986 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@e10bc8f{/,null,AVAILABLE,@Spark}
2025-12-21T23:26:28,988 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@39b6b4d3{/log,null,AVAILABLE,@Spark}
2025-12-21T23:26:28,989 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@5f984594{/json,null,AVAILABLE,@Spark}
2025-12-21T23:26:28,993 [dispatcher-event-loop-1] INFO  org.apache.spark.deploy.worker.ui.WorkerWebUI [] - Bound WorkerWebUI to 0.0.0.0, and started at http://3f9623515a95:8081
2025-12-21T23:26:28,997 [worker-register-master-threadpool-0] INFO  org.apache.spark.deploy.worker.Worker [] - Connecting to master spark-master:7077...
2025-12-21T23:26:29,001 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@5b8b856d{/static,null,AVAILABLE,@Spark}
2025-12-21T23:26:29,003 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@39b6b4d3{/log,null,AVAILABLE,@Spark}
2025-12-21T23:26:29,007 [dispatcher-event-loop-1] INFO  org.apache.spark.deploy.worker.ui.WorkerWebUI [] - Bound WorkerWebUI to 0.0.0.0, and started at http://1b3c1c32cfa1:8081
2025-12-21T23:26:29,011 [worker-register-master-threadpool-0] INFO  org.apache.spark.deploy.worker.Worker [] - Connecting to master spark-master:7077...
2025-12-21T23:26:29,021 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@50872cf1{/metrics/json,null,AVAILABLE,@Spark}
2025-12-21T23:26:29,022 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@10cee36d{/logPage,null,AVAILABLE,@Spark}
2025-12-21T23:26:29,029 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@17d42af8{/logPage/json,null,AVAILABLE,@Spark}
2025-12-21T23:26:29,031 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@3cfd4d40{/,null,AVAILABLE,@Spark}
2025-12-21T23:26:29,036 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@51444d00{/json,null,AVAILABLE,@Spark}
2025-12-21T23:26:29,040 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@50872cf1{/metrics/json,null,AVAILABLE,@Spark}
2025-12-21T23:26:29,053 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@4c898067{/static,null,AVAILABLE,@Spark}
2025-12-21T23:26:29,056 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@21cdc685{/log,null,AVAILABLE,@Spark}
2025-12-21T23:26:29,059 [dispatcher-event-loop-1] INFO  org.apache.spark.deploy.worker.ui.WorkerWebUI [] - Bound WorkerWebUI to 0.0.0.0, and started at http://6cc12a12e10d:8081
2025-12-21T23:26:29,064 [worker-register-master-threadpool-0] INFO  org.apache.spark.deploy.worker.Worker [] - Connecting to master spark-master:7077...
2025-12-21T23:26:29,087 [netty-rpc-connection-0] INFO  org.apache.spark.network.client.TransportClientFactory [] - Successfully created connection to spark-master/172.21.0.3:7077 after 49 ms (0 ms spent in bootstraps)
2025-12-21T23:26:29,098 [netty-rpc-connection-0] INFO  org.apache.spark.network.client.TransportClientFactory [] - Successfully created connection to spark-master/172.21.0.3:7077 after 56 ms (0 ms spent in bootstraps)
2025-12-21T23:26:29,109 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@3417fc37{/metrics/json,null,AVAILABLE,@Spark}
2025-12-21T23:26:29,167 [netty-rpc-connection-0] INFO  org.apache.spark.network.client.TransportClientFactory [] - Successfully created connection to spark-master/172.21.0.3:7077 after 57 ms (0 ms spent in bootstraps)
2025-12-21T23:26:29,280 [dispatcher-event-loop-5] INFO  org.apache.spark.deploy.master.Master [] - Registering worker 172.21.0.6:40341 with 2 cores, 3.0 GiB RAM
2025-12-21T23:26:29,297 [dispatcher-event-loop-5] INFO  org.apache.spark.deploy.master.Master [] - Registering worker 172.21.0.5:42003 with 2 cores, 3.0 GiB RAM
2025-12-21T23:26:29,300 [dispatcher-event-loop-5] INFO  org.apache.spark.deploy.master.Master [] - Registering worker 172.21.0.4:38813 with 2 cores, 3.0 GiB RAM
2025-12-21T23:26:29,303 [dispatcher-event-loop-6] INFO  org.apache.spark.deploy.worker.Worker [] - Successfully registered with master spark://1bde61be40a8:7077
2025-12-21T23:26:29,312 [dispatcher-event-loop-6] INFO  org.apache.spark.deploy.worker.Worker [] - Successfully registered with master spark://1bde61be40a8:7077
2025-12-21T23:26:29,315 [dispatcher-event-loop-7] INFO  org.apache.spark.deploy.worker.Worker [] - Successfully registered with master spark://1bde61be40a8:7077
2025-12-21T23:30:53,750 [dispatcher-event-loop-0] INFO  org.apache.spark.deploy.master.Master [] - 172.21.0.4:39864 got disassociated, removing it.
2025-12-21T23:30:53,752 [dispatcher-event-loop-0] INFO  org.apache.spark.deploy.master.Master [] - 172.21.0.5:52668 got disassociated, removing it.
2025-12-21T23:30:53,752 [dispatcher-event-loop-0] INFO  org.apache.spark.deploy.master.Master [] - 172.21.0.4:38813 got disassociated, removing it.
2025-12-21T23:30:53,753 [dispatcher-event-loop-0] INFO  org.apache.spark.deploy.master.Master [] - Removing worker worker-20251221232628-172.21.0.4-38813 on 172.21.0.4:38813
2025-12-21T23:30:53,755 [dispatcher-event-loop-0] INFO  org.apache.spark.deploy.master.Master [] - Telling app of lost worker: worker-20251221232628-172.21.0.4-38813
2025-12-21T23:30:53,758 [dispatcher-event-loop-0] INFO  org.apache.spark.deploy.master.Master [] - 172.21.0.6:42840 got disassociated, removing it.
2025-12-21T23:30:53,758 [dispatcher-event-loop-0] INFO  org.apache.spark.deploy.master.Master [] - 172.21.0.5:42003 got disassociated, removing it.
2025-12-21T23:30:53,759 [dispatcher-event-loop-0] INFO  org.apache.spark.deploy.master.Master [] - Removing worker worker-20251221232628-172.21.0.5-42003 on 172.21.0.5:42003
2025-12-21T23:30:53,759 [dispatcher-event-loop-0] INFO  org.apache.spark.deploy.master.Master [] - Telling app of lost worker: worker-20251221232628-172.21.0.5-42003
2025-12-21T23:30:53,759 [dispatcher-event-loop-0] INFO  org.apache.spark.deploy.master.Master [] - 172.21.0.6:40341 got disassociated, removing it.
2025-12-21T23:30:53,759 [dispatcher-event-loop-0] INFO  org.apache.spark.deploy.master.Master [] - Removing worker worker-20251221232628-172.21.0.6-40341 on 172.21.0.6:40341
2025-12-21T23:30:53,759 [dispatcher-event-loop-0] INFO  org.apache.spark.deploy.master.Master [] - Telling app of lost worker: worker-20251221232628-172.21.0.6-40341
2025-12-21T23:31:20,606 [main] INFO  org.apache.spark.deploy.master.Master [] - Started daemon with process name: 62@cc585e771d35
2025-12-21T23:31:20,624 [main] INFO  org.apache.spark.util.SignalUtils [] - Registering signal handler for TERM
2025-12-21T23:31:20,626 [main] INFO  org.apache.spark.util.SignalUtils [] - Registering signal handler for HUP
2025-12-21T23:31:20,627 [main] INFO  org.apache.spark.util.SignalUtils [] - Registering signal handler for INT
2025-12-21T23:31:20,741 [main] INFO  org.apache.spark.deploy.worker.Worker [] - Started daemon with process name: 60@84d6459cd6e4
2025-12-21T23:31:20,753 [main] INFO  org.apache.spark.util.SignalUtils [] - Registering signal handler for TERM
2025-12-21T23:31:20,754 [main] INFO  org.apache.spark.util.SignalUtils [] - Registering signal handler for HUP
2025-12-21T23:31:20,755 [main] INFO  org.apache.spark.util.SignalUtils [] - Registering signal handler for INT
2025-12-21T23:31:20,927 [main] INFO  org.apache.spark.deploy.worker.Worker [] - Started daemon with process name: 60@42f275a4bb58
2025-12-21T23:31:20,944 [main] INFO  org.apache.spark.util.SignalUtils [] - Registering signal handler for TERM
2025-12-21T23:31:20,945 [main] INFO  org.apache.spark.util.SignalUtils [] - Registering signal handler for HUP
2025-12-21T23:31:20,945 [main] INFO  org.apache.spark.util.SignalUtils [] - Registering signal handler for INT
2025-12-21T23:31:20,946 [main] INFO  org.apache.spark.SecurityManager [] - Changing view acls to: spark
2025-12-21T23:31:20,947 [main] INFO  org.apache.spark.SecurityManager [] - Changing modify acls to: spark
2025-12-21T23:31:20,949 [main] INFO  org.apache.spark.SecurityManager [] - Changing view acls groups to: 
2025-12-21T23:31:20,950 [main] INFO  org.apache.spark.SecurityManager [] - Changing modify acls groups to: 
2025-12-21T23:31:20,952 [main] INFO  org.apache.spark.SecurityManager [] - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
2025-12-21T23:31:21,039 [main] INFO  org.apache.spark.SecurityManager [] - Changing view acls to: spark
2025-12-21T23:31:21,041 [main] INFO  org.apache.spark.SecurityManager [] - Changing modify acls to: spark
2025-12-21T23:31:21,042 [main] INFO  org.apache.spark.SecurityManager [] - Changing view acls groups to: 
2025-12-21T23:31:21,043 [main] INFO  org.apache.spark.SecurityManager [] - Changing modify acls groups to: 
2025-12-21T23:31:21,044 [main] INFO  org.apache.spark.SecurityManager [] - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
2025-12-21T23:31:21,150 [main] INFO  org.apache.spark.deploy.worker.Worker [] - Started daemon with process name: 60@23588c79675c
2025-12-21T23:31:21,168 [main] INFO  org.apache.spark.util.SignalUtils [] - Registering signal handler for TERM
2025-12-21T23:31:21,170 [main] INFO  org.apache.spark.util.SignalUtils [] - Registering signal handler for HUP
2025-12-21T23:31:21,171 [main] INFO  org.apache.spark.util.SignalUtils [] - Registering signal handler for INT
2025-12-21T23:31:21,174 [main] WARN  org.apache.hadoop.util.NativeCodeLoader [] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2025-12-21T23:31:21,280 [main] WARN  org.apache.hadoop.util.NativeCodeLoader [] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2025-12-21T23:31:21,324 [main] INFO  org.apache.spark.SecurityManager [] - Changing view acls to: spark
2025-12-21T23:31:21,328 [main] INFO  org.apache.spark.SecurityManager [] - Changing modify acls to: spark
2025-12-21T23:31:21,331 [main] INFO  org.apache.spark.SecurityManager [] - Changing view acls groups to: 
2025-12-21T23:31:21,332 [main] INFO  org.apache.spark.SecurityManager [] - Changing modify acls groups to: 
2025-12-21T23:31:21,337 [main] INFO  org.apache.spark.SecurityManager [] - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
2025-12-21T23:31:21,534 [main] INFO  org.apache.spark.SecurityManager [] - Changing view acls to: spark
2025-12-21T23:31:21,535 [main] INFO  org.apache.spark.SecurityManager [] - Changing modify acls to: spark
2025-12-21T23:31:21,537 [main] INFO  org.apache.spark.SecurityManager [] - Changing view acls groups to: 
2025-12-21T23:31:21,539 [main] INFO  org.apache.spark.SecurityManager [] - Changing modify acls groups to: 
2025-12-21T23:31:21,540 [main] INFO  org.apache.spark.SecurityManager [] - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
2025-12-21T23:31:21,588 [main] WARN  org.apache.hadoop.util.NativeCodeLoader [] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2025-12-21T23:31:21,728 [main] WARN  org.apache.hadoop.util.NativeCodeLoader [] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2025-12-21T23:31:21,807 [main] INFO  org.apache.spark.util.Utils [] - Successfully started service 'sparkMaster' on port 7077.
2025-12-21T23:31:21,846 [dispatcher-event-loop-1] INFO  org.apache.spark.deploy.master.Master [] - Starting Spark master at spark://cc585e771d35:7077
2025-12-21T23:31:21,854 [dispatcher-event-loop-1] INFO  org.apache.spark.deploy.master.Master [] - Running Spark version 3.5.0
2025-12-21T23:31:21,878 [main] INFO  org.apache.spark.util.Utils [] - Successfully started service 'sparkWorker' on port 45077.
2025-12-21T23:31:21,887 [main] INFO  org.apache.spark.deploy.worker.Worker [] - Worker decommissioning not enabled.
2025-12-21T23:31:21,937 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.util.log [] - Logging initialized @3083ms to org.sparkproject.jetty.util.log.Slf4jLog
2025-12-21T23:31:22,003 [dispatcher-event-loop-1] INFO  org.apache.spark.ui.JettyUtils [] - Start Jetty 0.0.0.0:8080 for MasterUI
2025-12-21T23:31:22,031 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.Server [] - jetty-9.4.52.v20230823; built: 2023-08-23T19:29:37.669Z; git: abdcda73818a1a2c705da276edb0bf6581e7997e; jvm 17.0.10+13-LTS
2025-12-21T23:31:22,061 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.Server [] - Started @3208ms
2025-12-21T23:31:22,142 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.AbstractConnector [] - Started ServerConnector@6b55c3a5{HTTP/1.1, (http/1.1)}{0.0.0.0:8080}
2025-12-21T23:31:22,142 [dispatcher-event-loop-1] INFO  org.apache.spark.util.Utils [] - Successfully started service 'MasterUI' on port 8080.
2025-12-21T23:31:22,151 [main] INFO  org.apache.spark.util.Utils [] - Successfully started service 'sparkWorker' on port 38499.
2025-12-21T23:31:22,153 [main] INFO  org.apache.spark.deploy.worker.Worker [] - Worker decommissioning not enabled.
2025-12-21T23:31:22,191 [dispatcher-event-loop-1] INFO  org.apache.spark.deploy.worker.Worker [] - Starting Spark worker 172.20.0.3:45077 with 2 cores, 3.0 GiB RAM
2025-12-21T23:31:22,195 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@473f8edd{/app,null,AVAILABLE,@Spark}
2025-12-21T23:31:22,200 [dispatcher-event-loop-1] INFO  org.apache.spark.deploy.worker.Worker [] - Running Spark version 3.5.0
2025-12-21T23:31:22,201 [dispatcher-event-loop-1] INFO  org.apache.spark.deploy.worker.Worker [] - Spark home: /opt/bitnami/spark
2025-12-21T23:31:22,203 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@11642429{/app/json,null,AVAILABLE,@Spark}
2025-12-21T23:31:22,206 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@514f3564{/,null,AVAILABLE,@Spark}
2025-12-21T23:31:22,213 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@20d705e8{/json,null,AVAILABLE,@Spark}
2025-12-21T23:31:22,233 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@39466ab6{/static,null,AVAILABLE,@Spark}
2025-12-21T23:31:22,235 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@3f8c1d0c{/app/kill,null,AVAILABLE,@Spark}
2025-12-21T23:31:22,237 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@876c091{/driver/kill,null,AVAILABLE,@Spark}
2025-12-21T23:31:22,237 [dispatcher-event-loop-1] INFO  org.apache.spark.resource.ResourceUtils [] - ==============================================================
2025-12-21T23:31:22,239 [dispatcher-event-loop-1] INFO  org.apache.spark.resource.ResourceUtils [] - No custom resources configured for spark.worker.
2025-12-21T23:31:22,240 [dispatcher-event-loop-1] INFO  org.apache.spark.resource.ResourceUtils [] - ==============================================================
2025-12-21T23:31:22,241 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@4da252a3{/workers/kill,null,AVAILABLE,@Spark}
2025-12-21T23:31:22,247 [dispatcher-event-loop-1] INFO  org.apache.spark.deploy.master.ui.MasterWebUI [] - Bound MasterWebUI to 0.0.0.0, and started at http://cc585e771d35:8080
2025-12-21T23:31:22,264 [main] INFO  org.apache.spark.util.Utils [] - Successfully started service 'sparkWorker' on port 41399.
2025-12-21T23:31:22,266 [main] INFO  org.apache.spark.deploy.worker.Worker [] - Worker decommissioning not enabled.
2025-12-21T23:31:22,306 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.util.log [] - Logging initialized @3121ms to org.sparkproject.jetty.util.log.Slf4jLog
2025-12-21T23:31:22,370 [dispatcher-event-loop-1] INFO  org.apache.spark.ui.JettyUtils [] - Start Jetty 0.0.0.0:8081 for WorkerUI
2025-12-21T23:31:22,389 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.Server [] - jetty-9.4.52.v20230823; built: 2023-08-23T19:29:37.669Z; git: abdcda73818a1a2c705da276edb0bf6581e7997e; jvm 17.0.10+13-LTS
2025-12-21T23:31:22,422 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.Server [] - Started @3238ms
2025-12-21T23:31:22,433 [dispatcher-event-loop-1] INFO  org.apache.spark.deploy.worker.Worker [] - Starting Spark worker 172.20.0.4:38499 with 2 cores, 3.0 GiB RAM
2025-12-21T23:31:22,447 [dispatcher-event-loop-1] INFO  org.apache.spark.deploy.worker.Worker [] - Running Spark version 3.5.0
2025-12-21T23:31:22,450 [dispatcher-event-loop-1] INFO  org.apache.spark.deploy.worker.Worker [] - Spark home: /opt/bitnami/spark
2025-12-21T23:31:22,500 [dispatcher-event-loop-1] INFO  org.apache.spark.resource.ResourceUtils [] - ==============================================================
2025-12-21T23:31:22,501 [dispatcher-event-loop-1] INFO  org.apache.spark.resource.ResourceUtils [] - No custom resources configured for spark.worker.
2025-12-21T23:31:22,502 [dispatcher-event-loop-1] INFO  org.apache.spark.resource.ResourceUtils [] - ==============================================================
2025-12-21T23:31:22,518 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@51acb41c{/metrics/master/json,null,AVAILABLE,@Spark}
2025-12-21T23:31:22,520 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.AbstractConnector [] - Started ServerConnector@2a3c68b8{HTTP/1.1, (http/1.1)}{0.0.0.0:8081}
2025-12-21T23:31:22,520 [dispatcher-event-loop-1] INFO  org.apache.spark.util.Utils [] - Successfully started service 'WorkerUI' on port 8081.
2025-12-21T23:31:22,522 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@2549f23d{/metrics/applications/json,null,AVAILABLE,@Spark}
2025-12-21T23:31:22,548 [dispatcher-event-loop-1] INFO  org.apache.spark.deploy.master.Master [] - I have been elected leader! New state: ALIVE
2025-12-21T23:31:22,556 [dispatcher-event-loop-1] INFO  org.apache.spark.deploy.worker.Worker [] - Starting Spark worker 172.20.0.5:41399 with 2 cores, 3.0 GiB RAM
2025-12-21T23:31:22,563 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@2d210f40{/logPage,null,AVAILABLE,@Spark}
2025-12-21T23:31:22,564 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.util.log [] - Logging initialized @3316ms to org.sparkproject.jetty.util.log.Slf4jLog
2025-12-21T23:31:22,565 [dispatcher-event-loop-1] INFO  org.apache.spark.deploy.worker.Worker [] - Running Spark version 3.5.0
2025-12-21T23:31:22,566 [dispatcher-event-loop-1] INFO  org.apache.spark.deploy.worker.Worker [] - Spark home: /opt/bitnami/spark
2025-12-21T23:31:22,567 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@14239357{/logPage/json,null,AVAILABLE,@Spark}
2025-12-21T23:31:22,570 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@e10bc8f{/,null,AVAILABLE,@Spark}
2025-12-21T23:31:22,572 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@5f984594{/json,null,AVAILABLE,@Spark}
2025-12-21T23:31:22,585 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@5b8b856d{/static,null,AVAILABLE,@Spark}
2025-12-21T23:31:22,588 [dispatcher-event-loop-1] INFO  org.apache.spark.resource.ResourceUtils [] - ==============================================================
2025-12-21T23:31:22,588 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@39b6b4d3{/log,null,AVAILABLE,@Spark}
2025-12-21T23:31:22,589 [dispatcher-event-loop-1] INFO  org.apache.spark.resource.ResourceUtils [] - No custom resources configured for spark.worker.
2025-12-21T23:31:22,591 [dispatcher-event-loop-1] INFO  org.apache.spark.resource.ResourceUtils [] - ==============================================================
2025-12-21T23:31:22,593 [dispatcher-event-loop-1] INFO  org.apache.spark.deploy.worker.ui.WorkerWebUI [] - Bound WorkerWebUI to 0.0.0.0, and started at http://84d6459cd6e4:8081
2025-12-21T23:31:22,597 [worker-register-master-threadpool-0] INFO  org.apache.spark.deploy.worker.Worker [] - Connecting to master spark-master:7077...
2025-12-21T23:31:22,626 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@50872cf1{/metrics/json,null,AVAILABLE,@Spark}
2025-12-21T23:31:22,631 [dispatcher-event-loop-1] INFO  org.apache.spark.ui.JettyUtils [] - Start Jetty 0.0.0.0:8081 for WorkerUI
2025-12-21T23:31:22,656 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.util.log [] - Logging initialized @3334ms to org.sparkproject.jetty.util.log.Slf4jLog
2025-12-21T23:31:22,657 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.Server [] - jetty-9.4.52.v20230823; built: 2023-08-23T19:29:37.669Z; git: abdcda73818a1a2c705da276edb0bf6581e7997e; jvm 17.0.10+13-LTS
2025-12-21T23:31:22,698 [netty-rpc-connection-0] INFO  org.apache.spark.network.client.TransportClientFactory [] - Successfully created connection to spark-master/172.20.0.2:7077 after 58 ms (0 ms spent in bootstraps)
2025-12-21T23:31:22,707 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.Server [] - Started @3460ms
2025-12-21T23:31:22,745 [dispatcher-event-loop-1] INFO  org.apache.spark.ui.JettyUtils [] - Start Jetty 0.0.0.0:8081 for WorkerUI
2025-12-21T23:31:22,771 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.Server [] - jetty-9.4.52.v20230823; built: 2023-08-23T19:29:37.669Z; git: abdcda73818a1a2c705da276edb0bf6581e7997e; jvm 17.0.10+13-LTS
2025-12-21T23:31:22,778 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.AbstractConnector [] - Started ServerConnector@6168db18{HTTP/1.1, (http/1.1)}{0.0.0.0:8081}
2025-12-21T23:31:22,778 [dispatcher-event-loop-1] INFO  org.apache.spark.util.Utils [] - Successfully started service 'WorkerUI' on port 8081.
2025-12-21T23:31:22,806 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.Server [] - Started @3486ms
2025-12-21T23:31:22,820 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@43c46750{/logPage,null,AVAILABLE,@Spark}
2025-12-21T23:31:22,825 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@745d3b01{/logPage/json,null,AVAILABLE,@Spark}
2025-12-21T23:31:22,827 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@45e51fb6{/,null,AVAILABLE,@Spark}
2025-12-21T23:31:22,829 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@3477d0e8{/json,null,AVAILABLE,@Spark}
2025-12-21T23:31:22,842 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@6ca9b2fd{/static,null,AVAILABLE,@Spark}
2025-12-21T23:31:22,844 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@5fa93ca{/log,null,AVAILABLE,@Spark}
2025-12-21T23:31:22,847 [dispatcher-event-loop-1] INFO  org.apache.spark.deploy.worker.ui.WorkerWebUI [] - Bound WorkerWebUI to 0.0.0.0, and started at http://42f275a4bb58:8081
2025-12-21T23:31:22,851 [worker-register-master-threadpool-0] INFO  org.apache.spark.deploy.worker.Worker [] - Connecting to master spark-master:7077...
2025-12-21T23:31:22,872 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.AbstractConnector [] - Started ServerConnector@6168db18{HTTP/1.1, (http/1.1)}{0.0.0.0:8081}
2025-12-21T23:31:22,873 [dispatcher-event-loop-1] INFO  org.apache.spark.util.Utils [] - Successfully started service 'WorkerUI' on port 8081.
2025-12-21T23:31:22,879 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@422745ff{/metrics/json,null,AVAILABLE,@Spark}
2025-12-21T23:31:22,888 [dispatcher-event-loop-10] INFO  org.apache.spark.deploy.master.Master [] - Registering worker 172.20.0.3:45077 with 2 cores, 3.0 GiB RAM
2025-12-21T23:31:22,909 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@43c46750{/logPage,null,AVAILABLE,@Spark}
2025-12-21T23:31:22,909 [dispatcher-event-loop-6] INFO  org.apache.spark.deploy.worker.Worker [] - Successfully registered with master spark://cc585e771d35:7077
2025-12-21T23:31:22,916 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@745d3b01{/logPage/json,null,AVAILABLE,@Spark}
2025-12-21T23:31:22,919 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@45e51fb6{/,null,AVAILABLE,@Spark}
2025-12-21T23:31:22,922 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@3477d0e8{/json,null,AVAILABLE,@Spark}
2025-12-21T23:31:22,939 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@6ca9b2fd{/static,null,AVAILABLE,@Spark}
2025-12-21T23:31:22,942 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@5fa93ca{/log,null,AVAILABLE,@Spark}
2025-12-21T23:31:22,942 [netty-rpc-connection-0] INFO  org.apache.spark.network.client.TransportClientFactory [] - Successfully created connection to spark-master/172.20.0.2:7077 after 51 ms (0 ms spent in bootstraps)
2025-12-21T23:31:22,946 [dispatcher-event-loop-1] INFO  org.apache.spark.deploy.worker.ui.WorkerWebUI [] - Bound WorkerWebUI to 0.0.0.0, and started at http://23588c79675c:8081
2025-12-21T23:31:22,950 [worker-register-master-threadpool-0] INFO  org.apache.spark.deploy.worker.Worker [] - Connecting to master spark-master:7077...
2025-12-21T23:31:22,981 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@422745ff{/metrics/json,null,AVAILABLE,@Spark}
2025-12-21T23:31:23,047 [dispatcher-event-loop-5] INFO  org.apache.spark.deploy.master.Master [] - Registering worker 172.20.0.4:38499 with 2 cores, 3.0 GiB RAM
2025-12-21T23:31:23,046 [netty-rpc-connection-0] INFO  org.apache.spark.network.client.TransportClientFactory [] - Successfully created connection to spark-master/172.20.0.2:7077 after 45 ms (0 ms spent in bootstraps)
2025-12-21T23:31:23,062 [dispatcher-event-loop-6] INFO  org.apache.spark.deploy.worker.Worker [] - Successfully registered with master spark://cc585e771d35:7077
2025-12-21T23:31:23,148 [dispatcher-event-loop-12] INFO  org.apache.spark.deploy.master.Master [] - Registering worker 172.20.0.5:41399 with 2 cores, 3.0 GiB RAM
2025-12-21T23:31:23,162 [dispatcher-event-loop-6] INFO  org.apache.spark.deploy.worker.Worker [] - Successfully registered with master spark://cc585e771d35:7077
2025-12-22T01:52:53,306 [Thread-4] INFO  org.apache.spark.SparkContext [] - Running Spark version 3.5.0
2025-12-22T01:52:53,310 [Thread-4] INFO  org.apache.spark.SparkContext [] - OS info Linux, 6.6.87.1-microsoft-standard-WSL2, amd64
2025-12-22T01:52:53,310 [Thread-4] INFO  org.apache.spark.SparkContext [] - Java version 17.0.10
2025-12-22T01:52:53,342 [Thread-4] INFO  org.apache.spark.resource.ResourceUtils [] - ==============================================================
2025-12-22T01:52:53,343 [Thread-4] INFO  org.apache.spark.resource.ResourceUtils [] - No custom resources configured for spark.driver.
2025-12-22T01:52:53,343 [Thread-4] INFO  org.apache.spark.resource.ResourceUtils [] - ==============================================================
2025-12-22T01:52:53,344 [Thread-4] INFO  org.apache.spark.SparkContext [] - Submitted application: etl-rides-json
2025-12-22T01:52:53,366 [Thread-4] INFO  org.apache.spark.resource.ResourceProfile [] - Default ResourceProfile created, executor resources: Map(memory -> name: memory, amount: 3072, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
2025-12-22T01:52:53,376 [Thread-4] INFO  org.apache.spark.resource.ResourceProfile [] - Limiting resource is cpu
2025-12-22T01:52:53,377 [Thread-4] INFO  org.apache.spark.resource.ResourceProfileManager [] - Added ResourceProfile id: 0
2025-12-22T01:52:53,449 [Thread-4] INFO  org.apache.spark.SecurityManager [] - Changing view acls to: root,spark
2025-12-22T01:52:53,451 [Thread-4] INFO  org.apache.spark.SecurityManager [] - Changing modify acls to: root,spark
2025-12-22T01:52:53,452 [Thread-4] INFO  org.apache.spark.SecurityManager [] - Changing view acls groups to: 
2025-12-22T01:52:53,453 [Thread-4] INFO  org.apache.spark.SecurityManager [] - Changing modify acls groups to: 
2025-12-22T01:52:53,454 [Thread-4] INFO  org.apache.spark.SecurityManager [] - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, spark; groups with view permissions: EMPTY; users with modify permissions: root, spark; groups with modify permissions: EMPTY
2025-12-22T01:52:53,537 [Thread-4] WARN  org.apache.hadoop.util.NativeCodeLoader [] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2025-12-22T01:52:53,869 [Thread-4] INFO  org.apache.spark.util.Utils [] - Successfully started service 'sparkDriver' on port 45529.
2025-12-22T01:52:53,905 [Thread-4] INFO  org.apache.spark.SparkEnv [] - Registering MapOutputTracker
2025-12-22T01:52:53,943 [Thread-4] INFO  org.apache.spark.SparkEnv [] - Registering BlockManagerMaster
2025-12-22T01:52:53,963 [Thread-4] INFO  org.apache.spark.storage.BlockManagerMasterEndpoint [] - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2025-12-22T01:52:53,964 [Thread-4] INFO  org.apache.spark.storage.BlockManagerMasterEndpoint [] - BlockManagerMasterEndpoint up
2025-12-22T01:52:53,972 [Thread-4] INFO  org.apache.spark.SparkEnv [] - Registering BlockManagerMasterHeartbeat
2025-12-22T01:52:54,012 [Thread-4] INFO  org.apache.spark.storage.DiskBlockManager [] - Created local directory at /tmp/blockmgr-6db5b750-8434-4e4b-b511-e53bc15c0935
2025-12-22T01:52:54,027 [Thread-4] INFO  org.apache.spark.storage.memory.MemoryStore [] - MemoryStore started with capacity 434.4 MiB
2025-12-22T01:52:54,046 [Thread-4] INFO  org.apache.spark.SparkEnv [] - Registering OutputCommitCoordinator
2025-12-22T01:52:54,108 [Thread-4] INFO  org.sparkproject.jetty.util.log [] - Logging initialized @3102ms to org.sparkproject.jetty.util.log.Slf4jLog
2025-12-22T01:52:54,194 [Thread-4] INFO  org.apache.spark.ui.JettyUtils [] - Start Jetty 0.0.0.0:4040 for SparkUI
2025-12-22T01:52:54,208 [Thread-4] INFO  org.sparkproject.jetty.server.Server [] - jetty-9.4.52.v20230823; built: 2023-08-23T19:29:37.669Z; git: abdcda73818a1a2c705da276edb0bf6581e7997e; jvm 17.0.10+13-LTS
2025-12-22T01:52:54,234 [Thread-4] INFO  org.sparkproject.jetty.server.Server [] - Started @3230ms
2025-12-22T01:52:54,275 [Thread-4] INFO  org.sparkproject.jetty.server.AbstractConnector [] - Started ServerConnector@405ed8c2{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2025-12-22T01:52:54,276 [Thread-4] INFO  org.apache.spark.util.Utils [] - Successfully started service 'SparkUI' on port 4040.
2025-12-22T01:52:54,299 [Thread-4] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@1d3c1cbb{/,null,AVAILABLE,@Spark}
2025-12-22T01:52:54,412 [appclient-register-master-threadpool-0] INFO  org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint [] - Connecting to master spark://spark-master:7077...
2025-12-22T01:52:54,467 [netty-rpc-connection-0] INFO  org.apache.spark.network.client.TransportClientFactory [] - Successfully created connection to spark-master/172.20.0.2:7077 after 26 ms (0 ms spent in bootstraps)
2025-12-22T01:52:54,946 [dispatcher-event-loop-0] INFO  org.apache.spark.deploy.master.Master [] - Registering app etl-rides-json
2025-12-22T01:52:55,009 [dispatcher-event-loop-0] INFO  org.apache.spark.deploy.master.Master [] - Registered app etl-rides-json with ID app-20251222015254-0000
2025-12-22T01:52:55,022 [dispatcher-event-loop-0] INFO  org.apache.spark.deploy.master.Master [] - Start scheduling for app app-20251222015254-0000 with rpId: 0
2025-12-22T01:52:55,022 [dispatcher-event-loop-10] INFO  org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend [] - Connected to Spark cluster with app ID app-20251222015254-0000
2025-12-22T01:52:55,036 [Thread-4] INFO  org.apache.spark.util.Utils [] - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 39791.
2025-12-22T01:52:55,037 [Thread-4] INFO  org.apache.spark.network.netty.NettyBlockTransferService [] - Server created on cc585e771d35:39791
2025-12-22T01:52:55,041 [Thread-4] INFO  org.apache.spark.storage.BlockManager [] - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2025-12-22T01:52:55,052 [Thread-4] INFO  org.apache.spark.storage.BlockManagerMaster [] - Registering BlockManager BlockManagerId(driver, cc585e771d35, 39791, None)
2025-12-22T01:52:55,057 [dispatcher-BlockManagerMaster] INFO  org.apache.spark.storage.BlockManagerMasterEndpoint [] - Registering block manager cc585e771d35:39791 with 434.4 MiB RAM, BlockManagerId(driver, cc585e771d35, 39791, None)
2025-12-22T01:52:55,061 [Thread-4] INFO  org.apache.spark.storage.BlockManagerMaster [] - Registered BlockManager BlockManagerId(driver, cc585e771d35, 39791, None)
2025-12-22T01:52:55,063 [Thread-4] INFO  org.apache.spark.storage.BlockManager [] - Initialized BlockManager: BlockManagerId(driver, cc585e771d35, 39791, None)
2025-12-22T01:52:55,089 [dispatcher-event-loop-0] INFO  org.apache.spark.deploy.master.Master [] - Launching executor app-20251222015254-0000/0 on worker worker-20251221233122-172.20.0.4-38499
2025-12-22T01:52:55,107 [dispatcher-event-loop-0] INFO  org.apache.spark.deploy.master.Master [] - Launching executor app-20251222015254-0000/1 on worker worker-20251221233122-172.20.0.5-41399
2025-12-22T01:52:55,109 [dispatcher-event-loop-0] INFO  org.apache.spark.deploy.master.Master [] - Launching executor app-20251222015254-0000/2 on worker worker-20251221233121-172.20.0.3-45077
2025-12-22T01:52:55,112 [dispatcher-event-loop-2] INFO  org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint [] - Executor added: app-20251222015254-0000/0 on worker-20251221233122-172.20.0.4-38499 (172.20.0.4:38499) with 2 core(s)
2025-12-22T01:52:55,115 [dispatcher-event-loop-2] INFO  org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend [] - Granted executor ID app-20251222015254-0000/0 on hostPort 172.20.0.4:38499 with 2 core(s), 3.0 GiB RAM
2025-12-22T01:52:55,116 [dispatcher-event-loop-2] INFO  org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint [] - Executor added: app-20251222015254-0000/1 on worker-20251221233122-172.20.0.5-41399 (172.20.0.5:41399) with 2 core(s)
2025-12-22T01:52:55,116 [dispatcher-event-loop-2] INFO  org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend [] - Granted executor ID app-20251222015254-0000/1 on hostPort 172.20.0.5:41399 with 2 core(s), 3.0 GiB RAM
2025-12-22T01:52:55,117 [dispatcher-event-loop-2] INFO  org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint [] - Executor added: app-20251222015254-0000/2 on worker-20251221233121-172.20.0.3-45077 (172.20.0.3:45077) with 2 core(s)
2025-12-22T01:52:55,117 [dispatcher-event-loop-2] INFO  org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend [] - Granted executor ID app-20251222015254-0000/2 on hostPort 172.20.0.3:45077 with 2 core(s), 3.0 GiB RAM
2025-12-22T01:52:55,445 [Thread-4] INFO  org.apache.spark.deploy.history.SingleEventLogFileWriter [] - Logging events to file:/opt/bitnami/spark/logs/events/app-20251222015254-0000.inprogress
2025-12-22T01:52:55,681 [Thread-4] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Stopped o.s.j.s.ServletContextHandler@1d3c1cbb{/,null,STOPPED,@Spark}
2025-12-22T01:52:55,688 [Thread-4] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@28e863bf{/jobs,null,AVAILABLE,@Spark}
2025-12-22T01:52:55,691 [Thread-4] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@7d026d3e{/jobs/json,null,AVAILABLE,@Spark}
2025-12-22T01:52:55,694 [Thread-4] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@75185daa{/jobs/job,null,AVAILABLE,@Spark}
2025-12-22T01:52:55,696 [Thread-4] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@6d8cb992{/jobs/job/json,null,AVAILABLE,@Spark}
2025-12-22T01:52:55,698 [Thread-4] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@2ce679e2{/stages,null,AVAILABLE,@Spark}
2025-12-22T01:52:55,701 [Thread-4] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@48fb3a4b{/stages/json,null,AVAILABLE,@Spark}
2025-12-22T01:52:55,711 [Thread-4] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@e212986{/stages/stage,null,AVAILABLE,@Spark}
2025-12-22T01:52:55,713 [Thread-4] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@5da19815{/stages/stage/json,null,AVAILABLE,@Spark}
2025-12-22T01:52:55,715 [Thread-4] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@108484f{/stages/pool,null,AVAILABLE,@Spark}
2025-12-22T01:52:55,716 [Thread-4] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@27881534{/stages/pool/json,null,AVAILABLE,@Spark}
2025-12-22T01:52:55,718 [Thread-4] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@7394b3e9{/storage,null,AVAILABLE,@Spark}
2025-12-22T01:52:55,719 [Thread-4] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@2088a5df{/storage/json,null,AVAILABLE,@Spark}
2025-12-22T01:52:55,721 [Thread-4] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@286a4868{/storage/rdd,null,AVAILABLE,@Spark}
2025-12-22T01:52:55,724 [Thread-4] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@7b1c371a{/storage/rdd/json,null,AVAILABLE,@Spark}
2025-12-22T01:52:55,728 [Thread-4] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@42865368{/environment,null,AVAILABLE,@Spark}
2025-12-22T01:52:55,733 [Thread-4] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@387dfe19{/environment/json,null,AVAILABLE,@Spark}
2025-12-22T01:52:55,735 [Thread-4] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@5b7efaf8{/executors,null,AVAILABLE,@Spark}
2025-12-22T01:52:55,738 [Thread-4] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@339591c4{/executors/json,null,AVAILABLE,@Spark}
2025-12-22T01:52:55,741 [Thread-4] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@2b38f10b{/executors/threadDump,null,AVAILABLE,@Spark}
2025-12-22T01:52:55,743 [Thread-4] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@295d9296{/executors/threadDump/json,null,AVAILABLE,@Spark}
2025-12-22T01:52:55,748 [Thread-4] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@29c12880{/executors/heapHistogram,null,AVAILABLE,@Spark}
2025-12-22T01:52:55,730 [dispatcher-event-loop-13] INFO  org.apache.spark.deploy.worker.Worker [] - Asked to launch executor app-20251222015254-0000/0 for etl-rides-json
2025-12-22T01:52:55,750 [Thread-4] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@131a8a98{/executors/heapHistogram/json,null,AVAILABLE,@Spark}
2025-12-22T01:52:55,748 [dispatcher-event-loop-0] INFO  org.apache.spark.deploy.worker.Worker [] - Asked to launch executor app-20251222015254-0000/2 for etl-rides-json
2025-12-22T01:52:55,773 [Thread-4] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@1f42529f{/static,null,AVAILABLE,@Spark}
2025-12-22T01:52:55,775 [Thread-4] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@20200afd{/,null,AVAILABLE,@Spark}
2025-12-22T01:52:55,781 [Thread-4] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@71adf88f{/api,null,AVAILABLE,@Spark}
2025-12-22T01:52:55,783 [Thread-4] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@10c426cc{/jobs/job/kill,null,AVAILABLE,@Spark}
2025-12-22T01:52:55,787 [Thread-4] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@2f82746c{/stages/stage/kill,null,AVAILABLE,@Spark}
2025-12-22T01:52:55,794 [Thread-4] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@251ab103{/metrics/json,null,AVAILABLE,@Spark}
2025-12-22T01:52:55,797 [Thread-4] INFO  org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend [] - SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
2025-12-22T01:52:55,906 [ExecutorRunner for app-20251222015254-0000/0] INFO  org.apache.spark.SecurityManager [] - Changing view acls to: spark
2025-12-22T01:52:55,893 [dispatcher-event-loop-0] INFO  org.apache.spark.deploy.worker.Worker [] - Asked to launch executor app-20251222015254-0000/1 for etl-rides-json
2025-12-22T01:52:55,907 [ExecutorRunner for app-20251222015254-0000/0] INFO  org.apache.spark.SecurityManager [] - Changing modify acls to: spark
2025-12-22T01:52:55,907 [ExecutorRunner for app-20251222015254-0000/0] INFO  org.apache.spark.SecurityManager [] - Changing view acls groups to: 
2025-12-22T01:52:55,908 [ExecutorRunner for app-20251222015254-0000/0] INFO  org.apache.spark.SecurityManager [] - Changing modify acls groups to: 
2025-12-22T01:52:55,908 [ExecutorRunner for app-20251222015254-0000/0] INFO  org.apache.spark.SecurityManager [] - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
2025-12-22T01:52:55,939 [ExecutorRunner for app-20251222015254-0000/2] INFO  org.apache.spark.SecurityManager [] - Changing view acls to: spark
2025-12-22T01:52:55,941 [ExecutorRunner for app-20251222015254-0000/2] INFO  org.apache.spark.SecurityManager [] - Changing modify acls to: spark
2025-12-22T01:52:55,942 [ExecutorRunner for app-20251222015254-0000/2] INFO  org.apache.spark.SecurityManager [] - Changing view acls groups to: 
2025-12-22T01:52:55,943 [ExecutorRunner for app-20251222015254-0000/2] INFO  org.apache.spark.SecurityManager [] - Changing modify acls groups to: 
2025-12-22T01:52:55,944 [ExecutorRunner for app-20251222015254-0000/2] INFO  org.apache.spark.SecurityManager [] - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
2025-12-22T01:52:55,972 [ExecutorRunner for app-20251222015254-0000/0] INFO  org.apache.spark.deploy.worker.ExecutorRunner [] - Launch command: "/opt/bitnami/java/bin/java" "-cp" "/opt/bitnami/spark/conf/:/opt/bitnami/spark/jars/*" "-Xmx3072M" "-Dspark.driver.port=45529" "-Djava.net.preferIPv6Addresses=false" "-XX:+IgnoreUnrecognizedVMOptions" "--add-opens=java.base/java.lang=ALL-UNNAMED" "--add-opens=java.base/java.lang.invoke=ALL-UNNAMED" "--add-opens=java.base/java.lang.reflect=ALL-UNNAMED" "--add-opens=java.base/java.io=ALL-UNNAMED" "--add-opens=java.base/java.net=ALL-UNNAMED" "--add-opens=java.base/java.nio=ALL-UNNAMED" "--add-opens=java.base/java.util=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED" "--add-opens=java.base/sun.nio.ch=ALL-UNNAMED" "--add-opens=java.base/sun.nio.cs=ALL-UNNAMED" "--add-opens=java.base/sun.security.action=ALL-UNNAMED" "--add-opens=java.base/sun.util.calendar=ALL-UNNAMED" "--add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED" "-Djdk.reflect.useDirectMethodHandle=false" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@cc585e771d35:45529" "--executor-id" "0" "--hostname" "172.20.0.4" "--cores" "2" "--app-id" "app-20251222015254-0000" "--worker-url" "spark://Worker@172.20.0.4:38499" "--resourceProfileId" "0"
2025-12-22T01:52:56,011 [ExecutorRunner for app-20251222015254-0000/1] INFO  org.apache.spark.SecurityManager [] - Changing view acls to: spark
2025-12-22T01:52:56,011 [ExecutorRunner for app-20251222015254-0000/1] INFO  org.apache.spark.SecurityManager [] - Changing modify acls to: spark
2025-12-22T01:52:56,012 [ExecutorRunner for app-20251222015254-0000/1] INFO  org.apache.spark.SecurityManager [] - Changing view acls groups to: 
2025-12-22T01:52:56,012 [ExecutorRunner for app-20251222015254-0000/1] INFO  org.apache.spark.SecurityManager [] - Changing modify acls groups to: 
2025-12-22T01:52:56,012 [ExecutorRunner for app-20251222015254-0000/1] INFO  org.apache.spark.SecurityManager [] - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
2025-12-22T01:52:56,012 [ExecutorRunner for app-20251222015254-0000/2] INFO  org.apache.spark.deploy.worker.ExecutorRunner [] - Launch command: "/opt/bitnami/java/bin/java" "-cp" "/opt/bitnami/spark/conf/:/opt/bitnami/spark/jars/*" "-Xmx3072M" "-Dspark.driver.port=45529" "-Djava.net.preferIPv6Addresses=false" "-XX:+IgnoreUnrecognizedVMOptions" "--add-opens=java.base/java.lang=ALL-UNNAMED" "--add-opens=java.base/java.lang.invoke=ALL-UNNAMED" "--add-opens=java.base/java.lang.reflect=ALL-UNNAMED" "--add-opens=java.base/java.io=ALL-UNNAMED" "--add-opens=java.base/java.net=ALL-UNNAMED" "--add-opens=java.base/java.nio=ALL-UNNAMED" "--add-opens=java.base/java.util=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED" "--add-opens=java.base/sun.nio.ch=ALL-UNNAMED" "--add-opens=java.base/sun.nio.cs=ALL-UNNAMED" "--add-opens=java.base/sun.security.action=ALL-UNNAMED" "--add-opens=java.base/sun.util.calendar=ALL-UNNAMED" "--add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED" "-Djdk.reflect.useDirectMethodHandle=false" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@cc585e771d35:45529" "--executor-id" "2" "--hostname" "172.20.0.3" "--cores" "2" "--app-id" "app-20251222015254-0000" "--worker-url" "spark://Worker@172.20.0.3:45077" "--resourceProfileId" "0"
2025-12-22T01:52:56,060 [ExecutorRunner for app-20251222015254-0000/1] INFO  org.apache.spark.deploy.worker.ExecutorRunner [] - Launch command: "/opt/bitnami/java/bin/java" "-cp" "/opt/bitnami/spark/conf/:/opt/bitnami/spark/jars/*" "-Xmx3072M" "-Dspark.driver.port=45529" "-Djava.net.preferIPv6Addresses=false" "-XX:+IgnoreUnrecognizedVMOptions" "--add-opens=java.base/java.lang=ALL-UNNAMED" "--add-opens=java.base/java.lang.invoke=ALL-UNNAMED" "--add-opens=java.base/java.lang.reflect=ALL-UNNAMED" "--add-opens=java.base/java.io=ALL-UNNAMED" "--add-opens=java.base/java.net=ALL-UNNAMED" "--add-opens=java.base/java.nio=ALL-UNNAMED" "--add-opens=java.base/java.util=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED" "--add-opens=java.base/sun.nio.ch=ALL-UNNAMED" "--add-opens=java.base/sun.nio.cs=ALL-UNNAMED" "--add-opens=java.base/sun.security.action=ALL-UNNAMED" "--add-opens=java.base/sun.util.calendar=ALL-UNNAMED" "--add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED" "-Djdk.reflect.useDirectMethodHandle=false" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@cc585e771d35:45529" "--executor-id" "1" "--hostname" "172.20.0.5" "--cores" "2" "--app-id" "app-20251222015254-0000" "--worker-url" "spark://Worker@172.20.0.5:41399" "--resourceProfileId" "0"
2025-12-22T01:52:56,067 [dispatcher-event-loop-3] INFO  org.apache.spark.deploy.master.Master [] - Start scheduling for app app-20251222015254-0000 with rpId: 0
2025-12-22T01:52:56,091 [dispatcher-event-loop-9] INFO  org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint [] - Executor updated: app-20251222015254-0000/0 is now RUNNING
2025-12-22T01:52:56,103 [dispatcher-event-loop-4] INFO  org.apache.spark.deploy.master.Master [] - Start scheduling for app app-20251222015254-0000 with rpId: 0
2025-12-22T01:52:56,108 [dispatcher-event-loop-8] INFO  org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint [] - Executor updated: app-20251222015254-0000/2 is now RUNNING
2025-12-22T01:52:56,138 [dispatcher-event-loop-2] INFO  org.apache.spark.deploy.master.Master [] - Start scheduling for app app-20251222015254-0000 with rpId: 0
2025-12-22T01:52:56,145 [dispatcher-event-loop-7] INFO  org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint [] - Executor updated: app-20251222015254-0000/1 is now RUNNING
2025-12-22T01:52:56,334 [Thread-4] INFO  org.apache.spark.sql.internal.SharedState [] - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
2025-12-22T01:52:56,340 [Thread-4] INFO  org.apache.spark.sql.internal.SharedState [] - Warehouse path is 'file:/opt/bitnami/spark/spark-warehouse'.
2025-12-22T01:52:56,380 [Thread-4] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@7d34269{/SQL,null,AVAILABLE,@Spark}
2025-12-22T01:52:56,382 [Thread-4] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@6cf95c94{/SQL/json,null,AVAILABLE,@Spark}
2025-12-22T01:52:56,385 [Thread-4] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@2bca67d3{/SQL/execution,null,AVAILABLE,@Spark}
2025-12-22T01:52:56,388 [Thread-4] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@2563ca4b{/SQL/execution/json,null,AVAILABLE,@Spark}
2025-12-22T01:52:56,396 [Thread-4] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@2ff2f4a4{/static/sql,null,AVAILABLE,@Spark}
2025-12-22T01:52:57,460 [main] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend [] - Started daemon with process name: 149@42f275a4bb58
2025-12-22T01:52:57,469 [main] INFO  org.apache.spark.util.SignalUtils [] - Registering signal handler for TERM
2025-12-22T01:52:57,471 [main] INFO  org.apache.spark.util.SignalUtils [] - Registering signal handler for HUP
2025-12-22T01:52:57,472 [main] INFO  org.apache.spark.util.SignalUtils [] - Registering signal handler for INT
2025-12-22T01:52:57,470 [main] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend [] - Started daemon with process name: 148@84d6459cd6e4
2025-12-22T01:52:57,480 [main] INFO  org.apache.spark.util.SignalUtils [] - Registering signal handler for TERM
2025-12-22T01:52:57,482 [main] INFO  org.apache.spark.util.SignalUtils [] - Registering signal handler for HUP
2025-12-22T01:52:57,483 [main] INFO  org.apache.spark.util.SignalUtils [] - Registering signal handler for INT
2025-12-22T01:52:57,545 [main] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend [] - Started daemon with process name: 149@23588c79675c
2025-12-22T01:52:57,557 [main] INFO  org.apache.spark.util.SignalUtils [] - Registering signal handler for TERM
2025-12-22T01:52:57,558 [main] INFO  org.apache.spark.util.SignalUtils [] - Registering signal handler for HUP
2025-12-22T01:52:57,558 [main] INFO  org.apache.spark.util.SignalUtils [] - Registering signal handler for INT
2025-12-22T01:52:57,892 [main] WARN  org.apache.hadoop.util.NativeCodeLoader [] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2025-12-22T01:52:57,909 [main] WARN  org.apache.hadoop.util.NativeCodeLoader [] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2025-12-22T01:52:57,988 [main] WARN  org.apache.hadoop.util.NativeCodeLoader [] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2025-12-22T01:52:58,014 [main] INFO  org.apache.spark.SecurityManager [] - Changing view acls to: spark
2025-12-22T01:52:58,015 [main] INFO  org.apache.spark.SecurityManager [] - Changing modify acls to: spark
2025-12-22T01:52:58,017 [main] INFO  org.apache.spark.SecurityManager [] - Changing view acls groups to: 
2025-12-22T01:52:58,019 [main] INFO  org.apache.spark.SecurityManager [] - Changing modify acls groups to: 
2025-12-22T01:52:58,019 [main] INFO  org.apache.spark.SecurityManager [] - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
2025-12-22T01:52:58,040 [main] INFO  org.apache.spark.SecurityManager [] - Changing view acls to: spark
2025-12-22T01:52:58,042 [main] INFO  org.apache.spark.SecurityManager [] - Changing modify acls to: spark
2025-12-22T01:52:58,043 [main] INFO  org.apache.spark.SecurityManager [] - Changing view acls groups to: 
2025-12-22T01:52:58,045 [main] INFO  org.apache.spark.SecurityManager [] - Changing modify acls groups to: 
2025-12-22T01:52:58,049 [main] INFO  org.apache.spark.SecurityManager [] - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
2025-12-22T01:52:58,051 [Thread-4] WARN  org.apache.hadoop.metrics2.impl.MetricsConfig [] - Cannot locate configuration: tried hadoop-metrics2-s3a-file-system.properties,hadoop-metrics2.properties
2025-12-22T01:52:58,074 [Thread-4] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl [] - Scheduled Metric snapshot period at 10 second(s).
2025-12-22T01:52:58,074 [Thread-4] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl [] - s3a-file-system metrics system started
2025-12-22T01:52:58,147 [main] INFO  org.apache.spark.SecurityManager [] - Changing view acls to: spark
2025-12-22T01:52:58,149 [main] INFO  org.apache.spark.SecurityManager [] - Changing modify acls to: spark
2025-12-22T01:52:58,151 [main] INFO  org.apache.spark.SecurityManager [] - Changing view acls groups to: 
2025-12-22T01:52:58,152 [main] INFO  org.apache.spark.SecurityManager [] - Changing modify acls groups to: 
2025-12-22T01:52:58,153 [main] INFO  org.apache.spark.SecurityManager [] - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
2025-12-22T01:52:58,450 [netty-rpc-connection-0] INFO  org.apache.spark.network.client.TransportClientFactory [] - Successfully created connection to cc585e771d35/172.20.0.2:45529 after 88 ms (0 ms spent in bootstraps)
2025-12-22T01:52:58,477 [netty-rpc-connection-0] INFO  org.apache.spark.network.client.TransportClientFactory [] - Successfully created connection to cc585e771d35/172.20.0.2:45529 after 96 ms (0 ms spent in bootstraps)
2025-12-22T01:52:58,538 [netty-rpc-connection-0] INFO  org.apache.spark.network.client.TransportClientFactory [] - Successfully created connection to cc585e771d35/172.20.0.2:45529 after 88 ms (0 ms spent in bootstraps)
2025-12-22T01:52:58,600 [main] INFO  org.apache.spark.SecurityManager [] - Changing view acls to: spark
2025-12-22T01:52:58,601 [main] INFO  org.apache.spark.SecurityManager [] - Changing modify acls to: spark
2025-12-22T01:52:58,601 [main] INFO  org.apache.spark.SecurityManager [] - Changing view acls groups to: 
2025-12-22T01:52:58,601 [main] INFO  org.apache.spark.SecurityManager [] - Changing modify acls groups to: 
2025-12-22T01:52:58,601 [main] INFO  org.apache.spark.SecurityManager [] - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
2025-12-22T01:52:58,604 [main] INFO  org.apache.spark.SecurityManager [] - Changing view acls to: spark
2025-12-22T01:52:58,605 [main] INFO  org.apache.spark.SecurityManager [] - Changing modify acls to: spark
2025-12-22T01:52:58,605 [main] INFO  org.apache.spark.SecurityManager [] - Changing view acls groups to: 
2025-12-22T01:52:58,605 [main] INFO  org.apache.spark.SecurityManager [] - Changing modify acls groups to: 
2025-12-22T01:52:58,605 [main] INFO  org.apache.spark.SecurityManager [] - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
2025-12-22T01:52:58,664 [main] INFO  org.apache.spark.SecurityManager [] - Changing view acls to: spark
2025-12-22T01:52:58,665 [main] INFO  org.apache.spark.SecurityManager [] - Changing modify acls to: spark
2025-12-22T01:52:58,666 [main] INFO  org.apache.spark.SecurityManager [] - Changing view acls groups to: 
2025-12-22T01:52:58,666 [main] INFO  org.apache.spark.SecurityManager [] - Changing modify acls groups to: 
2025-12-22T01:52:58,667 [main] INFO  org.apache.spark.SecurityManager [] - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
2025-12-22T01:52:58,676 [netty-rpc-connection-0] INFO  org.apache.spark.network.client.TransportClientFactory [] - Successfully created connection to cc585e771d35/172.20.0.2:45529 after 3 ms (0 ms spent in bootstraps)
2025-12-22T01:52:58,684 [netty-rpc-connection-0] INFO  org.apache.spark.network.client.TransportClientFactory [] - Successfully created connection to cc585e771d35/172.20.0.2:45529 after 3 ms (0 ms spent in bootstraps)
2025-12-22T01:52:58,748 [netty-rpc-connection-0] INFO  org.apache.spark.network.client.TransportClientFactory [] - Successfully created connection to cc585e771d35/172.20.0.2:45529 after 4 ms (0 ms spent in bootstraps)
2025-12-22T01:52:58,806 [main] INFO  org.apache.spark.storage.DiskBlockManager [] - Created local directory at /tmp/spark-0dc9b242-0b01-4c31-90a0-5d8287810fc8/executor-73ffc2fc-c53f-461c-9574-a4465b8a33ad/blockmgr-d9ea0c40-e8c6-41d4-88c2-cf8c29272de3
2025-12-22T01:52:58,812 [main] INFO  org.apache.spark.storage.DiskBlockManager [] - Created local directory at /tmp/spark-103b3947-fe12-4c0e-b156-479177ff1911/executor-233fad2d-c0fb-49b4-97b6-e3609ffcc5d5/blockmgr-5c0ade87-7d3a-4a74-8fd7-f722425959d1
2025-12-22T01:52:58,852 [main] INFO  org.apache.spark.storage.memory.MemoryStore [] - MemoryStore started with capacity 1663.2 MiB
2025-12-22T01:52:58,864 [main] INFO  org.apache.spark.storage.memory.MemoryStore [] - MemoryStore started with capacity 1663.2 MiB
2025-12-22T01:52:58,869 [main] INFO  org.apache.spark.storage.DiskBlockManager [] - Created local directory at /tmp/spark-62ba56c6-8cdf-497d-9c31-bde574a3adcd/executor-2a61c493-0190-4d08-8133-c009edb02fc6/blockmgr-f984d172-e70c-40c2-a75d-aa434d57b774
2025-12-22T01:52:58,919 [main] INFO  org.apache.spark.storage.memory.MemoryStore [] - MemoryStore started with capacity 1663.2 MiB
2025-12-22T01:52:59,138 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend [] - Connecting to driver: spark://CoarseGrainedScheduler@cc585e771d35:45529
2025-12-22T01:52:59,139 [main] INFO  org.apache.spark.deploy.worker.WorkerWatcher [] - Connecting to worker spark://Worker@172.20.0.3:45077
2025-12-22T01:52:59,140 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend [] - Connecting to driver: spark://CoarseGrainedScheduler@cc585e771d35:45529
2025-12-22T01:52:59,141 [main] INFO  org.apache.spark.deploy.worker.WorkerWatcher [] - Connecting to worker spark://Worker@172.20.0.4:38499
2025-12-22T01:52:59,146 [netty-rpc-connection-1] INFO  org.apache.spark.network.client.TransportClientFactory [] - Successfully created connection to /172.20.0.3:45077 after 4 ms (0 ms spent in bootstraps)
2025-12-22T01:52:59,151 [dispatcher-event-loop-0] INFO  org.apache.spark.deploy.worker.WorkerWatcher [] - Successfully connected to spark://Worker@172.20.0.3:45077
2025-12-22T01:52:59,154 [netty-rpc-connection-1] INFO  org.apache.spark.network.client.TransportClientFactory [] - Successfully created connection to /172.20.0.4:38499 after 9 ms (0 ms spent in bootstraps)
2025-12-22T01:52:59,157 [dispatcher-event-loop-1] INFO  org.apache.spark.deploy.worker.WorkerWatcher [] - Successfully connected to spark://Worker@172.20.0.4:38499
2025-12-22T01:52:59,162 [dispatcher-Executor] INFO  org.apache.spark.resource.ResourceUtils [] - ==============================================================
2025-12-22T01:52:59,165 [dispatcher-Executor] INFO  org.apache.spark.resource.ResourceUtils [] - No custom resources configured for spark.executor.
2025-12-22T01:52:59,165 [dispatcher-Executor] INFO  org.apache.spark.resource.ResourceUtils [] - ==============================================================
2025-12-22T01:52:59,167 [dispatcher-Executor] INFO  org.apache.spark.resource.ResourceUtils [] - No custom resources configured for spark.executor.
2025-12-22T01:52:59,167 [dispatcher-Executor] INFO  org.apache.spark.resource.ResourceUtils [] - ==============================================================
2025-12-22T01:52:59,168 [dispatcher-Executor] INFO  org.apache.spark.resource.ResourceUtils [] - ==============================================================
2025-12-22T01:52:59,202 [dispatcher-CoarseGrainedScheduler] INFO  org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend$StandaloneDriverEndpoint [] - Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.20.0.4:46560) with ID 0,  ResourceProfileId 0
2025-12-22T01:52:59,212 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend [] - Successfully registered with driver
2025-12-22T01:52:59,219 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend [] - Connecting to driver: spark://CoarseGrainedScheduler@cc585e771d35:45529
2025-12-22T01:52:59,220 [main] INFO  org.apache.spark.deploy.worker.WorkerWatcher [] - Connecting to worker spark://Worker@172.20.0.5:41399
2025-12-22T01:52:59,225 [dispatcher-Executor] INFO  org.apache.spark.executor.Executor [] - Starting executor ID 0 on host 172.20.0.4
2025-12-22T01:52:59,226 [dispatcher-Executor] INFO  org.apache.spark.executor.Executor [] - OS info Linux, 6.6.87.1-microsoft-standard-WSL2, amd64
2025-12-22T01:52:59,227 [dispatcher-CoarseGrainedScheduler] INFO  org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend$StandaloneDriverEndpoint [] - Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.20.0.3:49998) with ID 2,  ResourceProfileId 0
2025-12-22T01:52:59,229 [dispatcher-Executor] INFO  org.apache.spark.executor.Executor [] - Java version 17.0.10
2025-12-22T01:52:59,238 [netty-rpc-connection-1] INFO  org.apache.spark.network.client.TransportClientFactory [] - Successfully created connection to /172.20.0.5:41399 after 11 ms (0 ms spent in bootstraps)
2025-12-22T01:52:59,241 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend [] - Successfully registered with driver
2025-12-22T01:52:59,241 [dispatcher-event-loop-0] INFO  org.apache.spark.deploy.worker.WorkerWatcher [] - Successfully connected to spark://Worker@172.20.0.5:41399
2025-12-22T01:52:59,248 [dispatcher-Executor] INFO  org.apache.spark.resource.ResourceUtils [] - ==============================================================
2025-12-22T01:52:59,249 [dispatcher-Executor] INFO  org.apache.spark.resource.ResourceUtils [] - No custom resources configured for spark.executor.
2025-12-22T01:52:59,250 [dispatcher-Executor] INFO  org.apache.spark.executor.Executor [] - Starting executor ID 2 on host 172.20.0.3
2025-12-22T01:52:59,251 [dispatcher-Executor] INFO  org.apache.spark.resource.ResourceUtils [] - ==============================================================
2025-12-22T01:52:59,253 [dispatcher-Executor] INFO  org.apache.spark.executor.Executor [] - OS info Linux, 6.6.87.1-microsoft-standard-WSL2, amd64
2025-12-22T01:52:59,254 [dispatcher-Executor] INFO  org.apache.spark.executor.Executor [] - Java version 17.0.10
2025-12-22T01:52:59,281 [dispatcher-CoarseGrainedScheduler] INFO  org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend$StandaloneDriverEndpoint [] - Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.20.0.5:46128) with ID 1,  ResourceProfileId 0
2025-12-22T01:52:59,288 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend [] - Successfully registered with driver
2025-12-22T01:52:59,296 [dispatcher-Executor] INFO  org.apache.spark.executor.Executor [] - Starting executor ID 1 on host 172.20.0.5
2025-12-22T01:52:59,298 [dispatcher-Executor] INFO  org.apache.spark.executor.Executor [] - OS info Linux, 6.6.87.1-microsoft-standard-WSL2, amd64
2025-12-22T01:52:59,299 [dispatcher-Executor] INFO  org.apache.spark.executor.Executor [] - Java version 17.0.10
2025-12-22T01:52:59,306 [dispatcher-Executor] INFO  org.apache.spark.util.Utils [] - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 40533.
2025-12-22T01:52:59,306 [dispatcher-Executor] INFO  org.apache.spark.network.netty.NettyBlockTransferService [] - Server created on 172.20.0.4:40533
2025-12-22T01:52:59,309 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManager [] - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2025-12-22T01:52:59,321 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManagerMaster [] - Registering BlockManager BlockManagerId(0, 172.20.0.4, 40533, None)
2025-12-22T01:52:59,327 [dispatcher-Executor] INFO  org.apache.spark.util.Utils [] - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 41283.
2025-12-22T01:52:59,328 [dispatcher-Executor] INFO  org.apache.spark.network.netty.NettyBlockTransferService [] - Server created on 172.20.0.3:41283
2025-12-22T01:52:59,331 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManager [] - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2025-12-22T01:52:59,333 [dispatcher-BlockManagerMaster] INFO  org.apache.spark.storage.BlockManagerMasterEndpoint [] - Registering block manager 172.20.0.4:40533 with 1663.2 MiB RAM, BlockManagerId(0, 172.20.0.4, 40533, None)
2025-12-22T01:52:59,339 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManagerMaster [] - Registered BlockManager BlockManagerId(0, 172.20.0.4, 40533, None)
2025-12-22T01:52:59,341 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManager [] - Initialized BlockManager: BlockManagerId(0, 172.20.0.4, 40533, None)
2025-12-22T01:52:59,343 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManagerMaster [] - Registering BlockManager BlockManagerId(2, 172.20.0.3, 41283, None)
2025-12-22T01:52:59,359 [dispatcher-Executor] INFO  org.apache.spark.executor.Executor [] - Starting executor with user classpath (userClassPathFirst = false): ''
2025-12-22T01:52:59,359 [dispatcher-BlockManagerMaster] INFO  org.apache.spark.storage.BlockManagerMasterEndpoint [] - Registering block manager 172.20.0.3:41283 with 1663.2 MiB RAM, BlockManagerId(2, 172.20.0.3, 41283, None)
2025-12-22T01:52:59,361 [dispatcher-Executor] INFO  org.apache.spark.executor.Executor [] - Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@5e89724c for default.
2025-12-22T01:52:59,364 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManagerMaster [] - Registered BlockManager BlockManagerId(2, 172.20.0.3, 41283, None)
2025-12-22T01:52:59,367 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManager [] - Initialized BlockManager: BlockManagerId(2, 172.20.0.3, 41283, None)
2025-12-22T01:52:59,376 [dispatcher-Executor] INFO  org.apache.spark.util.Utils [] - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 40993.
2025-12-22T01:52:59,377 [dispatcher-Executor] INFO  org.apache.spark.network.netty.NettyBlockTransferService [] - Server created on 172.20.0.5:40993
2025-12-22T01:52:59,378 [dispatcher-Executor] INFO  org.apache.spark.executor.Executor [] - Starting executor with user classpath (userClassPathFirst = false): ''
2025-12-22T01:52:59,379 [dispatcher-Executor] INFO  org.apache.spark.executor.Executor [] - Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@5e89724c for default.
2025-12-22T01:52:59,381 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManager [] - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2025-12-22T01:52:59,395 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManagerMaster [] - Registering BlockManager BlockManagerId(1, 172.20.0.5, 40993, None)
2025-12-22T01:52:59,404 [dispatcher-BlockManagerMaster] INFO  org.apache.spark.storage.BlockManagerMasterEndpoint [] - Registering block manager 172.20.0.5:40993 with 1663.2 MiB RAM, BlockManagerId(1, 172.20.0.5, 40993, None)
2025-12-22T01:52:59,408 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManagerMaster [] - Registered BlockManager BlockManagerId(1, 172.20.0.5, 40993, None)
2025-12-22T01:52:59,410 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManager [] - Initialized BlockManager: BlockManagerId(1, 172.20.0.5, 40993, None)
2025-12-22T01:52:59,422 [dispatcher-Executor] INFO  org.apache.spark.executor.Executor [] - Starting executor with user classpath (userClassPathFirst = false): ''
2025-12-22T01:52:59,423 [dispatcher-Executor] INFO  org.apache.spark.executor.Executor [] - Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@5e89724c for default.
2025-12-22T02:03:13,226 [MasterUI-59] INFO  org.apache.spark.deploy.master.Master [] - Removing app app-20251222015254-0000
2025-12-22T02:03:13,263 [dispatcher-event-loop-1] ERROR org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend [] - Application has been killed. Reason: Master removed our application: KILLED
2025-12-22T02:03:13,279 [dispatcher-event-loop-4] INFO  org.apache.spark.deploy.worker.Worker [] - Asked to kill executor app-20251222015254-0000/0
2025-12-22T02:03:13,282 [ExecutorRunner for app-20251222015254-0000/0] INFO  org.apache.spark.deploy.worker.ExecutorRunner [] - Runner thread for executor app-20251222015254-0000/0 interrupted
2025-12-22T02:03:13,284 [ExecutorRunner for app-20251222015254-0000/0] INFO  org.apache.spark.deploy.worker.ExecutorRunner [] - Killing process!
2025-12-22T02:03:13,283 [dispatcher-event-loop-4] INFO  org.apache.spark.deploy.worker.Worker [] - Asked to kill executor app-20251222015254-0000/2
2025-12-22T02:03:13,284 [dispatcher-event-loop-4] INFO  org.apache.spark.deploy.worker.Worker [] - Asked to kill executor app-20251222015254-0000/1
2025-12-22T02:03:13,289 [ExecutorRunner for app-20251222015254-0000/2] INFO  org.apache.spark.deploy.worker.ExecutorRunner [] - Runner thread for executor app-20251222015254-0000/2 interrupted
2025-12-22T02:03:13,291 [ExecutorRunner for app-20251222015254-0000/1] INFO  org.apache.spark.deploy.worker.ExecutorRunner [] - Runner thread for executor app-20251222015254-0000/1 interrupted
2025-12-22T02:03:13,290 [SIGTERM handler] ERROR org.apache.spark.executor.CoarseGrainedExecutorBackend [] - RECEIVED SIGNAL TERM
2025-12-22T02:03:13,292 [ExecutorRunner for app-20251222015254-0000/2] INFO  org.apache.spark.deploy.worker.ExecutorRunner [] - Killing process!
2025-12-22T02:03:13,292 [ExecutorRunner for app-20251222015254-0000/1] INFO  org.apache.spark.deploy.worker.ExecutorRunner [] - Killing process!
2025-12-22T02:03:13,295 [SIGTERM handler] ERROR org.apache.spark.executor.CoarseGrainedExecutorBackend [] - RECEIVED SIGNAL TERM
2025-12-22T02:03:13,296 [SIGTERM handler] ERROR org.apache.spark.executor.CoarseGrainedExecutorBackend [] - RECEIVED SIGNAL TERM
2025-12-22T02:03:13,335 [shutdown-hook-0] INFO  org.apache.spark.storage.memory.MemoryStore [] - MemoryStore cleared
2025-12-22T02:03:13,337 [shutdown-hook-0] INFO  org.apache.spark.storage.BlockManager [] - BlockManager stopped
2025-12-22T02:03:13,337 [shutdown-hook-0] INFO  org.apache.spark.storage.memory.MemoryStore [] - MemoryStore cleared
2025-12-22T02:03:13,338 [shutdown-hook-0] INFO  org.apache.spark.storage.BlockManager [] - BlockManager stopped
2025-12-22T02:03:13,337 [shutdown-hook-0] INFO  org.apache.spark.storage.memory.MemoryStore [] - MemoryStore cleared
2025-12-22T02:03:13,339 [shutdown-hook-0] INFO  org.apache.spark.storage.BlockManager [] - BlockManager stopped
2025-12-22T02:03:13,342 [shutdown-hook-0] INFO  org.apache.spark.util.ShutdownHookManager [] - Shutdown hook called
2025-12-22T02:03:13,343 [shutdown-hook-0] INFO  org.apache.spark.util.ShutdownHookManager [] - Shutdown hook called
2025-12-22T02:03:13,345 [shutdown-hook-0] INFO  org.apache.spark.util.ShutdownHookManager [] - Shutdown hook called
2025-12-22T02:03:13,397 [dispatcher-event-loop-3] WARN  org.apache.spark.deploy.master.Master [] - Got status update for unknown executor app-20251222015254-0000/0
2025-12-22T02:03:13,400 [dispatcher-event-loop-8] INFO  org.apache.spark.deploy.worker.Worker [] - Executor app-20251222015254-0000/0 finished with state KILLED exitStatus 143
2025-12-22T02:03:13,401 [dispatcher-event-loop-4] WARN  org.apache.spark.deploy.master.Master [] - Got status update for unknown executor app-20251222015254-0000/1
2025-12-22T02:03:13,407 [dispatcher-event-loop-2] WARN  org.apache.spark.deploy.master.Master [] - Got status update for unknown executor app-20251222015254-0000/2
2025-12-22T02:03:13,407 [dispatcher-event-loop-8] INFO  org.apache.spark.deploy.worker.Worker [] - Executor app-20251222015254-0000/1 finished with state KILLED exitStatus 143
2025-12-22T02:03:13,409 [dispatcher-event-loop-8] INFO  org.apache.spark.network.shuffle.ExternalShuffleBlockResolver [] - Clean up non-shuffle and non-RDD files associated with the finished executor 0
2025-12-22T02:03:13,412 [dispatcher-event-loop-8] INFO  org.apache.spark.network.shuffle.ExternalShuffleBlockResolver [] - Executor is not registered (appId=app-20251222015254-0000, execId=0)
2025-12-22T02:03:13,414 [dispatcher-event-loop-8] INFO  org.apache.spark.network.shuffle.ExternalShuffleBlockResolver [] - Clean up non-shuffle and non-RDD files associated with the finished executor 1
2025-12-22T02:03:13,413 [dispatcher-event-loop-8] INFO  org.apache.spark.deploy.worker.Worker [] - Executor app-20251222015254-0000/2 finished with state KILLED exitStatus 143
2025-12-22T02:03:13,416 [dispatcher-event-loop-8] INFO  org.apache.spark.network.shuffle.ExternalShuffleBlockResolver [] - Executor is not registered (appId=app-20251222015254-0000, execId=1)
2025-12-22T02:03:13,420 [dispatcher-event-loop-8] INFO  org.apache.spark.network.shuffle.ExternalShuffleBlockResolver [] - Application app-20251222015254-0000 removed, cleanupLocalDirs = true
2025-12-22T02:03:13,420 [worker-cleanup-thread] INFO  org.apache.spark.deploy.worker.Worker [] - Cleaning up local directories for application app-20251222015254-0000
2025-12-22T02:03:13,423 [dispatcher-event-loop-8] INFO  org.apache.spark.network.shuffle.ExternalShuffleBlockResolver [] - Application app-20251222015254-0000 removed, cleanupLocalDirs = true
2025-12-22T02:03:13,423 [dispatcher-event-loop-8] INFO  org.apache.spark.network.shuffle.ExternalShuffleBlockResolver [] - Clean up non-shuffle and non-RDD files associated with the finished executor 2
2025-12-22T02:03:13,424 [worker-cleanup-thread] INFO  org.apache.spark.deploy.worker.Worker [] - Cleaning up local directories for application app-20251222015254-0000
2025-12-22T02:03:13,425 [dispatcher-event-loop-8] INFO  org.apache.spark.network.shuffle.ExternalShuffleBlockResolver [] - Executor is not registered (appId=app-20251222015254-0000, execId=2)
2025-12-22T02:03:13,431 [dispatcher-event-loop-8] INFO  org.apache.spark.network.shuffle.ExternalShuffleBlockResolver [] - Application app-20251222015254-0000 removed, cleanupLocalDirs = true
2025-12-22T02:03:13,432 [worker-cleanup-thread] INFO  org.apache.spark.deploy.worker.Worker [] - Cleaning up local directories for application app-20251222015254-0000
2025-12-22T02:03:13,591 [stop-spark-context] INFO  org.apache.spark.SparkContext [] - SparkContext is stopping with exitCode 0.
2025-12-22T02:03:13,591 [dispatcher-event-loop-1] ERROR org.apache.spark.rpc.netty.Inbox [] - Ignoring error
org.apache.spark.SparkException: Exiting due to error from cluster scheduler: Master removed our application: KILLED
	at org.apache.spark.errors.SparkCoreErrors$.clusterSchedulerError(SparkCoreErrors.scala:291) ~[spark-core_2.12-3.5.0.jar:3.5.0]
	at org.apache.spark.scheduler.TaskSchedulerImpl.error(TaskSchedulerImpl.scala:981) ~[spark-core_2.12-3.5.0.jar:3.5.0]
	at org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend.dead(StandaloneSchedulerBackend.scala:165) ~[spark-core_2.12-3.5.0.jar:3.5.0]
	at org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint.markDead(StandaloneAppClient.scala:263) ~[spark-core_2.12-3.5.0.jar:3.5.0]
	at org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint$$anonfun$receive$1.applyOrElse(StandaloneAppClient.scala:170) ~[spark-core_2.12-3.5.0.jar:3.5.0]
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:115) [spark-core_2.12-3.5.0.jar:3.5.0]
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) [spark-core_2.12-3.5.0.jar:3.5.0]
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) [spark-core_2.12-3.5.0.jar:3.5.0]
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) [spark-core_2.12-3.5.0.jar:3.5.0]
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) [spark-core_2.12-3.5.0.jar:3.5.0]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-12-22T02:03:13,605 [stop-spark-context] INFO  org.sparkproject.jetty.server.AbstractConnector [] - Stopped Spark@405ed8c2{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2025-12-22T02:03:13,609 [stop-spark-context] INFO  org.apache.spark.ui.SparkUI [] - Stopped Spark web UI at http://cc585e771d35:4040
2025-12-22T02:03:13,619 [stop-spark-context] INFO  org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend [] - Shutting down all executors
2025-12-22T02:03:13,620 [dispatcher-CoarseGrainedScheduler] INFO  org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend$StandaloneDriverEndpoint [] - Asking each executor to shut down
2025-12-22T02:03:13,640 [dispatcher-event-loop-1] INFO  org.apache.spark.deploy.master.Master [] - Received unregister request from application app-20251222015254-0000
2025-12-22T02:03:13,649 [dispatcher-event-loop-5] INFO  org.apache.spark.MapOutputTrackerMasterEndpoint [] - MapOutputTrackerMasterEndpoint stopped!
2025-12-22T02:03:13,670 [stop-spark-context] INFO  org.apache.spark.storage.memory.MemoryStore [] - MemoryStore cleared
2025-12-22T02:03:13,670 [stop-spark-context] INFO  org.apache.spark.storage.BlockManager [] - BlockManager stopped
2025-12-22T02:03:13,677 [stop-spark-context] INFO  org.apache.spark.storage.BlockManagerMaster [] - BlockManagerMaster stopped
2025-12-22T02:03:13,682 [dispatcher-event-loop-13] INFO  org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint [] - OutputCommitCoordinator stopped!
2025-12-22T02:03:13,692 [stop-spark-context] INFO  org.apache.spark.SparkContext [] - Successfully stopped SparkContext
2025-12-22T02:03:13,693 [dispatcher-event-loop-6] INFO  org.apache.spark.deploy.master.Master [] - 172.20.0.2:55018 got disassociated, removing it.
2025-12-22T02:03:13,695 [dispatcher-event-loop-6] INFO  org.apache.spark.deploy.master.Master [] - cc585e771d35:45529 got disassociated, removing it.
2025-12-22T02:04:03,301 [shutdown-hook-0] INFO  org.apache.spark.util.ShutdownHookManager [] - Shutdown hook called
2025-12-22T02:04:03,302 [shutdown-hook-0] INFO  org.apache.spark.util.ShutdownHookManager [] - Deleting directory /tmp/spark-6b5bfcb2-13dc-4714-8f55-06bf9d794690/pyspark-77646972-6f11-48dd-a3bb-0f19927a2ffa
2025-12-22T02:04:03,307 [shutdown-hook-0] INFO  org.apache.spark.util.ShutdownHookManager [] - Deleting directory /tmp/spark-3910a219-dca7-4270-a6f0-530cbf4504b9
2025-12-22T02:04:03,310 [shutdown-hook-0] INFO  org.apache.spark.util.ShutdownHookManager [] - Deleting directory /tmp/spark-6b5bfcb2-13dc-4714-8f55-06bf9d794690
2025-12-22T02:04:03,321 [shutdown-hook-0] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl [] - Stopping s3a-file-system metrics system...
2025-12-22T02:04:03,322 [shutdown-hook-0] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl [] - s3a-file-system metrics system stopped.
2025-12-22T02:04:03,322 [shutdown-hook-0] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl [] - s3a-file-system metrics system shutdown complete.
2025-12-22T02:10:48,183 [dispatcher-event-loop-11] INFO  org.apache.spark.deploy.worker.Worker [] - spark-master:7077 Disassociated !
2025-12-22T02:10:48,183 [dispatcher-event-loop-11] INFO  org.apache.spark.deploy.worker.Worker [] - spark-master:7077 Disassociated !
2025-12-22T02:10:48,185 [dispatcher-event-loop-11] ERROR org.apache.spark.deploy.worker.Worker [] - Connection to master failed! Waiting for master to reconnect...
2025-12-22T02:10:48,186 [dispatcher-event-loop-11] ERROR org.apache.spark.deploy.worker.Worker [] - Connection to master failed! Waiting for master to reconnect...
2025-12-22T02:10:48,185 [dispatcher-event-loop-12] INFO  org.apache.spark.deploy.worker.Worker [] - spark-master:7077 Disassociated !
2025-12-22T02:10:48,187 [dispatcher-event-loop-12] ERROR org.apache.spark.deploy.worker.Worker [] - Connection to master failed! Waiting for master to reconnect...
2025-12-22T02:10:48,188 [dispatcher-event-loop-11] INFO  org.apache.spark.deploy.worker.Worker [] - cc585e771d35:7077 Disassociated !
2025-12-22T02:10:48,188 [dispatcher-event-loop-11] ERROR org.apache.spark.deploy.worker.Worker [] - Connection to master failed! Waiting for master to reconnect...
2025-12-22T02:10:48,188 [dispatcher-event-loop-11] INFO  org.apache.spark.deploy.worker.Worker [] - cc585e771d35:7077 Disassociated !
2025-12-22T02:10:48,188 [dispatcher-event-loop-11] ERROR org.apache.spark.deploy.worker.Worker [] - Connection to master failed! Waiting for master to reconnect...
2025-12-22T02:10:48,188 [worker-register-master-threadpool-1] INFO  org.apache.spark.deploy.worker.Worker [] - Connecting to master spark-master:7077...
2025-12-22T02:10:48,188 [worker-register-master-threadpool-1] INFO  org.apache.spark.deploy.worker.Worker [] - Connecting to master spark-master:7077...
2025-12-22T02:10:48,189 [dispatcher-event-loop-11] INFO  org.apache.spark.deploy.worker.Worker [] - Not spawning another attempt to register with the master, since there is an attempt scheduled already.
2025-12-22T02:10:48,190 [dispatcher-event-loop-11] INFO  org.apache.spark.deploy.worker.Worker [] - Not spawning another attempt to register with the master, since there is an attempt scheduled already.
2025-12-22T02:10:48,191 [dispatcher-event-loop-12] INFO  org.apache.spark.deploy.worker.Worker [] - cc585e771d35:7077 Disassociated !
2025-12-22T02:10:48,191 [dispatcher-event-loop-12] ERROR org.apache.spark.deploy.worker.Worker [] - Connection to master failed! Waiting for master to reconnect...
2025-12-22T02:10:48,191 [worker-register-master-threadpool-1] INFO  org.apache.spark.deploy.worker.Worker [] - Connecting to master spark-master:7077...
2025-12-22T02:10:48,192 [dispatcher-event-loop-12] INFO  org.apache.spark.deploy.worker.Worker [] - Not spawning another attempt to register with the master, since there is an attempt scheduled already.
2025-12-22T02:10:48,195 [netty-rpc-connection-1] INFO  org.apache.spark.network.client.TransportClientFactory [] - Found inactive connection to spark-master/172.20.0.2:7077, creating a new one.
2025-12-22T02:10:48,195 [netty-rpc-connection-1] INFO  org.apache.spark.network.client.TransportClientFactory [] - Found inactive connection to spark-master/172.20.0.2:7077, creating a new one.
2025-12-22T02:10:48,199 [netty-rpc-connection-1] INFO  org.apache.spark.network.client.TransportClientFactory [] - Found inactive connection to spark-master/172.20.0.2:7077, creating a new one.
2025-12-22T02:10:48,213 [worker-register-master-threadpool-1] WARN  org.apache.spark.deploy.worker.Worker [] - Failed to connect to master spark-master:7077
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.0.jar:3.5.0]
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.0.jar:3.5.0]
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.0.jar:3.5.0]
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102) ~[spark-core_2.12-3.5.0.jar:3.5.0]
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110) ~[spark-core_2.12-3.5.0.jar:3.5.0]
	at org.apache.spark.deploy.worker.Worker$$anon$1.run(Worker.scala:313) [spark-core_2.12-3.5.0.jar:3.5.0]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
Caused by: java.io.IOException: Failed to connect to spark-master/172.20.0.2:7077
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:294) ~[spark-network-common_2.12-3.5.0.jar:3.5.0]
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:214) ~[spark-network-common_2.12-3.5.0.jar:3.5.0]
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:226) ~[spark-network-common_2.12-3.5.0.jar:3.5.0]
	at org.apache.spark.rpc.netty.NettyRpcEnv.createClient(NettyRpcEnv.scala:204) ~[spark-core_2.12-3.5.0.jar:3.5.0]
	at org.apache.spark.rpc.netty.Outbox$$anon$1.call(Outbox.scala:202) ~[spark-core_2.12-3.5.0.jar:3.5.0]
	at org.apache.spark.rpc.netty.Outbox$$anon$1.call(Outbox.scala:198) ~[spark-core_2.12-3.5.0.jar:3.5.0]
	... 4 more
Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: spark-master/172.20.0.2:7077
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.Net.pollConnect(Native Method) ~[?:?]
	at sun.nio.ch.Net.pollConnectNow(Net.java:672) ~[?:?]
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:946) ~[?:?]
	at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:337) ~[netty-transport-4.1.96.Final.jar:4.1.96.Final]
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:334) ~[netty-transport-4.1.96.Final.jar:4.1.96.Final]
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:776) ~[netty-transport-4.1.96.Final.jar:4.1.96.Final]
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:724) ~[netty-transport-4.1.96.Final.jar:4.1.96.Final]
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:650) ~[netty-transport-4.1.96.Final.jar:4.1.96.Final]
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:562) ~[netty-transport-4.1.96.Final.jar:4.1.96.Final]
	at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997) ~[netty-common-4.1.96.Final.jar:4.1.96.Final]
	at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74) ~[netty-common-4.1.96.Final.jar:4.1.96.Final]
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30) ~[netty-common-4.1.96.Final.jar:4.1.96.Final]
	... 1 more
2025-12-22T02:10:48,217 [worker-register-master-threadpool-1] WARN  org.apache.spark.deploy.worker.Worker [] - Failed to connect to master spark-master:7077
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.0.jar:3.5.0]
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.0.jar:3.5.0]
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.0.jar:3.5.0]
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102) ~[spark-core_2.12-3.5.0.jar:3.5.0]
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110) ~[spark-core_2.12-3.5.0.jar:3.5.0]
	at org.apache.spark.deploy.worker.Worker$$anon$1.run(Worker.scala:313) [spark-core_2.12-3.5.0.jar:3.5.0]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
Caused by: java.io.IOException: Failed to connect to spark-master/172.20.0.2:7077
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:294) ~[spark-network-common_2.12-3.5.0.jar:3.5.0]
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:214) ~[spark-network-common_2.12-3.5.0.jar:3.5.0]
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:226) ~[spark-network-common_2.12-3.5.0.jar:3.5.0]
	at org.apache.spark.rpc.netty.NettyRpcEnv.createClient(NettyRpcEnv.scala:204) ~[spark-core_2.12-3.5.0.jar:3.5.0]
	at org.apache.spark.rpc.netty.Outbox$$anon$1.call(Outbox.scala:202) ~[spark-core_2.12-3.5.0.jar:3.5.0]
	at org.apache.spark.rpc.netty.Outbox$$anon$1.call(Outbox.scala:198) ~[spark-core_2.12-3.5.0.jar:3.5.0]
	... 4 more
Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: spark-master/172.20.0.2:7077
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.Net.pollConnect(Native Method) ~[?:?]
	at sun.nio.ch.Net.pollConnectNow(Net.java:672) ~[?:?]
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:946) ~[?:?]
	at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:337) ~[netty-transport-4.1.96.Final.jar:4.1.96.Final]
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:334) ~[netty-transport-4.1.96.Final.jar:4.1.96.Final]
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:776) ~[netty-transport-4.1.96.Final.jar:4.1.96.Final]
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:724) ~[netty-transport-4.1.96.Final.jar:4.1.96.Final]
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:650) ~[netty-transport-4.1.96.Final.jar:4.1.96.Final]
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:562) ~[netty-transport-4.1.96.Final.jar:4.1.96.Final]
	at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997) ~[netty-common-4.1.96.Final.jar:4.1.96.Final]
	at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74) ~[netty-common-4.1.96.Final.jar:4.1.96.Final]
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30) ~[netty-common-4.1.96.Final.jar:4.1.96.Final]
	... 1 more
2025-12-22T02:10:48,212 [worker-register-master-threadpool-1] WARN  org.apache.spark.deploy.worker.Worker [] - Failed to connect to master spark-master:7077
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.0.jar:3.5.0]
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.0.jar:3.5.0]
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.0.jar:3.5.0]
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102) ~[spark-core_2.12-3.5.0.jar:3.5.0]
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110) ~[spark-core_2.12-3.5.0.jar:3.5.0]
	at org.apache.spark.deploy.worker.Worker$$anon$1.run(Worker.scala:313) [spark-core_2.12-3.5.0.jar:3.5.0]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
Caused by: java.io.IOException: Failed to connect to spark-master/172.20.0.2:7077
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:294) ~[spark-network-common_2.12-3.5.0.jar:3.5.0]
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:214) ~[spark-network-common_2.12-3.5.0.jar:3.5.0]
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:226) ~[spark-network-common_2.12-3.5.0.jar:3.5.0]
	at org.apache.spark.rpc.netty.NettyRpcEnv.createClient(NettyRpcEnv.scala:204) ~[spark-core_2.12-3.5.0.jar:3.5.0]
	at org.apache.spark.rpc.netty.Outbox$$anon$1.call(Outbox.scala:202) ~[spark-core_2.12-3.5.0.jar:3.5.0]
	at org.apache.spark.rpc.netty.Outbox$$anon$1.call(Outbox.scala:198) ~[spark-core_2.12-3.5.0.jar:3.5.0]
	... 4 more
Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: spark-master/172.20.0.2:7077
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.Net.pollConnect(Native Method) ~[?:?]
	at sun.nio.ch.Net.pollConnectNow(Net.java:672) ~[?:?]
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:946) ~[?:?]
	at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:337) ~[netty-transport-4.1.96.Final.jar:4.1.96.Final]
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:334) ~[netty-transport-4.1.96.Final.jar:4.1.96.Final]
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:776) ~[netty-transport-4.1.96.Final.jar:4.1.96.Final]
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:724) ~[netty-transport-4.1.96.Final.jar:4.1.96.Final]
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:650) ~[netty-transport-4.1.96.Final.jar:4.1.96.Final]
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:562) ~[netty-transport-4.1.96.Final.jar:4.1.96.Final]
	at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997) ~[netty-common-4.1.96.Final.jar:4.1.96.Final]
	at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74) ~[netty-common-4.1.96.Final.jar:4.1.96.Final]
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30) ~[netty-common-4.1.96.Final.jar:4.1.96.Final]
	... 1 more
2025-12-22T02:10:53,190 [dispatcher-event-loop-3] INFO  org.apache.spark.deploy.worker.Worker [] - Retrying connection to master (attempt # 1)
2025-12-22T02:10:53,192 [worker-register-master-threadpool-1] INFO  org.apache.spark.deploy.worker.Worker [] - Connecting to master cc585e771d35:7077...
2025-12-22T02:10:58,188 [dispatcher-event-loop-2] INFO  org.apache.spark.deploy.worker.Worker [] - Retrying connection to master (attempt # 2)
2025-12-22T02:10:58,191 [worker-register-master-threadpool-1] INFO  org.apache.spark.deploy.worker.Worker [] - Connecting to master cc585e771d35:7077...
2025-12-22T02:10:58,193 [dispatcher-event-loop-2] INFO  org.apache.spark.deploy.worker.Worker [] - Retrying connection to master (attempt # 1)
2025-12-22T02:10:58,195 [worker-register-master-threadpool-1] INFO  org.apache.spark.deploy.worker.Worker [] - Connecting to master cc585e771d35:7077...
2025-12-22T02:11:16,443 [main] INFO  org.apache.spark.deploy.master.Master [] - Started daemon with process name: 63@e78e7707373c
2025-12-22T02:11:16,465 [main] INFO  org.apache.spark.util.SignalUtils [] - Registering signal handler for TERM
2025-12-22T02:11:16,469 [main] INFO  org.apache.spark.util.SignalUtils [] - Registering signal handler for HUP
2025-12-22T02:11:16,470 [main] INFO  org.apache.spark.util.SignalUtils [] - Registering signal handler for INT
2025-12-22T02:11:16,638 [main] INFO  org.apache.spark.deploy.worker.Worker [] - Started daemon with process name: 60@e7f2b1a13d24
2025-12-22T02:11:16,652 [main] INFO  org.apache.spark.util.SignalUtils [] - Registering signal handler for TERM
2025-12-22T02:11:16,654 [main] INFO  org.apache.spark.util.SignalUtils [] - Registering signal handler for HUP
2025-12-22T02:11:16,655 [main] INFO  org.apache.spark.util.SignalUtils [] - Registering signal handler for INT
2025-12-22T02:11:16,858 [main] INFO  org.apache.spark.deploy.worker.Worker [] - Started daemon with process name: 60@b7a722371209
2025-12-22T02:11:16,891 [main] INFO  org.apache.spark.util.SignalUtils [] - Registering signal handler for TERM
2025-12-22T02:11:16,894 [main] INFO  org.apache.spark.util.SignalUtils [] - Registering signal handler for HUP
2025-12-22T02:11:16,895 [main] INFO  org.apache.spark.util.SignalUtils [] - Registering signal handler for INT
2025-12-22T02:11:16,920 [main] INFO  org.apache.spark.deploy.worker.Worker [] - Started daemon with process name: 60@74f89a3203f2
2025-12-22T02:11:16,942 [main] INFO  org.apache.spark.util.SignalUtils [] - Registering signal handler for TERM
2025-12-22T02:11:16,945 [main] INFO  org.apache.spark.util.SignalUtils [] - Registering signal handler for HUP
2025-12-22T02:11:16,945 [main] INFO  org.apache.spark.util.SignalUtils [] - Registering signal handler for INT
2025-12-22T02:11:16,947 [main] INFO  org.apache.spark.SecurityManager [] - Changing view acls to: spark
2025-12-22T02:11:16,949 [main] INFO  org.apache.spark.SecurityManager [] - Changing modify acls to: spark
2025-12-22T02:11:16,953 [main] INFO  org.apache.spark.SecurityManager [] - Changing view acls groups to: 
2025-12-22T02:11:16,955 [main] INFO  org.apache.spark.SecurityManager [] - Changing modify acls groups to: 
2025-12-22T02:11:16,956 [main] INFO  org.apache.spark.SecurityManager [] - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
2025-12-22T02:11:17,025 [main] INFO  org.apache.spark.SecurityManager [] - Changing view acls to: spark
2025-12-22T02:11:17,026 [main] INFO  org.apache.spark.SecurityManager [] - Changing modify acls to: spark
2025-12-22T02:11:17,028 [main] INFO  org.apache.spark.SecurityManager [] - Changing view acls groups to: 
2025-12-22T02:11:17,030 [main] INFO  org.apache.spark.SecurityManager [] - Changing modify acls groups to: 
2025-12-22T02:11:17,030 [main] INFO  org.apache.spark.SecurityManager [] - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
2025-12-22T02:11:17,253 [main] WARN  org.apache.hadoop.util.NativeCodeLoader [] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2025-12-22T02:11:17,509 [main] WARN  org.apache.hadoop.util.NativeCodeLoader [] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2025-12-22T02:11:17,596 [main] INFO  org.apache.spark.SecurityManager [] - Changing view acls to: spark
2025-12-22T02:11:17,605 [main] INFO  org.apache.spark.SecurityManager [] - Changing modify acls to: spark
2025-12-22T02:11:17,609 [main] INFO  org.apache.spark.SecurityManager [] - Changing view acls groups to: 
2025-12-22T02:11:17,616 [main] INFO  org.apache.spark.SecurityManager [] - Changing modify acls groups to: 
2025-12-22T02:11:17,621 [main] INFO  org.apache.spark.SecurityManager [] - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
2025-12-22T02:11:17,655 [main] INFO  org.apache.spark.SecurityManager [] - Changing view acls to: spark
2025-12-22T02:11:17,657 [main] INFO  org.apache.spark.SecurityManager [] - Changing modify acls to: spark
2025-12-22T02:11:17,658 [main] INFO  org.apache.spark.SecurityManager [] - Changing view acls groups to: 
2025-12-22T02:11:17,660 [main] INFO  org.apache.spark.SecurityManager [] - Changing modify acls groups to: 
2025-12-22T02:11:17,661 [main] INFO  org.apache.spark.SecurityManager [] - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
2025-12-22T02:11:17,956 [main] WARN  org.apache.hadoop.util.NativeCodeLoader [] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2025-12-22T02:11:17,990 [main] WARN  org.apache.hadoop.util.NativeCodeLoader [] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2025-12-22T02:11:18,262 [main] INFO  org.apache.spark.util.Utils [] - Successfully started service 'sparkMaster' on port 7077.
2025-12-22T02:11:18,325 [dispatcher-event-loop-1] INFO  org.apache.spark.deploy.master.Master [] - Starting Spark master at spark://e78e7707373c:7077
2025-12-22T02:11:18,330 [main] INFO  org.apache.spark.util.Utils [] - Successfully started service 'sparkWorker' on port 42325.
2025-12-22T02:11:18,333 [main] INFO  org.apache.spark.deploy.worker.Worker [] - Worker decommissioning not enabled.
2025-12-22T02:11:18,336 [dispatcher-event-loop-1] INFO  org.apache.spark.deploy.master.Master [] - Running Spark version 3.5.0
2025-12-22T02:11:18,401 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.util.log [] - Logging initialized @4028ms to org.sparkproject.jetty.util.log.Slf4jLog
2025-12-22T02:11:18,459 [dispatcher-event-loop-1] INFO  org.apache.spark.ui.JettyUtils [] - Start Jetty 0.0.0.0:8080 for MasterUI
2025-12-22T02:11:18,482 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.Server [] - jetty-9.4.52.v20230823; built: 2023-08-23T19:29:37.669Z; git: abdcda73818a1a2c705da276edb0bf6581e7997e; jvm 17.0.10+13-LTS
2025-12-22T02:11:18,526 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.Server [] - Started @4154ms
2025-12-22T02:11:18,542 [main] INFO  org.apache.spark.util.Utils [] - Successfully started service 'sparkWorker' on port 37529.
2025-12-22T02:11:18,545 [main] INFO  org.apache.spark.deploy.worker.Worker [] - Worker decommissioning not enabled.
2025-12-22T02:11:18,607 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.AbstractConnector [] - Started ServerConnector@7825d88c{HTTP/1.1, (http/1.1)}{0.0.0.0:8080}
2025-12-22T02:11:18,607 [dispatcher-event-loop-1] INFO  org.apache.spark.util.Utils [] - Successfully started service 'MasterUI' on port 8080.
2025-12-22T02:11:18,655 [main] INFO  org.apache.spark.util.Utils [] - Successfully started service 'sparkWorker' on port 36353.
2025-12-22T02:11:18,659 [main] INFO  org.apache.spark.deploy.worker.Worker [] - Worker decommissioning not enabled.
2025-12-22T02:11:18,662 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@2a6b2ff6{/app,null,AVAILABLE,@Spark}
2025-12-22T02:11:18,667 [dispatcher-event-loop-1] INFO  org.apache.spark.deploy.worker.Worker [] - Starting Spark worker 172.20.0.4:42325 with 2 cores, 3.0 GiB RAM
2025-12-22T02:11:18,668 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@4fc197b4{/app/json,null,AVAILABLE,@Spark}
2025-12-22T02:11:18,671 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@3aca9f7a{/,null,AVAILABLE,@Spark}
2025-12-22T02:11:18,675 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@50b6963{/json,null,AVAILABLE,@Spark}
2025-12-22T02:11:18,681 [dispatcher-event-loop-1] INFO  org.apache.spark.deploy.worker.Worker [] - Running Spark version 3.5.0
2025-12-22T02:11:18,682 [dispatcher-event-loop-1] INFO  org.apache.spark.deploy.worker.Worker [] - Spark home: /opt/bitnami/spark
2025-12-22T02:11:18,691 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@3c3bf53a{/static,null,AVAILABLE,@Spark}
2025-12-22T02:11:18,695 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@388840c6{/app/kill,null,AVAILABLE,@Spark}
2025-12-22T02:11:18,699 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@2416fc60{/driver/kill,null,AVAILABLE,@Spark}
2025-12-22T02:11:18,702 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@9c45afa{/workers/kill,null,AVAILABLE,@Spark}
2025-12-22T02:11:18,709 [dispatcher-event-loop-1] INFO  org.apache.spark.deploy.master.ui.MasterWebUI [] - Bound MasterWebUI to 0.0.0.0, and started at http://e78e7707373c:8080
2025-12-22T02:11:18,713 [dispatcher-event-loop-1] INFO  org.apache.spark.resource.ResourceUtils [] - ==============================================================
2025-12-22T02:11:18,714 [dispatcher-event-loop-1] INFO  org.apache.spark.resource.ResourceUtils [] - No custom resources configured for spark.worker.
2025-12-22T02:11:18,714 [dispatcher-event-loop-1] INFO  org.apache.spark.resource.ResourceUtils [] - ==============================================================
2025-12-22T02:11:18,782 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.util.log [] - Logging initialized @4266ms to org.sparkproject.jetty.util.log.Slf4jLog
2025-12-22T02:11:18,861 [dispatcher-event-loop-1] INFO  org.apache.spark.ui.JettyUtils [] - Start Jetty 0.0.0.0:8081 for WorkerUI
2025-12-22T02:11:18,887 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.Server [] - jetty-9.4.52.v20230823; built: 2023-08-23T19:29:37.669Z; git: abdcda73818a1a2c705da276edb0bf6581e7997e; jvm 17.0.10+13-LTS
2025-12-22T02:11:18,896 [dispatcher-event-loop-1] INFO  org.apache.spark.deploy.worker.Worker [] - Starting Spark worker 172.20.0.5:37529 with 2 cores, 3.0 GiB RAM
2025-12-22T02:11:18,904 [dispatcher-event-loop-1] INFO  org.apache.spark.deploy.worker.Worker [] - Running Spark version 3.5.0
2025-12-22T02:11:18,905 [dispatcher-event-loop-1] INFO  org.apache.spark.deploy.worker.Worker [] - Spark home: /opt/bitnami/spark
2025-12-22T02:11:18,928 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.Server [] - Started @4413ms
2025-12-22T02:11:18,932 [dispatcher-event-loop-1] INFO  org.apache.spark.resource.ResourceUtils [] - ==============================================================
2025-12-22T02:11:18,933 [dispatcher-event-loop-1] INFO  org.apache.spark.resource.ResourceUtils [] - No custom resources configured for spark.worker.
2025-12-22T02:11:18,935 [dispatcher-event-loop-1] INFO  org.apache.spark.resource.ResourceUtils [] - ==============================================================
2025-12-22T02:11:18,976 [dispatcher-event-loop-2] INFO  org.apache.spark.deploy.worker.Worker [] - Starting Spark worker 172.20.0.6:36353 with 2 cores, 3.0 GiB RAM
2025-12-22T02:11:18,985 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@2c0ef529{/metrics/master/json,null,AVAILABLE,@Spark}
2025-12-22T02:11:18,989 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@160dda07{/metrics/applications/json,null,AVAILABLE,@Spark}
2025-12-22T02:11:18,989 [dispatcher-event-loop-2] INFO  org.apache.spark.deploy.worker.Worker [] - Running Spark version 3.5.0
2025-12-22T02:11:18,990 [dispatcher-event-loop-2] INFO  org.apache.spark.deploy.worker.Worker [] - Spark home: /opt/bitnami/spark
2025-12-22T02:11:18,994 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.AbstractConnector [] - Started ServerConnector@6168db18{HTTP/1.1, (http/1.1)}{0.0.0.0:8081}
2025-12-22T02:11:18,995 [dispatcher-event-loop-1] INFO  org.apache.spark.util.Utils [] - Successfully started service 'WorkerUI' on port 8081.
2025-12-22T02:11:19,012 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.util.log [] - Logging initialized @4418ms to org.sparkproject.jetty.util.log.Slf4jLog
2025-12-22T02:11:19,020 [dispatcher-event-loop-1] INFO  org.apache.spark.deploy.master.Master [] - I have been elected leader! New state: ALIVE
2025-12-22T02:11:19,024 [dispatcher-event-loop-2] INFO  org.apache.spark.resource.ResourceUtils [] - ==============================================================
2025-12-22T02:11:19,025 [dispatcher-event-loop-2] INFO  org.apache.spark.resource.ResourceUtils [] - No custom resources configured for spark.worker.
2025-12-22T02:11:19,026 [dispatcher-event-loop-2] INFO  org.apache.spark.resource.ResourceUtils [] - ==============================================================
2025-12-22T02:11:19,039 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@43c46750{/logPage,null,AVAILABLE,@Spark}
2025-12-22T02:11:19,045 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@745d3b01{/logPage/json,null,AVAILABLE,@Spark}
2025-12-22T02:11:19,047 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@45e51fb6{/,null,AVAILABLE,@Spark}
2025-12-22T02:11:19,050 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@3477d0e8{/json,null,AVAILABLE,@Spark}
2025-12-22T02:11:19,062 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@6ca9b2fd{/static,null,AVAILABLE,@Spark}
2025-12-22T02:11:19,064 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@5fa93ca{/log,null,AVAILABLE,@Spark}
2025-12-22T02:11:19,066 [dispatcher-event-loop-1] INFO  org.apache.spark.deploy.worker.ui.WorkerWebUI [] - Bound WorkerWebUI to 0.0.0.0, and started at http://e7f2b1a13d24:8081
2025-12-22T02:11:19,072 [worker-register-master-threadpool-0] INFO  org.apache.spark.deploy.worker.Worker [] - Connecting to master spark-master:7077...
2025-12-22T02:11:19,096 [dispatcher-event-loop-2] INFO  org.sparkproject.jetty.util.log [] - Logging initialized @4451ms to org.sparkproject.jetty.util.log.Slf4jLog
2025-12-22T02:11:19,110 [dispatcher-event-loop-1] INFO  org.apache.spark.ui.JettyUtils [] - Start Jetty 0.0.0.0:8081 for WorkerUI
2025-12-22T02:11:19,109 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@422745ff{/metrics/json,null,AVAILABLE,@Spark}
2025-12-22T02:11:19,153 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.Server [] - jetty-9.4.52.v20230823; built: 2023-08-23T19:29:37.669Z; git: abdcda73818a1a2c705da276edb0bf6581e7997e; jvm 17.0.10+13-LTS
2025-12-22T02:11:19,181 [dispatcher-event-loop-2] INFO  org.apache.spark.ui.JettyUtils [] - Start Jetty 0.0.0.0:8081 for WorkerUI
2025-12-22T02:11:19,186 [netty-rpc-connection-0] INFO  org.apache.spark.network.client.TransportClientFactory [] - Successfully created connection to spark-master/172.20.0.3:7077 after 56 ms (0 ms spent in bootstraps)
2025-12-22T02:11:19,188 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.Server [] - Started @4598ms
2025-12-22T02:11:19,211 [dispatcher-event-loop-2] INFO  org.sparkproject.jetty.server.Server [] - jetty-9.4.52.v20230823; built: 2023-08-23T19:29:37.669Z; git: abdcda73818a1a2c705da276edb0bf6581e7997e; jvm 17.0.10+13-LTS
2025-12-22T02:11:19,262 [dispatcher-event-loop-2] INFO  org.sparkproject.jetty.server.Server [] - Started @4619ms
2025-12-22T02:11:19,265 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.AbstractConnector [] - Started ServerConnector@2a3c68b8{HTTP/1.1, (http/1.1)}{0.0.0.0:8081}
2025-12-22T02:11:19,266 [dispatcher-event-loop-1] INFO  org.apache.spark.util.Utils [] - Successfully started service 'WorkerUI' on port 8081.
2025-12-22T02:11:19,305 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@2d210f40{/logPage,null,AVAILABLE,@Spark}
2025-12-22T02:11:19,313 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@14239357{/logPage/json,null,AVAILABLE,@Spark}
2025-12-22T02:11:19,315 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@e10bc8f{/,null,AVAILABLE,@Spark}
2025-12-22T02:11:19,319 [dispatcher-event-loop-2] INFO  org.sparkproject.jetty.server.AbstractConnector [] - Started ServerConnector@70cd65c8{HTTP/1.1, (http/1.1)}{0.0.0.0:8081}
2025-12-22T02:11:19,320 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@5f984594{/json,null,AVAILABLE,@Spark}
2025-12-22T02:11:19,320 [dispatcher-event-loop-2] INFO  org.apache.spark.util.Utils [] - Successfully started service 'WorkerUI' on port 8081.
2025-12-22T02:11:19,335 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@5b8b856d{/static,null,AVAILABLE,@Spark}
2025-12-22T02:11:19,339 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@39b6b4d3{/log,null,AVAILABLE,@Spark}
2025-12-22T02:11:19,345 [dispatcher-event-loop-1] INFO  org.apache.spark.deploy.worker.ui.WorkerWebUI [] - Bound WorkerWebUI to 0.0.0.0, and started at http://b7a722371209:8081
2025-12-22T02:11:19,349 [worker-register-master-threadpool-0] INFO  org.apache.spark.deploy.worker.Worker [] - Connecting to master spark-master:7077...
2025-12-22T02:11:19,364 [dispatcher-event-loop-2] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@1ce4728f{/logPage,null,AVAILABLE,@Spark}
2025-12-22T02:11:19,371 [dispatcher-event-loop-2] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@6fb49b21{/logPage/json,null,AVAILABLE,@Spark}
2025-12-22T02:11:19,375 [dispatcher-event-loop-2] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@45582497{/,null,AVAILABLE,@Spark}
2025-12-22T02:11:19,378 [dispatcher-event-loop-2] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@1a003d8e{/json,null,AVAILABLE,@Spark}
2025-12-22T02:11:19,380 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@50872cf1{/metrics/json,null,AVAILABLE,@Spark}
2025-12-22T02:11:19,396 [dispatcher-event-loop-2] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@666a61d8{/static,null,AVAILABLE,@Spark}
2025-12-22T02:11:19,398 [dispatcher-event-loop-7] INFO  org.apache.spark.deploy.master.Master [] - Registering worker 172.20.0.4:42325 with 2 cores, 3.0 GiB RAM
2025-12-22T02:11:19,398 [dispatcher-event-loop-2] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@587d010f{/log,null,AVAILABLE,@Spark}
2025-12-22T02:11:19,402 [dispatcher-event-loop-2] INFO  org.apache.spark.deploy.worker.ui.WorkerWebUI [] - Bound WorkerWebUI to 0.0.0.0, and started at http://74f89a3203f2:8081
2025-12-22T02:11:19,405 [worker-register-master-threadpool-0] INFO  org.apache.spark.deploy.worker.Worker [] - Connecting to master spark-master:7077...
2025-12-22T02:11:19,422 [dispatcher-event-loop-5] INFO  org.apache.spark.deploy.worker.Worker [] - Successfully registered with master spark://e78e7707373c:7077
2025-12-22T02:11:19,435 [dispatcher-event-loop-2] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@1646a7ef{/metrics/json,null,AVAILABLE,@Spark}
2025-12-22T02:11:19,441 [netty-rpc-connection-0] INFO  org.apache.spark.network.client.TransportClientFactory [] - Successfully created connection to spark-master/172.20.0.3:7077 after 52 ms (0 ms spent in bootstraps)
2025-12-22T02:11:19,483 [netty-rpc-connection-0] INFO  org.apache.spark.network.client.TransportClientFactory [] - Successfully created connection to spark-master/172.20.0.3:7077 after 40 ms (0 ms spent in bootstraps)
2025-12-22T02:11:19,523 [dispatcher-event-loop-6] INFO  org.apache.spark.deploy.master.Master [] - Registering worker 172.20.0.5:37529 with 2 cores, 3.0 GiB RAM
2025-12-22T02:11:19,536 [dispatcher-event-loop-6] INFO  org.apache.spark.deploy.worker.Worker [] - Successfully registered with master spark://e78e7707373c:7077
2025-12-22T02:11:19,568 [dispatcher-event-loop-11] INFO  org.apache.spark.deploy.master.Master [] - Registering worker 172.20.0.6:36353 with 2 cores, 3.0 GiB RAM
2025-12-22T02:11:19,581 [dispatcher-event-loop-6] INFO  org.apache.spark.deploy.worker.Worker [] - Successfully registered with master spark://e78e7707373c:7077
2025-12-22T02:12:51,186 [Thread-4] INFO  org.apache.spark.SparkContext [] - Running Spark version 3.5.0
2025-12-22T02:12:51,190 [Thread-4] INFO  org.apache.spark.SparkContext [] - OS info Linux, 6.6.87.1-microsoft-standard-WSL2, amd64
2025-12-22T02:12:51,191 [Thread-4] INFO  org.apache.spark.SparkContext [] - Java version 17.0.10
2025-12-22T02:12:51,212 [Thread-4] INFO  org.apache.spark.resource.ResourceUtils [] - ==============================================================
2025-12-22T02:12:51,213 [Thread-4] INFO  org.apache.spark.resource.ResourceUtils [] - No custom resources configured for spark.driver.
2025-12-22T02:12:51,214 [Thread-4] INFO  org.apache.spark.resource.ResourceUtils [] - ==============================================================
2025-12-22T02:12:51,214 [Thread-4] INFO  org.apache.spark.SparkContext [] - Submitted application: etl-rides-json
2025-12-22T02:12:51,231 [Thread-4] INFO  org.apache.spark.resource.ResourceProfile [] - Default ResourceProfile created, executor resources: Map(memory -> name: memory, amount: 3072, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
2025-12-22T02:12:51,236 [Thread-4] INFO  org.apache.spark.resource.ResourceProfile [] - Limiting resource is cpu
2025-12-22T02:12:51,238 [Thread-4] INFO  org.apache.spark.resource.ResourceProfileManager [] - Added ResourceProfile id: 0
2025-12-22T02:12:51,283 [Thread-4] INFO  org.apache.spark.SecurityManager [] - Changing view acls to: root,spark
2025-12-22T02:12:51,284 [Thread-4] INFO  org.apache.spark.SecurityManager [] - Changing modify acls to: root,spark
2025-12-22T02:12:51,285 [Thread-4] INFO  org.apache.spark.SecurityManager [] - Changing view acls groups to: 
2025-12-22T02:12:51,285 [Thread-4] INFO  org.apache.spark.SecurityManager [] - Changing modify acls groups to: 
2025-12-22T02:12:51,286 [Thread-4] INFO  org.apache.spark.SecurityManager [] - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, spark; groups with view permissions: EMPTY; users with modify permissions: root, spark; groups with modify permissions: EMPTY
2025-12-22T02:12:51,329 [Thread-4] WARN  org.apache.hadoop.util.NativeCodeLoader [] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2025-12-22T02:12:51,564 [Thread-4] INFO  org.apache.spark.util.Utils [] - Successfully started service 'sparkDriver' on port 44703.
2025-12-22T02:12:51,590 [Thread-4] INFO  org.apache.spark.SparkEnv [] - Registering MapOutputTracker
2025-12-22T02:12:51,631 [Thread-4] INFO  org.apache.spark.SparkEnv [] - Registering BlockManagerMaster
2025-12-22T02:12:51,643 [Thread-4] INFO  org.apache.spark.storage.BlockManagerMasterEndpoint [] - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2025-12-22T02:12:51,644 [Thread-4] INFO  org.apache.spark.storage.BlockManagerMasterEndpoint [] - BlockManagerMasterEndpoint up
2025-12-22T02:12:51,648 [Thread-4] INFO  org.apache.spark.SparkEnv [] - Registering BlockManagerMasterHeartbeat
2025-12-22T02:12:51,669 [Thread-4] INFO  org.apache.spark.storage.DiskBlockManager [] - Created local directory at /tmp/blockmgr-ccc0c8bc-e3e0-4bdc-a674-5794114b5b50
2025-12-22T02:12:51,682 [Thread-4] INFO  org.apache.spark.storage.memory.MemoryStore [] - MemoryStore started with capacity 434.4 MiB
2025-12-22T02:12:51,703 [Thread-4] INFO  org.apache.spark.SparkEnv [] - Registering OutputCommitCoordinator
2025-12-22T02:12:51,742 [Thread-4] INFO  org.sparkproject.jetty.util.log [] - Logging initialized @2246ms to org.sparkproject.jetty.util.log.Slf4jLog
2025-12-22T02:12:51,804 [Thread-4] INFO  org.apache.spark.ui.JettyUtils [] - Start Jetty 0.0.0.0:4040 for SparkUI
2025-12-22T02:12:51,816 [Thread-4] INFO  org.sparkproject.jetty.server.Server [] - jetty-9.4.52.v20230823; built: 2023-08-23T19:29:37.669Z; git: abdcda73818a1a2c705da276edb0bf6581e7997e; jvm 17.0.10+13-LTS
2025-12-22T02:12:51,836 [Thread-4] INFO  org.sparkproject.jetty.server.Server [] - Started @2340ms
2025-12-22T02:12:51,865 [Thread-4] INFO  org.sparkproject.jetty.server.AbstractConnector [] - Started ServerConnector@2d0e4a66{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2025-12-22T02:12:51,865 [Thread-4] INFO  org.apache.spark.util.Utils [] - Successfully started service 'SparkUI' on port 4040.
2025-12-22T02:12:51,887 [Thread-4] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@5252459a{/,null,AVAILABLE,@Spark}
2025-12-22T02:12:51,974 [appclient-register-master-threadpool-0] INFO  org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint [] - Connecting to master spark://spark-master:7077...
2025-12-22T02:12:52,017 [netty-rpc-connection-0] INFO  org.apache.spark.network.client.TransportClientFactory [] - Successfully created connection to spark-master/172.20.0.3:7077 after 18 ms (0 ms spent in bootstraps)
2025-12-22T02:12:52,137 [dispatcher-event-loop-12] INFO  org.apache.spark.deploy.master.Master [] - Registering app etl-rides-json
2025-12-22T02:12:52,158 [dispatcher-event-loop-12] INFO  org.apache.spark.deploy.master.Master [] - Registered app etl-rides-json with ID app-20251222021252-0000
2025-12-22T02:12:52,162 [dispatcher-event-loop-12] INFO  org.apache.spark.deploy.master.Master [] - Start scheduling for app app-20251222021252-0000 with rpId: 0
2025-12-22T02:12:52,166 [dispatcher-event-loop-10] INFO  org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend [] - Connected to Spark cluster with app ID app-20251222021252-0000
2025-12-22T02:12:52,177 [Thread-4] INFO  org.apache.spark.util.Utils [] - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 41515.
2025-12-22T02:12:52,178 [Thread-4] INFO  org.apache.spark.network.netty.NettyBlockTransferService [] - Server created on e78e7707373c:41515
2025-12-22T02:12:52,180 [Thread-4] INFO  org.apache.spark.storage.BlockManager [] - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2025-12-22T02:12:52,187 [dispatcher-event-loop-12] INFO  org.apache.spark.deploy.master.Master [] - Launching executor app-20251222021252-0000/0 on worker worker-20251222021118-172.20.0.4-42325
2025-12-22T02:12:52,188 [Thread-4] INFO  org.apache.spark.storage.BlockManagerMaster [] - Registering BlockManager BlockManagerId(driver, e78e7707373c, 41515, None)
2025-12-22T02:12:52,192 [dispatcher-BlockManagerMaster] INFO  org.apache.spark.storage.BlockManagerMasterEndpoint [] - Registering block manager e78e7707373c:41515 with 434.4 MiB RAM, BlockManagerId(driver, e78e7707373c, 41515, None)
2025-12-22T02:12:52,194 [Thread-4] INFO  org.apache.spark.storage.BlockManagerMaster [] - Registered BlockManager BlockManagerId(driver, e78e7707373c, 41515, None)
2025-12-22T02:12:52,196 [Thread-4] INFO  org.apache.spark.storage.BlockManager [] - Initialized BlockManager: BlockManagerId(driver, e78e7707373c, 41515, None)
2025-12-22T02:12:52,198 [dispatcher-event-loop-12] INFO  org.apache.spark.deploy.master.Master [] - Launching executor app-20251222021252-0000/1 on worker worker-20251222021118-172.20.0.5-37529
2025-12-22T02:12:52,199 [dispatcher-event-loop-12] INFO  org.apache.spark.deploy.master.Master [] - Launching executor app-20251222021252-0000/2 on worker worker-20251222021118-172.20.0.6-36353
2025-12-22T02:12:52,203 [dispatcher-event-loop-2] INFO  org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint [] - Executor added: app-20251222021252-0000/0 on worker-20251222021118-172.20.0.4-42325 (172.20.0.4:42325) with 2 core(s)
2025-12-22T02:12:52,206 [dispatcher-event-loop-2] INFO  org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend [] - Granted executor ID app-20251222021252-0000/0 on hostPort 172.20.0.4:42325 with 2 core(s), 3.0 GiB RAM
2025-12-22T02:12:52,207 [dispatcher-event-loop-2] INFO  org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint [] - Executor added: app-20251222021252-0000/1 on worker-20251222021118-172.20.0.5-37529 (172.20.0.5:37529) with 2 core(s)
2025-12-22T02:12:52,208 [dispatcher-event-loop-2] INFO  org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend [] - Granted executor ID app-20251222021252-0000/1 on hostPort 172.20.0.5:37529 with 2 core(s), 3.0 GiB RAM
2025-12-22T02:12:52,208 [dispatcher-event-loop-2] INFO  org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint [] - Executor added: app-20251222021252-0000/2 on worker-20251222021118-172.20.0.6-36353 (172.20.0.6:36353) with 2 core(s)
2025-12-22T02:12:52,208 [dispatcher-event-loop-2] INFO  org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend [] - Granted executor ID app-20251222021252-0000/2 on hostPort 172.20.0.6:36353 with 2 core(s), 3.0 GiB RAM
2025-12-22T02:12:52,279 [dispatcher-event-loop-0] INFO  org.apache.spark.deploy.worker.Worker [] - Asked to launch executor app-20251222021252-0000/0 for etl-rides-json
2025-12-22T02:12:52,288 [dispatcher-event-loop-0] INFO  org.apache.spark.deploy.worker.Worker [] - Asked to launch executor app-20251222021252-0000/1 for etl-rides-json
2025-12-22T02:12:52,291 [dispatcher-event-loop-0] INFO  org.apache.spark.deploy.worker.Worker [] - Asked to launch executor app-20251222021252-0000/2 for etl-rides-json
2025-12-22T02:12:52,333 [ExecutorRunner for app-20251222021252-0000/1] INFO  org.apache.spark.SecurityManager [] - Changing view acls to: spark
2025-12-22T02:12:52,334 [ExecutorRunner for app-20251222021252-0000/1] INFO  org.apache.spark.SecurityManager [] - Changing modify acls to: spark
2025-12-22T02:12:52,334 [ExecutorRunner for app-20251222021252-0000/1] INFO  org.apache.spark.SecurityManager [] - Changing view acls groups to: 
2025-12-22T02:12:52,334 [ExecutorRunner for app-20251222021252-0000/1] INFO  org.apache.spark.SecurityManager [] - Changing modify acls groups to: 
2025-12-22T02:12:52,335 [ExecutorRunner for app-20251222021252-0000/1] INFO  org.apache.spark.SecurityManager [] - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
2025-12-22T02:12:52,341 [ExecutorRunner for app-20251222021252-0000/0] INFO  org.apache.spark.SecurityManager [] - Changing view acls to: spark
2025-12-22T02:12:52,341 [ExecutorRunner for app-20251222021252-0000/0] INFO  org.apache.spark.SecurityManager [] - Changing modify acls to: spark
2025-12-22T02:12:52,342 [ExecutorRunner for app-20251222021252-0000/0] INFO  org.apache.spark.SecurityManager [] - Changing view acls groups to: 
2025-12-22T02:12:52,342 [ExecutorRunner for app-20251222021252-0000/0] INFO  org.apache.spark.SecurityManager [] - Changing modify acls groups to: 
2025-12-22T02:12:52,342 [ExecutorRunner for app-20251222021252-0000/0] INFO  org.apache.spark.SecurityManager [] - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
2025-12-22T02:12:52,349 [ExecutorRunner for app-20251222021252-0000/2] INFO  org.apache.spark.SecurityManager [] - Changing view acls to: spark
2025-12-22T02:12:52,349 [ExecutorRunner for app-20251222021252-0000/2] INFO  org.apache.spark.SecurityManager [] - Changing modify acls to: spark
2025-12-22T02:12:52,349 [ExecutorRunner for app-20251222021252-0000/2] INFO  org.apache.spark.SecurityManager [] - Changing view acls groups to: 
2025-12-22T02:12:52,349 [ExecutorRunner for app-20251222021252-0000/2] INFO  org.apache.spark.SecurityManager [] - Changing modify acls groups to: 
2025-12-22T02:12:52,350 [ExecutorRunner for app-20251222021252-0000/2] INFO  org.apache.spark.SecurityManager [] - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
2025-12-22T02:12:52,376 [ExecutorRunner for app-20251222021252-0000/0] INFO  org.apache.spark.deploy.worker.ExecutorRunner [] - Launch command: "/opt/bitnami/java/bin/java" "-cp" "/opt/bitnami/spark/conf/:/opt/bitnami/spark/jars/*" "-Xmx3072M" "-Dspark.driver.port=44703" "-Djava.net.preferIPv6Addresses=false" "-XX:+IgnoreUnrecognizedVMOptions" "--add-opens=java.base/java.lang=ALL-UNNAMED" "--add-opens=java.base/java.lang.invoke=ALL-UNNAMED" "--add-opens=java.base/java.lang.reflect=ALL-UNNAMED" "--add-opens=java.base/java.io=ALL-UNNAMED" "--add-opens=java.base/java.net=ALL-UNNAMED" "--add-opens=java.base/java.nio=ALL-UNNAMED" "--add-opens=java.base/java.util=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED" "--add-opens=java.base/sun.nio.ch=ALL-UNNAMED" "--add-opens=java.base/sun.nio.cs=ALL-UNNAMED" "--add-opens=java.base/sun.security.action=ALL-UNNAMED" "--add-opens=java.base/sun.util.calendar=ALL-UNNAMED" "--add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED" "-Djdk.reflect.useDirectMethodHandle=false" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@e78e7707373c:44703" "--executor-id" "0" "--hostname" "172.20.0.4" "--cores" "2" "--app-id" "app-20251222021252-0000" "--worker-url" "spark://Worker@172.20.0.4:42325" "--resourceProfileId" "0"
2025-12-22T02:12:52,390 [ExecutorRunner for app-20251222021252-0000/1] INFO  org.apache.spark.deploy.worker.ExecutorRunner [] - Launch command: "/opt/bitnami/java/bin/java" "-cp" "/opt/bitnami/spark/conf/:/opt/bitnami/spark/jars/*" "-Xmx3072M" "-Dspark.driver.port=44703" "-Djava.net.preferIPv6Addresses=false" "-XX:+IgnoreUnrecognizedVMOptions" "--add-opens=java.base/java.lang=ALL-UNNAMED" "--add-opens=java.base/java.lang.invoke=ALL-UNNAMED" "--add-opens=java.base/java.lang.reflect=ALL-UNNAMED" "--add-opens=java.base/java.io=ALL-UNNAMED" "--add-opens=java.base/java.net=ALL-UNNAMED" "--add-opens=java.base/java.nio=ALL-UNNAMED" "--add-opens=java.base/java.util=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED" "--add-opens=java.base/sun.nio.ch=ALL-UNNAMED" "--add-opens=java.base/sun.nio.cs=ALL-UNNAMED" "--add-opens=java.base/sun.security.action=ALL-UNNAMED" "--add-opens=java.base/sun.util.calendar=ALL-UNNAMED" "--add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED" "-Djdk.reflect.useDirectMethodHandle=false" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@e78e7707373c:44703" "--executor-id" "1" "--hostname" "172.20.0.5" "--cores" "2" "--app-id" "app-20251222021252-0000" "--worker-url" "spark://Worker@172.20.0.5:37529" "--resourceProfileId" "0"
2025-12-22T02:12:52,401 [ExecutorRunner for app-20251222021252-0000/2] INFO  org.apache.spark.deploy.worker.ExecutorRunner [] - Launch command: "/opt/bitnami/java/bin/java" "-cp" "/opt/bitnami/spark/conf/:/opt/bitnami/spark/jars/*" "-Xmx3072M" "-Dspark.driver.port=44703" "-Djava.net.preferIPv6Addresses=false" "-XX:+IgnoreUnrecognizedVMOptions" "--add-opens=java.base/java.lang=ALL-UNNAMED" "--add-opens=java.base/java.lang.invoke=ALL-UNNAMED" "--add-opens=java.base/java.lang.reflect=ALL-UNNAMED" "--add-opens=java.base/java.io=ALL-UNNAMED" "--add-opens=java.base/java.net=ALL-UNNAMED" "--add-opens=java.base/java.nio=ALL-UNNAMED" "--add-opens=java.base/java.util=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED" "--add-opens=java.base/sun.nio.ch=ALL-UNNAMED" "--add-opens=java.base/sun.nio.cs=ALL-UNNAMED" "--add-opens=java.base/sun.security.action=ALL-UNNAMED" "--add-opens=java.base/sun.util.calendar=ALL-UNNAMED" "--add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED" "-Djdk.reflect.useDirectMethodHandle=false" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@e78e7707373c:44703" "--executor-id" "2" "--hostname" "172.20.0.6" "--cores" "2" "--app-id" "app-20251222021252-0000" "--worker-url" "spark://Worker@172.20.0.6:36353" "--resourceProfileId" "0"
2025-12-22T02:12:52,428 [dispatcher-event-loop-11] INFO  org.apache.spark.deploy.master.Master [] - Start scheduling for app app-20251222021252-0000 with rpId: 0
2025-12-22T02:12:52,449 [dispatcher-event-loop-13] INFO  org.apache.spark.deploy.master.Master [] - Start scheduling for app app-20251222021252-0000 with rpId: 0
2025-12-22T02:12:52,457 [dispatcher-event-loop-2] INFO  org.apache.spark.deploy.master.Master [] - Start scheduling for app app-20251222021252-0000 with rpId: 0
2025-12-22T02:12:52,469 [dispatcher-event-loop-9] INFO  org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint [] - Executor updated: app-20251222021252-0000/0 is now RUNNING
2025-12-22T02:12:52,470 [dispatcher-event-loop-9] INFO  org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint [] - Executor updated: app-20251222021252-0000/2 is now RUNNING
2025-12-22T02:12:52,471 [dispatcher-event-loop-9] INFO  org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint [] - Executor updated: app-20251222021252-0000/1 is now RUNNING
2025-12-22T02:12:52,537 [Thread-4] INFO  org.apache.spark.deploy.history.SingleEventLogFileWriter [] - Logging events to file:/opt/bitnami/spark/logs/events/app-20251222021252-0000.inprogress
2025-12-22T02:12:52,768 [Thread-4] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Stopped o.s.j.s.ServletContextHandler@5252459a{/,null,STOPPED,@Spark}
2025-12-22T02:12:52,771 [Thread-4] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@110304b1{/jobs,null,AVAILABLE,@Spark}
2025-12-22T02:12:52,773 [Thread-4] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@571b6d5{/jobs/json,null,AVAILABLE,@Spark}
2025-12-22T02:12:52,774 [Thread-4] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@1c950ceb{/jobs/job,null,AVAILABLE,@Spark}
2025-12-22T02:12:52,777 [Thread-4] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@682e66e1{/jobs/job/json,null,AVAILABLE,@Spark}
2025-12-22T02:12:52,778 [Thread-4] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@1ecd30ae{/stages,null,AVAILABLE,@Spark}
2025-12-22T02:12:52,781 [Thread-4] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@6ed9d575{/stages/json,null,AVAILABLE,@Spark}
2025-12-22T02:12:52,785 [Thread-4] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@682d6801{/stages/stage,null,AVAILABLE,@Spark}
2025-12-22T02:12:52,789 [Thread-4] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@58f0ca17{/stages/stage/json,null,AVAILABLE,@Spark}
2025-12-22T02:12:52,791 [Thread-4] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@7ad05966{/stages/pool,null,AVAILABLE,@Spark}
2025-12-22T02:12:52,792 [Thread-4] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@2c543880{/stages/pool/json,null,AVAILABLE,@Spark}
2025-12-22T02:12:52,794 [Thread-4] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@5fdb6789{/storage,null,AVAILABLE,@Spark}
2025-12-22T02:12:52,795 [Thread-4] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@77eca040{/storage/json,null,AVAILABLE,@Spark}
2025-12-22T02:12:52,797 [Thread-4] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@14db5e64{/storage/rdd,null,AVAILABLE,@Spark}
2025-12-22T02:12:52,798 [Thread-4] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@741975c2{/storage/rdd/json,null,AVAILABLE,@Spark}
2025-12-22T02:12:52,800 [Thread-4] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@6e359bb8{/environment,null,AVAILABLE,@Spark}
2025-12-22T02:12:52,801 [Thread-4] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@1e28dd44{/environment/json,null,AVAILABLE,@Spark}
2025-12-22T02:12:52,802 [Thread-4] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@62226ec2{/executors,null,AVAILABLE,@Spark}
2025-12-22T02:12:52,808 [Thread-4] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@1b671824{/executors/json,null,AVAILABLE,@Spark}
2025-12-22T02:12:52,811 [Thread-4] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@c6526b5{/executors/threadDump,null,AVAILABLE,@Spark}
2025-12-22T02:12:52,813 [Thread-4] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@5489021{/executors/threadDump/json,null,AVAILABLE,@Spark}
2025-12-22T02:12:52,815 [Thread-4] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@5d9d9784{/executors/heapHistogram,null,AVAILABLE,@Spark}
2025-12-22T02:12:52,816 [Thread-4] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@52c17fa9{/executors/heapHistogram/json,null,AVAILABLE,@Spark}
2025-12-22T02:12:52,833 [Thread-4] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@59b66532{/static,null,AVAILABLE,@Spark}
2025-12-22T02:12:52,835 [Thread-4] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@1a2b0933{/,null,AVAILABLE,@Spark}
2025-12-22T02:12:52,841 [Thread-4] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@7207d9e{/api,null,AVAILABLE,@Spark}
2025-12-22T02:12:52,842 [Thread-4] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@35146ee8{/jobs/job/kill,null,AVAILABLE,@Spark}
2025-12-22T02:12:52,844 [Thread-4] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@36abbac5{/stages/stage/kill,null,AVAILABLE,@Spark}
2025-12-22T02:12:52,855 [Thread-4] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@34c7ad6b{/metrics/json,null,AVAILABLE,@Spark}
2025-12-22T02:12:52,857 [Thread-4] INFO  org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend [] - SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
2025-12-22T02:12:53,243 [Thread-4] INFO  org.apache.spark.sql.internal.SharedState [] - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
2025-12-22T02:12:53,249 [Thread-4] INFO  org.apache.spark.sql.internal.SharedState [] - Warehouse path is 'file:/opt/bitnami/spark/spark-warehouse'.
2025-12-22T02:12:53,272 [Thread-4] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@c4f066b{/SQL,null,AVAILABLE,@Spark}
2025-12-22T02:12:53,275 [Thread-4] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@54573aa7{/SQL/json,null,AVAILABLE,@Spark}
2025-12-22T02:12:53,276 [Thread-4] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@2e173cca{/SQL/execution,null,AVAILABLE,@Spark}
2025-12-22T02:12:53,278 [Thread-4] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@2cb6c37e{/SQL/execution/json,null,AVAILABLE,@Spark}
2025-12-22T02:12:53,281 [Thread-4] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@42b5af77{/static/sql,null,AVAILABLE,@Spark}
2025-12-22T02:12:53,886 [main] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend [] - Started daemon with process name: 149@e7f2b1a13d24
2025-12-22T02:12:53,895 [main] INFO  org.apache.spark.util.SignalUtils [] - Registering signal handler for TERM
2025-12-22T02:12:53,896 [main] INFO  org.apache.spark.util.SignalUtils [] - Registering signal handler for HUP
2025-12-22T02:12:53,897 [main] INFO  org.apache.spark.util.SignalUtils [] - Registering signal handler for INT
2025-12-22T02:12:53,918 [main] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend [] - Started daemon with process name: 150@b7a722371209
2025-12-22T02:12:53,931 [main] INFO  org.apache.spark.util.SignalUtils [] - Registering signal handler for TERM
2025-12-22T02:12:53,934 [main] INFO  org.apache.spark.util.SignalUtils [] - Registering signal handler for HUP
2025-12-22T02:12:53,935 [main] INFO  org.apache.spark.util.SignalUtils [] - Registering signal handler for INT
2025-12-22T02:12:54,006 [main] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend [] - Started daemon with process name: 149@74f89a3203f2
2025-12-22T02:12:54,022 [main] INFO  org.apache.spark.util.SignalUtils [] - Registering signal handler for TERM
2025-12-22T02:12:54,024 [main] INFO  org.apache.spark.util.SignalUtils [] - Registering signal handler for HUP
2025-12-22T02:12:54,024 [main] INFO  org.apache.spark.util.SignalUtils [] - Registering signal handler for INT
2025-12-22T02:12:54,520 [main] WARN  org.apache.hadoop.util.NativeCodeLoader [] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2025-12-22T02:12:54,535 [main] WARN  org.apache.hadoop.util.NativeCodeLoader [] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2025-12-22T02:12:54,690 [Thread-4] WARN  org.apache.hadoop.metrics2.impl.MetricsConfig [] - Cannot locate configuration: tried hadoop-metrics2-s3a-file-system.properties,hadoop-metrics2.properties
2025-12-22T02:12:54,723 [Thread-4] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl [] - Scheduled Metric snapshot period at 10 second(s).
2025-12-22T02:12:54,723 [Thread-4] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl [] - s3a-file-system metrics system started
2025-12-22T02:12:54,723 [main] WARN  org.apache.hadoop.util.NativeCodeLoader [] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2025-12-22T02:12:54,773 [main] INFO  org.apache.spark.SecurityManager [] - Changing view acls to: spark
2025-12-22T02:12:54,776 [main] INFO  org.apache.spark.SecurityManager [] - Changing modify acls to: spark
2025-12-22T02:12:54,779 [main] INFO  org.apache.spark.SecurityManager [] - Changing view acls groups to: 
2025-12-22T02:12:54,781 [main] INFO  org.apache.spark.SecurityManager [] - Changing modify acls groups to: 
2025-12-22T02:12:54,782 [main] INFO  org.apache.spark.SecurityManager [] - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
2025-12-22T02:12:54,861 [main] INFO  org.apache.spark.SecurityManager [] - Changing view acls to: spark
2025-12-22T02:12:54,863 [main] INFO  org.apache.spark.SecurityManager [] - Changing modify acls to: spark
2025-12-22T02:12:54,864 [main] INFO  org.apache.spark.SecurityManager [] - Changing view acls groups to: 
2025-12-22T02:12:54,866 [main] INFO  org.apache.spark.SecurityManager [] - Changing modify acls groups to: 
2025-12-22T02:12:54,871 [main] INFO  org.apache.spark.SecurityManager [] - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
2025-12-22T02:12:54,921 [main] INFO  org.apache.spark.SecurityManager [] - Changing view acls to: spark
2025-12-22T02:12:54,922 [main] INFO  org.apache.spark.SecurityManager [] - Changing modify acls to: spark
2025-12-22T02:12:54,924 [main] INFO  org.apache.spark.SecurityManager [] - Changing view acls groups to: 
2025-12-22T02:12:54,926 [main] INFO  org.apache.spark.SecurityManager [] - Changing modify acls groups to: 
2025-12-22T02:12:54,927 [main] INFO  org.apache.spark.SecurityManager [] - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
2025-12-22T02:12:55,225 [netty-rpc-connection-0] INFO  org.apache.spark.network.client.TransportClientFactory [] - Successfully created connection to e78e7707373c/172.20.0.3:44703 after 82 ms (0 ms spent in bootstraps)
2025-12-22T02:12:55,310 [netty-rpc-connection-0] INFO  org.apache.spark.network.client.TransportClientFactory [] - Successfully created connection to e78e7707373c/172.20.0.3:44703 after 94 ms (0 ms spent in bootstraps)
2025-12-22T02:12:55,315 [netty-rpc-connection-0] INFO  org.apache.spark.network.client.TransportClientFactory [] - Successfully created connection to e78e7707373c/172.20.0.3:44703 after 79 ms (0 ms spent in bootstraps)
2025-12-22T02:12:55,357 [main] INFO  org.apache.spark.SecurityManager [] - Changing view acls to: spark
2025-12-22T02:12:55,357 [main] INFO  org.apache.spark.SecurityManager [] - Changing modify acls to: spark
2025-12-22T02:12:55,358 [main] INFO  org.apache.spark.SecurityManager [] - Changing view acls groups to: 
2025-12-22T02:12:55,358 [main] INFO  org.apache.spark.SecurityManager [] - Changing modify acls groups to: 
2025-12-22T02:12:55,359 [main] INFO  org.apache.spark.SecurityManager [] - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
2025-12-22T02:12:55,437 [netty-rpc-connection-0] INFO  org.apache.spark.network.client.TransportClientFactory [] - Successfully created connection to e78e7707373c/172.20.0.3:44703 after 5 ms (0 ms spent in bootstraps)
2025-12-22T02:12:55,442 [main] INFO  org.apache.spark.SecurityManager [] - Changing view acls to: spark
2025-12-22T02:12:55,443 [main] INFO  org.apache.spark.SecurityManager [] - Changing modify acls to: spark
2025-12-22T02:12:55,443 [main] INFO  org.apache.spark.SecurityManager [] - Changing view acls groups to: 
2025-12-22T02:12:55,444 [main] INFO  org.apache.spark.SecurityManager [] - Changing modify acls groups to: 
2025-12-22T02:12:55,444 [main] INFO  org.apache.spark.SecurityManager [] - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
2025-12-22T02:12:55,448 [main] INFO  org.apache.spark.SecurityManager [] - Changing view acls to: spark
2025-12-22T02:12:55,449 [main] INFO  org.apache.spark.SecurityManager [] - Changing modify acls to: spark
2025-12-22T02:12:55,449 [main] INFO  org.apache.spark.SecurityManager [] - Changing view acls groups to: 
2025-12-22T02:12:55,450 [main] INFO  org.apache.spark.SecurityManager [] - Changing modify acls groups to: 
2025-12-22T02:12:55,450 [main] INFO  org.apache.spark.SecurityManager [] - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
2025-12-22T02:12:55,513 [netty-rpc-connection-0] INFO  org.apache.spark.network.client.TransportClientFactory [] - Successfully created connection to e78e7707373c/172.20.0.3:44703 after 3 ms (0 ms spent in bootstraps)
2025-12-22T02:12:55,534 [netty-rpc-connection-0] INFO  org.apache.spark.network.client.TransportClientFactory [] - Successfully created connection to e78e7707373c/172.20.0.3:44703 after 5 ms (0 ms spent in bootstraps)
2025-12-22T02:12:55,543 [main] INFO  org.apache.spark.storage.DiskBlockManager [] - Created local directory at /tmp/spark-9a843cda-0109-4a98-94f0-ddd489474289/executor-3d058395-3ef3-4c47-a82a-8dff253a8650/blockmgr-d80957ef-58a1-46db-bfce-36f55772ec63
2025-12-22T02:12:55,606 [main] INFO  org.apache.spark.storage.memory.MemoryStore [] - MemoryStore started with capacity 1663.2 MiB
2025-12-22T02:12:55,670 [main] INFO  org.apache.spark.storage.DiskBlockManager [] - Created local directory at /tmp/spark-92f73c85-65cf-4360-ab95-59e73798545b/executor-42ed7356-d805-4673-8d46-287e5ca9ffb0/blockmgr-6492be47-8325-4162-80f6-ade7aab76160
2025-12-22T02:12:55,682 [main] INFO  org.apache.spark.storage.DiskBlockManager [] - Created local directory at /tmp/spark-7ee3a3a3-8fc8-47ed-a33b-3f46111677ce/executor-9125c8d1-65ab-4b08-8c23-308d89896601/blockmgr-38142d58-c15c-45e1-81a5-f62be6680d4a
2025-12-22T02:12:55,726 [main] INFO  org.apache.spark.storage.memory.MemoryStore [] - MemoryStore started with capacity 1663.2 MiB
2025-12-22T02:12:55,728 [main] INFO  org.apache.spark.storage.memory.MemoryStore [] - MemoryStore started with capacity 1663.2 MiB
2025-12-22T02:12:55,891 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend [] - Connecting to driver: spark://CoarseGrainedScheduler@e78e7707373c:44703
2025-12-22T02:12:55,893 [main] INFO  org.apache.spark.deploy.worker.WorkerWatcher [] - Connecting to worker spark://Worker@172.20.0.4:42325
2025-12-22T02:12:55,898 [netty-rpc-connection-1] INFO  org.apache.spark.network.client.TransportClientFactory [] - Successfully created connection to /172.20.0.4:42325 after 2 ms (0 ms spent in bootstraps)
2025-12-22T02:12:55,902 [dispatcher-event-loop-0] INFO  org.apache.spark.deploy.worker.WorkerWatcher [] - Successfully connected to spark://Worker@172.20.0.4:42325
2025-12-22T02:12:55,903 [dispatcher-Executor] INFO  org.apache.spark.resource.ResourceUtils [] - ==============================================================
2025-12-22T02:12:55,904 [dispatcher-Executor] INFO  org.apache.spark.resource.ResourceUtils [] - No custom resources configured for spark.executor.
2025-12-22T02:12:55,905 [dispatcher-Executor] INFO  org.apache.spark.resource.ResourceUtils [] - ==============================================================
2025-12-22T02:12:55,938 [dispatcher-CoarseGrainedScheduler] INFO  org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend$StandaloneDriverEndpoint [] - Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.20.0.4:59186) with ID 0,  ResourceProfileId 0
2025-12-22T02:12:55,947 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend [] - Successfully registered with driver
2025-12-22T02:12:55,952 [dispatcher-Executor] INFO  org.apache.spark.executor.Executor [] - Starting executor ID 0 on host 172.20.0.4
2025-12-22T02:12:55,953 [dispatcher-Executor] INFO  org.apache.spark.executor.Executor [] - OS info Linux, 6.6.87.1-microsoft-standard-WSL2, amd64
2025-12-22T02:12:55,954 [dispatcher-Executor] INFO  org.apache.spark.executor.Executor [] - Java version 17.0.10
2025-12-22T02:12:55,992 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend [] - Connecting to driver: spark://CoarseGrainedScheduler@e78e7707373c:44703
2025-12-22T02:12:55,993 [main] INFO  org.apache.spark.deploy.worker.WorkerWatcher [] - Connecting to worker spark://Worker@172.20.0.5:37529
2025-12-22T02:12:56,000 [netty-rpc-connection-1] INFO  org.apache.spark.network.client.TransportClientFactory [] - Successfully created connection to /172.20.0.5:37529 after 3 ms (0 ms spent in bootstraps)
2025-12-22T02:12:56,005 [dispatcher-event-loop-1] INFO  org.apache.spark.deploy.worker.WorkerWatcher [] - Successfully connected to spark://Worker@172.20.0.5:37529
2025-12-22T02:12:56,011 [dispatcher-Executor] INFO  org.apache.spark.resource.ResourceUtils [] - ==============================================================
2025-12-22T02:12:56,012 [dispatcher-Executor] INFO  org.apache.spark.resource.ResourceUtils [] - No custom resources configured for spark.executor.
2025-12-22T02:12:56,013 [dispatcher-Executor] INFO  org.apache.spark.resource.ResourceUtils [] - ==============================================================
2025-12-22T02:12:56,022 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend [] - Connecting to driver: spark://CoarseGrainedScheduler@e78e7707373c:44703
2025-12-22T02:12:56,022 [main] INFO  org.apache.spark.deploy.worker.WorkerWatcher [] - Connecting to worker spark://Worker@172.20.0.6:36353
2025-12-22T02:12:56,025 [dispatcher-Executor] INFO  org.apache.spark.util.Utils [] - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 44999.
2025-12-22T02:12:56,025 [dispatcher-Executor] INFO  org.apache.spark.network.netty.NettyBlockTransferService [] - Server created on 172.20.0.4:44999
2025-12-22T02:12:56,029 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManager [] - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2025-12-22T02:12:56,032 [netty-rpc-connection-1] INFO  org.apache.spark.network.client.TransportClientFactory [] - Successfully created connection to /172.20.0.6:36353 after 7 ms (0 ms spent in bootstraps)
2025-12-22T02:12:56,037 [dispatcher-event-loop-0] INFO  org.apache.spark.deploy.worker.WorkerWatcher [] - Successfully connected to spark://Worker@172.20.0.6:36353
2025-12-22T02:12:56,039 [dispatcher-CoarseGrainedScheduler] INFO  org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend$StandaloneDriverEndpoint [] - Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.20.0.5:38706) with ID 1,  ResourceProfileId 0
2025-12-22T02:12:56,046 [dispatcher-Executor] INFO  org.apache.spark.resource.ResourceUtils [] - ==============================================================
2025-12-22T02:12:56,047 [dispatcher-Executor] INFO  org.apache.spark.resource.ResourceUtils [] - No custom resources configured for spark.executor.
2025-12-22T02:12:56,049 [dispatcher-Executor] INFO  org.apache.spark.resource.ResourceUtils [] - ==============================================================
2025-12-22T02:12:56,052 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend [] - Successfully registered with driver
2025-12-22T02:12:56,052 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManagerMaster [] - Registering BlockManager BlockManagerId(0, 172.20.0.4, 44999, None)
2025-12-22T02:12:56,060 [dispatcher-Executor] INFO  org.apache.spark.executor.Executor [] - Starting executor ID 1 on host 172.20.0.5
2025-12-22T02:12:56,062 [dispatcher-Executor] INFO  org.apache.spark.executor.Executor [] - OS info Linux, 6.6.87.1-microsoft-standard-WSL2, amd64
2025-12-22T02:12:56,063 [dispatcher-Executor] INFO  org.apache.spark.executor.Executor [] - Java version 17.0.10
2025-12-22T02:12:56,069 [Thread-4] INFO  org.apache.spark.sql.execution.datasources.InMemoryFileIndex [] - It took 128 ms to list leaf files for 1 paths.
2025-12-22T02:12:56,074 [dispatcher-BlockManagerMaster] INFO  org.apache.spark.storage.BlockManagerMasterEndpoint [] - Registering block manager 172.20.0.4:44999 with 1663.2 MiB RAM, BlockManagerId(0, 172.20.0.4, 44999, None)
2025-12-22T02:12:56,081 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManagerMaster [] - Registered BlockManager BlockManagerId(0, 172.20.0.4, 44999, None)
2025-12-22T02:12:56,083 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManager [] - Initialized BlockManager: BlockManagerId(0, 172.20.0.4, 44999, None)
2025-12-22T02:12:56,098 [dispatcher-CoarseGrainedScheduler] INFO  org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend$StandaloneDriverEndpoint [] - Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.20.0.6:57932) with ID 2,  ResourceProfileId 0
2025-12-22T02:12:56,100 [dispatcher-Executor] INFO  org.apache.spark.executor.Executor [] - Starting executor with user classpath (userClassPathFirst = false): ''
2025-12-22T02:12:56,103 [dispatcher-Executor] INFO  org.apache.spark.executor.Executor [] - Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@6568e711 for default.
2025-12-22T02:12:56,108 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend [] - Successfully registered with driver
2025-12-22T02:12:56,116 [dispatcher-Executor] INFO  org.apache.spark.executor.Executor [] - Starting executor ID 2 on host 172.20.0.6
2025-12-22T02:12:56,118 [dispatcher-Executor] INFO  org.apache.spark.executor.Executor [] - OS info Linux, 6.6.87.1-microsoft-standard-WSL2, amd64
2025-12-22T02:12:56,120 [dispatcher-Executor] INFO  org.apache.spark.executor.Executor [] - Java version 17.0.10
2025-12-22T02:12:56,152 [dispatcher-Executor] INFO  org.apache.spark.util.Utils [] - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 45841.
2025-12-22T02:12:56,152 [dispatcher-Executor] INFO  org.apache.spark.network.netty.NettyBlockTransferService [] - Server created on 172.20.0.5:45841
2025-12-22T02:12:56,155 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManager [] - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2025-12-22T02:12:56,164 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManagerMaster [] - Registering BlockManager BlockManagerId(1, 172.20.0.5, 45841, None)
2025-12-22T02:12:56,175 [dispatcher-BlockManagerMaster] INFO  org.apache.spark.storage.BlockManagerMasterEndpoint [] - Registering block manager 172.20.0.5:45841 with 1663.2 MiB RAM, BlockManagerId(1, 172.20.0.5, 45841, None)
2025-12-22T02:12:56,180 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManagerMaster [] - Registered BlockManager BlockManagerId(1, 172.20.0.5, 45841, None)
2025-12-22T02:12:56,182 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManager [] - Initialized BlockManager: BlockManagerId(1, 172.20.0.5, 45841, None)
2025-12-22T02:12:56,190 [dispatcher-Executor] INFO  org.apache.spark.util.Utils [] - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 34907.
2025-12-22T02:12:56,191 [dispatcher-Executor] INFO  org.apache.spark.network.netty.NettyBlockTransferService [] - Server created on 172.20.0.6:34907
2025-12-22T02:12:56,195 [dispatcher-Executor] INFO  org.apache.spark.executor.Executor [] - Starting executor with user classpath (userClassPathFirst = false): ''
2025-12-22T02:12:56,195 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManager [] - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2025-12-22T02:12:56,196 [dispatcher-Executor] INFO  org.apache.spark.executor.Executor [] - Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@1eac68a8 for default.
2025-12-22T02:12:56,208 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManagerMaster [] - Registering BlockManager BlockManagerId(2, 172.20.0.6, 34907, None)
2025-12-22T02:12:56,218 [Thread-4] INFO  org.apache.spark.sql.execution.datasources.InMemoryFileIndex [] - It took 16 ms to list leaf files for 1 paths.
2025-12-22T02:12:56,219 [dispatcher-BlockManagerMaster] INFO  org.apache.spark.storage.BlockManagerMasterEndpoint [] - Registering block manager 172.20.0.6:34907 with 1663.2 MiB RAM, BlockManagerId(2, 172.20.0.6, 34907, None)
2025-12-22T02:12:56,223 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManagerMaster [] - Registered BlockManager BlockManagerId(2, 172.20.0.6, 34907, None)
2025-12-22T02:12:56,224 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManager [] - Initialized BlockManager: BlockManagerId(2, 172.20.0.6, 34907, None)
2025-12-22T02:12:56,238 [dispatcher-Executor] INFO  org.apache.spark.executor.Executor [] - Starting executor with user classpath (userClassPathFirst = false): ''
2025-12-22T02:12:56,240 [dispatcher-Executor] INFO  org.apache.spark.executor.Executor [] - Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@26184d41 for default.
2025-12-22T02:12:57,875 [Thread-4] INFO  org.apache.spark.sql.execution.datasources.FileSourceStrategy [] - Pushed Filters: 
2025-12-22T02:12:57,876 [Thread-4] INFO  org.apache.spark.sql.execution.datasources.FileSourceStrategy [] - Post-Scan Filters: 
2025-12-22T02:12:58,005 [Thread-4] INFO  org.apache.spark.storage.memory.MemoryStore [] - Block broadcast_0 stored as values in memory (estimated size 203.9 KiB, free 434.2 MiB)
2025-12-22T02:12:58,048 [Thread-4] INFO  org.apache.spark.storage.memory.MemoryStore [] - Block broadcast_0_piece0 stored as bytes in memory (estimated size 35.3 KiB, free 434.2 MiB)
2025-12-22T02:12:58,057 [dispatcher-BlockManagerMaster] INFO  org.apache.spark.storage.BlockManagerInfo [] - Added broadcast_0_piece0 in memory on e78e7707373c:41515 (size: 35.3 KiB, free: 434.4 MiB)
2025-12-22T02:12:58,062 [Thread-4] INFO  org.apache.spark.SparkContext [] - Created broadcast 0 from json at NativeMethodAccessorImpl.java:0
2025-12-22T02:12:58,077 [Thread-4] INFO  org.apache.spark.sql.execution.FileSourceScanExec [] - Planning scan with bin packing, max size: 20509683 bytes, open cost is considered as scanning 4194304 bytes.
2025-12-22T02:12:58,219 [Thread-4] INFO  org.apache.spark.SparkContext [] - Starting job: json at NativeMethodAccessorImpl.java:0
2025-12-22T02:12:58,235 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.DAGScheduler [] - Got job 0 (json at NativeMethodAccessorImpl.java:0) with 6 output partitions
2025-12-22T02:12:58,236 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.DAGScheduler [] - Final stage: ResultStage 0 (json at NativeMethodAccessorImpl.java:0)
2025-12-22T02:12:58,236 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.DAGScheduler [] - Parents of final stage: List()
2025-12-22T02:12:58,237 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.DAGScheduler [] - Missing parents: List()
2025-12-22T02:12:58,241 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.DAGScheduler [] - Submitting ResultStage 0 (MapPartitionsRDD[3] at json at NativeMethodAccessorImpl.java:0), which has no missing parents
2025-12-22T02:12:58,302 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.memory.MemoryStore [] - Block broadcast_1 stored as values in memory (estimated size 17.2 KiB, free 434.1 MiB)
2025-12-22T02:12:58,311 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.memory.MemoryStore [] - Block broadcast_1_piece0 stored as bytes in memory (estimated size 8.2 KiB, free 434.1 MiB)
2025-12-22T02:12:58,312 [dispatcher-BlockManagerMaster] INFO  org.apache.spark.storage.BlockManagerInfo [] - Added broadcast_1_piece0 in memory on e78e7707373c:41515 (size: 8.2 KiB, free: 434.4 MiB)
2025-12-22T02:12:58,313 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext [] - Created broadcast 1 from broadcast at DAGScheduler.scala:1580
2025-12-22T02:12:58,336 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.DAGScheduler [] - Submitting 6 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at json at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5))
2025-12-22T02:12:58,338 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.TaskSchedulerImpl [] - Adding task set 0.0 with 6 tasks resource profile 0
2025-12-22T02:12:58,364 [dispatcher-CoarseGrainedScheduler] INFO  org.apache.spark.scheduler.TaskSetManager [] - Starting task 0.0 in stage 0.0 (TID 0) (172.20.0.5, executor 1, partition 0, PROCESS_LOCAL, 8236 bytes) 
2025-12-22T02:12:58,370 [dispatcher-CoarseGrainedScheduler] INFO  org.apache.spark.scheduler.TaskSetManager [] - Starting task 1.0 in stage 0.0 (TID 1) (172.20.0.6, executor 2, partition 1, PROCESS_LOCAL, 8236 bytes) 
2025-12-22T02:12:58,371 [dispatcher-CoarseGrainedScheduler] INFO  org.apache.spark.scheduler.TaskSetManager [] - Starting task 2.0 in stage 0.0 (TID 2) (172.20.0.4, executor 0, partition 2, PROCESS_LOCAL, 8236 bytes) 
2025-12-22T02:12:58,372 [dispatcher-CoarseGrainedScheduler] INFO  org.apache.spark.scheduler.TaskSetManager [] - Starting task 3.0 in stage 0.0 (TID 3) (172.20.0.5, executor 1, partition 3, PROCESS_LOCAL, 8236 bytes) 
2025-12-22T02:12:58,373 [dispatcher-CoarseGrainedScheduler] INFO  org.apache.spark.scheduler.TaskSetManager [] - Starting task 4.0 in stage 0.0 (TID 4) (172.20.0.6, executor 2, partition 4, PROCESS_LOCAL, 8236 bytes) 
2025-12-22T02:12:58,374 [dispatcher-CoarseGrainedScheduler] INFO  org.apache.spark.scheduler.TaskSetManager [] - Starting task 5.0 in stage 0.0 (TID 5) (172.20.0.4, executor 0, partition 5, PROCESS_LOCAL, 8236 bytes) 
2025-12-22T02:12:58,397 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend [] - Got assigned task 0
2025-12-22T02:12:58,398 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend [] - Got assigned task 2
2025-12-22T02:12:58,398 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend [] - Got assigned task 1
2025-12-22T02:12:58,404 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend [] - Got assigned task 4
2025-12-22T02:12:58,404 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend [] - Got assigned task 5
2025-12-22T02:12:58,404 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend [] - Got assigned task 3
2025-12-22T02:12:58,410 [Executor task launch worker for task 5.0 in stage 0.0 (TID 5)] INFO  org.apache.spark.executor.Executor [] - Running task 5.0 in stage 0.0 (TID 5)
2025-12-22T02:12:58,410 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.executor.Executor [] - Running task 0.0 in stage 0.0 (TID 0)
2025-12-22T02:12:58,410 [Executor task launch worker for task 3.0 in stage 0.0 (TID 3)] INFO  org.apache.spark.executor.Executor [] - Running task 3.0 in stage 0.0 (TID 3)
2025-12-22T02:12:58,410 [Executor task launch worker for task 2.0 in stage 0.0 (TID 2)] INFO  org.apache.spark.executor.Executor [] - Running task 2.0 in stage 0.0 (TID 2)
2025-12-22T02:12:58,411 [Executor task launch worker for task 4.0 in stage 0.0 (TID 4)] INFO  org.apache.spark.executor.Executor [] - Running task 4.0 in stage 0.0 (TID 4)
2025-12-22T02:12:58,411 [Executor task launch worker for task 1.0 in stage 0.0 (TID 1)] INFO  org.apache.spark.executor.Executor [] - Running task 1.0 in stage 0.0 (TID 1)
2025-12-22T02:12:58,528 [Executor task launch worker for task 2.0 in stage 0.0 (TID 2)] INFO  org.apache.spark.broadcast.TorrentBroadcast [] - Started reading broadcast variable 1 with 1 pieces (estimated total size 4.0 MiB)
2025-12-22T02:12:58,545 [Executor task launch worker for task 3.0 in stage 0.0 (TID 3)] INFO  org.apache.spark.broadcast.TorrentBroadcast [] - Started reading broadcast variable 1 with 1 pieces (estimated total size 4.0 MiB)
2025-12-22T02:12:58,557 [Executor task launch worker for task 1.0 in stage 0.0 (TID 1)] INFO  org.apache.spark.broadcast.TorrentBroadcast [] - Started reading broadcast variable 1 with 1 pieces (estimated total size 4.0 MiB)
2025-12-22T02:12:58,609 [Executor task launch worker for task 2.0 in stage 0.0 (TID 2)] INFO  org.apache.spark.network.client.TransportClientFactory [] - Successfully created connection to e78e7707373c/172.20.0.3:41515 after 2 ms (0 ms spent in bootstraps)
2025-12-22T02:12:58,609 [Executor task launch worker for task 1.0 in stage 0.0 (TID 1)] INFO  org.apache.spark.network.client.TransportClientFactory [] - Successfully created connection to e78e7707373c/172.20.0.3:41515 after 4 ms (0 ms spent in bootstraps)
2025-12-22T02:12:58,639 [Executor task launch worker for task 3.0 in stage 0.0 (TID 3)] INFO  org.apache.spark.network.client.TransportClientFactory [] - Successfully created connection to e78e7707373c/172.20.0.3:41515 after 3 ms (0 ms spent in bootstraps)
2025-12-22T02:12:58,660 [Executor task launch worker for task 2.0 in stage 0.0 (TID 2)] INFO  org.apache.spark.storage.memory.MemoryStore [] - Block broadcast_1_piece0 stored as bytes in memory (estimated size 8.2 KiB, free 1663.2 MiB)
2025-12-22T02:12:58,667 [Executor task launch worker for task 1.0 in stage 0.0 (TID 1)] INFO  org.apache.spark.storage.memory.MemoryStore [] - Block broadcast_1_piece0 stored as bytes in memory (estimated size 8.2 KiB, free 1663.2 MiB)
2025-12-22T02:12:58,669 [dispatcher-BlockManagerMaster] INFO  org.apache.spark.storage.BlockManagerInfo [] - Added broadcast_1_piece0 in memory on 172.20.0.4:44999 (size: 8.2 KiB, free: 1663.2 MiB)
2025-12-22T02:12:58,673 [dispatcher-BlockManagerMaster] INFO  org.apache.spark.storage.BlockManagerInfo [] - Added broadcast_1_piece0 in memory on 172.20.0.6:34907 (size: 8.2 KiB, free: 1663.2 MiB)
2025-12-22T02:12:58,674 [Executor task launch worker for task 2.0 in stage 0.0 (TID 2)] INFO  org.apache.spark.broadcast.TorrentBroadcast [] - Reading broadcast variable 1 took 144 ms
2025-12-22T02:12:58,679 [Executor task launch worker for task 3.0 in stage 0.0 (TID 3)] INFO  org.apache.spark.storage.memory.MemoryStore [] - Block broadcast_1_piece0 stored as bytes in memory (estimated size 8.2 KiB, free 1663.2 MiB)
2025-12-22T02:12:58,680 [Executor task launch worker for task 1.0 in stage 0.0 (TID 1)] INFO  org.apache.spark.broadcast.TorrentBroadcast [] - Reading broadcast variable 1 took 122 ms
2025-12-22T02:12:58,687 [dispatcher-BlockManagerMaster] INFO  org.apache.spark.storage.BlockManagerInfo [] - Added broadcast_1_piece0 in memory on 172.20.0.5:45841 (size: 8.2 KiB, free: 1663.2 MiB)
2025-12-22T02:12:58,695 [Executor task launch worker for task 3.0 in stage 0.0 (TID 3)] INFO  org.apache.spark.broadcast.TorrentBroadcast [] - Reading broadcast variable 1 took 149 ms
2025-12-22T02:12:58,737 [Executor task launch worker for task 2.0 in stage 0.0 (TID 2)] INFO  org.apache.spark.storage.memory.MemoryStore [] - Block broadcast_1 stored as values in memory (estimated size 17.2 KiB, free 1663.2 MiB)
2025-12-22T02:12:58,738 [Executor task launch worker for task 1.0 in stage 0.0 (TID 1)] INFO  org.apache.spark.storage.memory.MemoryStore [] - Block broadcast_1 stored as values in memory (estimated size 17.2 KiB, free 1663.2 MiB)
2025-12-22T02:12:58,760 [Executor task launch worker for task 3.0 in stage 0.0 (TID 3)] INFO  org.apache.spark.storage.memory.MemoryStore [] - Block broadcast_1 stored as values in memory (estimated size 17.2 KiB, free 1663.2 MiB)
2025-12-22T02:12:59,185 [Executor task launch worker for task 1.0 in stage 0.0 (TID 1)] INFO  org.apache.spark.sql.execution.datasources.FileScanRDD [] - Reading File path: s3a://landing/yelp/yelp_academic_dataset_business.json, range: 20509683-41019366, partition values: [empty row]
2025-12-22T02:12:59,185 [Executor task launch worker for task 4.0 in stage 0.0 (TID 4)] INFO  org.apache.spark.sql.execution.datasources.FileScanRDD [] - Reading File path: s3a://landing/yelp/yelp_academic_dataset_business.json, range: 82038732-102548415, partition values: [empty row]
2025-12-22T02:12:59,195 [Executor task launch worker for task 5.0 in stage 0.0 (TID 5)] INFO  org.apache.spark.sql.execution.datasources.FileScanRDD [] - Reading File path: s3a://landing/yelp/yelp_academic_dataset_business.json, range: 102548415-118863795, partition values: [empty row]
2025-12-22T02:12:59,195 [Executor task launch worker for task 2.0 in stage 0.0 (TID 2)] INFO  org.apache.spark.sql.execution.datasources.FileScanRDD [] - Reading File path: s3a://landing/yelp/yelp_academic_dataset_business.json, range: 41019366-61529049, partition values: [empty row]
2025-12-22T02:12:59,249 [Executor task launch worker for task 3.0 in stage 0.0 (TID 3)] INFO  org.apache.spark.sql.execution.datasources.FileScanRDD [] - Reading File path: s3a://landing/yelp/yelp_academic_dataset_business.json, range: 61529049-82038732, partition values: [empty row]
2025-12-22T02:12:59,249 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.sql.execution.datasources.FileScanRDD [] - Reading File path: s3a://landing/yelp/yelp_academic_dataset_business.json, range: 0-20509683, partition values: [empty row]
2025-12-22T02:12:59,599 [Executor task launch worker for task 5.0 in stage 0.0 (TID 5)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator [] - Code generated in 251.43421 ms
2025-12-22T02:12:59,602 [Executor task launch worker for task 2.0 in stage 0.0 (TID 2)] INFO  org.apache.spark.broadcast.TorrentBroadcast [] - Started reading broadcast variable 0 with 1 pieces (estimated total size 4.0 MiB)
2025-12-22T02:12:59,604 [Executor task launch worker for task 1.0 in stage 0.0 (TID 1)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator [] - Code generated in 252.066675 ms
2025-12-22T02:12:59,606 [Executor task launch worker for task 4.0 in stage 0.0 (TID 4)] INFO  org.apache.spark.broadcast.TorrentBroadcast [] - Started reading broadcast variable 0 with 1 pieces (estimated total size 4.0 MiB)
2025-12-22T02:12:59,614 [Executor task launch worker for task 2.0 in stage 0.0 (TID 2)] INFO  org.apache.spark.storage.memory.MemoryStore [] - Block broadcast_0_piece0 stored as bytes in memory (estimated size 35.3 KiB, free 1663.1 MiB)
2025-12-22T02:12:59,618 [dispatcher-BlockManagerMaster] INFO  org.apache.spark.storage.BlockManagerInfo [] - Added broadcast_0_piece0 in memory on 172.20.0.4:44999 (size: 35.3 KiB, free: 1663.2 MiB)
2025-12-22T02:12:59,618 [Executor task launch worker for task 4.0 in stage 0.0 (TID 4)] INFO  org.apache.spark.storage.memory.MemoryStore [] - Block broadcast_0_piece0 stored as bytes in memory (estimated size 35.3 KiB, free 1663.1 MiB)
2025-12-22T02:12:59,620 [Executor task launch worker for task 2.0 in stage 0.0 (TID 2)] INFO  org.apache.spark.broadcast.TorrentBroadcast [] - Reading broadcast variable 0 took 18 ms
2025-12-22T02:12:59,622 [dispatcher-BlockManagerMaster] INFO  org.apache.spark.storage.BlockManagerInfo [] - Added broadcast_0_piece0 in memory on 172.20.0.6:34907 (size: 35.3 KiB, free: 1663.2 MiB)
2025-12-22T02:12:59,625 [Executor task launch worker for task 4.0 in stage 0.0 (TID 4)] INFO  org.apache.spark.broadcast.TorrentBroadcast [] - Reading broadcast variable 0 took 17 ms
2025-12-22T02:12:59,667 [Executor task launch worker for task 3.0 in stage 0.0 (TID 3)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator [] - Code generated in 261.883639 ms
2025-12-22T02:12:59,670 [Executor task launch worker for task 3.0 in stage 0.0 (TID 3)] INFO  org.apache.spark.broadcast.TorrentBroadcast [] - Started reading broadcast variable 0 with 1 pieces (estimated total size 4.0 MiB)
2025-12-22T02:12:59,684 [Executor task launch worker for task 3.0 in stage 0.0 (TID 3)] INFO  org.apache.spark.storage.memory.MemoryStore [] - Block broadcast_0_piece0 stored as bytes in memory (estimated size 35.3 KiB, free 1663.1 MiB)
2025-12-22T02:12:59,688 [dispatcher-BlockManagerMaster] INFO  org.apache.spark.storage.BlockManagerInfo [] - Added broadcast_0_piece0 in memory on 172.20.0.5:45841 (size: 35.3 KiB, free: 1663.2 MiB)
2025-12-22T02:12:59,690 [Executor task launch worker for task 3.0 in stage 0.0 (TID 3)] INFO  org.apache.spark.broadcast.TorrentBroadcast [] - Reading broadcast variable 0 took 19 ms
2025-12-22T02:12:59,691 [Executor task launch worker for task 2.0 in stage 0.0 (TID 2)] INFO  org.apache.spark.storage.memory.MemoryStore [] - Block broadcast_0 stored as values in memory (estimated size 381.2 KiB, free 1662.8 MiB)
2025-12-22T02:12:59,697 [Executor task launch worker for task 4.0 in stage 0.0 (TID 4)] INFO  org.apache.spark.storage.memory.MemoryStore [] - Block broadcast_0 stored as values in memory (estimated size 381.2 KiB, free 1662.8 MiB)
2025-12-22T02:12:59,748 [Executor task launch worker for task 3.0 in stage 0.0 (TID 3)] INFO  org.apache.spark.storage.memory.MemoryStore [] - Block broadcast_0 stored as values in memory (estimated size 381.2 KiB, free 1662.8 MiB)
2025-12-22T02:12:59,876 [Executor task launch worker for task 5.0 in stage 0.0 (TID 5)] WARN  org.apache.hadoop.metrics2.impl.MetricsConfig [] - Cannot locate configuration: tried hadoop-metrics2-s3a-file-system.properties,hadoop-metrics2.properties
2025-12-22T02:12:59,881 [Executor task launch worker for task 4.0 in stage 0.0 (TID 4)] WARN  org.apache.hadoop.metrics2.impl.MetricsConfig [] - Cannot locate configuration: tried hadoop-metrics2-s3a-file-system.properties,hadoop-metrics2.properties
2025-12-22T02:12:59,891 [Executor task launch worker for task 5.0 in stage 0.0 (TID 5)] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl [] - Scheduled Metric snapshot period at 10 second(s).
2025-12-22T02:12:59,891 [Executor task launch worker for task 5.0 in stage 0.0 (TID 5)] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl [] - s3a-file-system metrics system started
2025-12-22T02:12:59,898 [Executor task launch worker for task 4.0 in stage 0.0 (TID 4)] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl [] - Scheduled Metric snapshot period at 10 second(s).
2025-12-22T02:12:59,899 [Executor task launch worker for task 4.0 in stage 0.0 (TID 4)] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl [] - s3a-file-system metrics system started
2025-12-22T02:12:59,901 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] WARN  org.apache.hadoop.metrics2.impl.MetricsConfig [] - Cannot locate configuration: tried hadoop-metrics2-s3a-file-system.properties,hadoop-metrics2.properties
2025-12-22T02:12:59,919 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl [] - Scheduled Metric snapshot period at 10 second(s).
2025-12-22T02:12:59,919 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl [] - s3a-file-system metrics system started
2025-12-22T02:13:02,631 [Executor task launch worker for task 4.0 in stage 0.0 (TID 4)] INFO  org.apache.spark.executor.Executor [] - Finished task 4.0 in stage 0.0 (TID 4). 4004 bytes result sent to driver
2025-12-22T02:13:02,631 [Executor task launch worker for task 1.0 in stage 0.0 (TID 1)] INFO  org.apache.spark.executor.Executor [] - Finished task 1.0 in stage 0.0 (TID 1). 4004 bytes result sent to driver
2025-12-22T02:13:02,660 [task-result-getter-0] INFO  org.apache.spark.scheduler.TaskSetManager [] - Finished task 1.0 in stage 0.0 (TID 1) in 4288 ms on 172.20.0.6 (executor 2) (1/6)
2025-12-22T02:13:02,664 [task-result-getter-1] INFO  org.apache.spark.scheduler.TaskSetManager [] - Finished task 4.0 in stage 0.0 (TID 4) in 4290 ms on 172.20.0.6 (executor 2) (2/6)
2025-12-22T02:13:02,757 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.executor.Executor [] - Finished task 0.0 in stage 0.0 (TID 0). 4004 bytes result sent to driver
2025-12-22T02:13:02,757 [Executor task launch worker for task 3.0 in stage 0.0 (TID 3)] INFO  org.apache.spark.executor.Executor [] - Finished task 3.0 in stage 0.0 (TID 3). 4004 bytes result sent to driver
2025-12-22T02:13:02,768 [task-result-getter-2] INFO  org.apache.spark.scheduler.TaskSetManager [] - Finished task 3.0 in stage 0.0 (TID 3) in 4396 ms on 172.20.0.5 (executor 1) (3/6)
2025-12-22T02:13:02,769 [task-result-getter-3] INFO  org.apache.spark.scheduler.TaskSetManager [] - Finished task 0.0 in stage 0.0 (TID 0) in 4414 ms on 172.20.0.5 (executor 1) (4/6)
2025-12-22T02:13:02,847 [Executor task launch worker for task 5.0 in stage 0.0 (TID 5)] INFO  org.apache.spark.executor.Executor [] - Finished task 5.0 in stage 0.0 (TID 5). 4004 bytes result sent to driver
2025-12-22T02:13:02,854 [task-result-getter-0] INFO  org.apache.spark.scheduler.TaskSetManager [] - Finished task 5.0 in stage 0.0 (TID 5) in 4480 ms on 172.20.0.4 (executor 0) (5/6)
2025-12-22T02:13:03,069 [Executor task launch worker for task 2.0 in stage 0.0 (TID 2)] INFO  org.apache.spark.executor.Executor [] - Finished task 2.0 in stage 0.0 (TID 2). 4004 bytes result sent to driver
2025-12-22T02:13:03,075 [task-result-getter-1] INFO  org.apache.spark.scheduler.TaskSetManager [] - Finished task 2.0 in stage 0.0 (TID 2) in 4704 ms on 172.20.0.4 (executor 0) (6/6)
2025-12-22T02:13:03,077 [task-result-getter-1] INFO  org.apache.spark.scheduler.TaskSchedulerImpl [] - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2025-12-22T02:13:03,077 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.DAGScheduler [] - ResultStage 0 (json at NativeMethodAccessorImpl.java:0) finished in 4.821 s
2025-12-22T02:13:03,081 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.DAGScheduler [] - Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
2025-12-22T02:13:03,082 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.TaskSchedulerImpl [] - Killing all running tasks in stage 0: Stage finished
2025-12-22T02:13:03,085 [Thread-4] INFO  org.apache.spark.scheduler.DAGScheduler [] - Job 0 finished: json at NativeMethodAccessorImpl.java:0, took 4.865070 s
2025-12-22T02:13:03,191 [Thread-4] WARN  org.apache.spark.sql.catalyst.util.SparkStringUtils [] - Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.
2025-12-22T02:13:03,239 [Thread-4] INFO  org.apache.spark.sql.execution.datasources.FileSourceStrategy [] - Pushed Filters: 
2025-12-22T02:13:03,239 [Thread-4] INFO  org.apache.spark.sql.execution.datasources.FileSourceStrategy [] - Post-Scan Filters: 
2025-12-22T02:13:03,249 [Thread-4] INFO  org.apache.spark.storage.memory.MemoryStore [] - Block broadcast_2 stored as values in memory (estimated size 203.6 KiB, free 433.9 MiB)
2025-12-22T02:13:03,270 [Thread-4] INFO  org.apache.spark.storage.memory.MemoryStore [] - Block broadcast_2_piece0 stored as bytes in memory (estimated size 35.3 KiB, free 433.9 MiB)
2025-12-22T02:13:03,272 [dispatcher-BlockManagerMaster] INFO  org.apache.spark.storage.BlockManagerInfo [] - Added broadcast_2_piece0 in memory on e78e7707373c:41515 (size: 35.3 KiB, free: 434.3 MiB)
2025-12-22T02:13:03,273 [Thread-4] INFO  org.apache.spark.SparkContext [] - Created broadcast 2 from javaToPython at NativeMethodAccessorImpl.java:0
2025-12-22T02:13:03,277 [Thread-4] INFO  org.apache.spark.sql.execution.FileSourceScanExec [] - Planning scan with bin packing, max size: 20509683 bytes, open cost is considered as scanning 4194304 bytes.
2025-12-22T02:13:03,506 [Thread-4] INFO  org.apache.spark.sql.execution.datasources.FileSourceStrategy [] - Pushed Filters: 
2025-12-22T02:13:03,506 [Thread-4] INFO  org.apache.spark.sql.execution.datasources.FileSourceStrategy [] - Post-Scan Filters: 
2025-12-22T02:13:03,957 [Thread-4] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator [] - Code generated in 220.925482 ms
2025-12-22T02:13:03,961 [Thread-4] INFO  org.apache.spark.storage.memory.MemoryStore [] - Block broadcast_3 stored as values in memory (estimated size 203.6 KiB, free 433.7 MiB)
2025-12-22T02:13:03,976 [Thread-4] INFO  org.apache.spark.storage.memory.MemoryStore [] - Block broadcast_3_piece0 stored as bytes in memory (estimated size 35.3 KiB, free 433.7 MiB)
2025-12-22T02:13:03,977 [dispatcher-BlockManagerMaster] INFO  org.apache.spark.storage.BlockManagerInfo [] - Added broadcast_3_piece0 in memory on e78e7707373c:41515 (size: 35.3 KiB, free: 434.3 MiB)
2025-12-22T02:13:03,979 [Thread-4] INFO  org.apache.spark.SparkContext [] - Created broadcast 3 from count at NativeMethodAccessorImpl.java:0
2025-12-22T02:13:03,981 [Thread-4] INFO  org.apache.spark.sql.execution.FileSourceScanExec [] - Planning scan with bin packing, max size: 20509683 bytes, open cost is considered as scanning 4194304 bytes.
2025-12-22T02:13:04,025 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.DAGScheduler [] - Registering RDD 12 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 0
2025-12-22T02:13:04,031 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.DAGScheduler [] - Got map stage job 1 (count at NativeMethodAccessorImpl.java:0) with 6 output partitions
2025-12-22T02:13:04,032 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.DAGScheduler [] - Final stage: ShuffleMapStage 1 (count at NativeMethodAccessorImpl.java:0)
2025-12-22T02:13:04,032 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.DAGScheduler [] - Parents of final stage: List()
2025-12-22T02:13:04,033 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.DAGScheduler [] - Missing parents: List()
2025-12-22T02:13:04,035 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.DAGScheduler [] - Submitting ShuffleMapStage 1 (MapPartitionsRDD[12] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
2025-12-22T02:13:04,055 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.memory.MemoryStore [] - Block broadcast_4 stored as values in memory (estimated size 17.0 KiB, free 433.7 MiB)
2025-12-22T02:13:04,059 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.memory.MemoryStore [] - Block broadcast_4_piece0 stored as bytes in memory (estimated size 8.3 KiB, free 433.7 MiB)
2025-12-22T02:13:04,060 [dispatcher-BlockManagerMaster] INFO  org.apache.spark.storage.BlockManagerInfo [] - Added broadcast_4_piece0 in memory on e78e7707373c:41515 (size: 8.3 KiB, free: 434.3 MiB)
2025-12-22T02:13:04,061 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext [] - Created broadcast 4 from broadcast at DAGScheduler.scala:1580
2025-12-22T02:13:04,064 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.DAGScheduler [] - Submitting 6 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[12] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5))
2025-12-22T02:13:04,064 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.TaskSchedulerImpl [] - Adding task set 1.0 with 6 tasks resource profile 0
2025-12-22T02:13:04,067 [dispatcher-CoarseGrainedScheduler] INFO  org.apache.spark.scheduler.TaskSetManager [] - Starting task 0.0 in stage 1.0 (TID 6) (172.20.0.4, executor 0, partition 0, PROCESS_LOCAL, 8225 bytes) 
2025-12-22T02:13:04,068 [dispatcher-CoarseGrainedScheduler] INFO  org.apache.spark.scheduler.TaskSetManager [] - Starting task 1.0 in stage 1.0 (TID 7) (172.20.0.6, executor 2, partition 1, PROCESS_LOCAL, 8225 bytes) 
2025-12-22T02:13:04,069 [dispatcher-CoarseGrainedScheduler] INFO  org.apache.spark.scheduler.TaskSetManager [] - Starting task 2.0 in stage 1.0 (TID 8) (172.20.0.5, executor 1, partition 2, PROCESS_LOCAL, 8225 bytes) 
2025-12-22T02:13:04,070 [dispatcher-CoarseGrainedScheduler] INFO  org.apache.spark.scheduler.TaskSetManager [] - Starting task 3.0 in stage 1.0 (TID 9) (172.20.0.4, executor 0, partition 3, PROCESS_LOCAL, 8225 bytes) 
2025-12-22T02:13:04,071 [dispatcher-CoarseGrainedScheduler] INFO  org.apache.spark.scheduler.TaskSetManager [] - Starting task 4.0 in stage 1.0 (TID 10) (172.20.0.6, executor 2, partition 4, PROCESS_LOCAL, 8225 bytes) 
2025-12-22T02:13:04,071 [dispatcher-CoarseGrainedScheduler] INFO  org.apache.spark.scheduler.TaskSetManager [] - Starting task 5.0 in stage 1.0 (TID 11) (172.20.0.5, executor 1, partition 5, PROCESS_LOCAL, 8225 bytes) 
2025-12-22T02:13:04,075 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend [] - Got assigned task 6
2025-12-22T02:13:04,076 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend [] - Got assigned task 7
2025-12-22T02:13:04,076 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend [] - Got assigned task 9
2025-12-22T02:13:04,077 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend [] - Got assigned task 8
2025-12-22T02:13:04,077 [Executor task launch worker for task 0.0 in stage 1.0 (TID 6)] INFO  org.apache.spark.executor.Executor [] - Running task 0.0 in stage 1.0 (TID 6)
2025-12-22T02:13:04,077 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend [] - Got assigned task 10
2025-12-22T02:13:04,077 [Executor task launch worker for task 1.0 in stage 1.0 (TID 7)] INFO  org.apache.spark.executor.Executor [] - Running task 1.0 in stage 1.0 (TID 7)
2025-12-22T02:13:04,077 [Executor task launch worker for task 4.0 in stage 1.0 (TID 10)] INFO  org.apache.spark.executor.Executor [] - Running task 4.0 in stage 1.0 (TID 10)
2025-12-22T02:13:04,077 [Executor task launch worker for task 3.0 in stage 1.0 (TID 9)] INFO  org.apache.spark.executor.Executor [] - Running task 3.0 in stage 1.0 (TID 9)
2025-12-22T02:13:04,078 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend [] - Got assigned task 11
2025-12-22T02:13:04,079 [Executor task launch worker for task 2.0 in stage 1.0 (TID 8)] INFO  org.apache.spark.executor.Executor [] - Running task 2.0 in stage 1.0 (TID 8)
2025-12-22T02:13:04,081 [Executor task launch worker for task 5.0 in stage 1.0 (TID 11)] INFO  org.apache.spark.executor.Executor [] - Running task 5.0 in stage 1.0 (TID 11)
2025-12-22T02:13:04,101 [Executor task launch worker for task 4.0 in stage 1.0 (TID 10)] INFO  org.apache.spark.broadcast.TorrentBroadcast [] - Started reading broadcast variable 4 with 1 pieces (estimated total size 4.0 MiB)
2025-12-22T02:13:04,105 [Executor task launch worker for task 5.0 in stage 1.0 (TID 11)] INFO  org.apache.spark.broadcast.TorrentBroadcast [] - Started reading broadcast variable 4 with 1 pieces (estimated total size 4.0 MiB)
2025-12-22T02:13:04,108 [Executor task launch worker for task 0.0 in stage 1.0 (TID 6)] INFO  org.apache.spark.broadcast.TorrentBroadcast [] - Started reading broadcast variable 4 with 1 pieces (estimated total size 4.0 MiB)
2025-12-22T02:13:04,114 [Executor task launch worker for task 4.0 in stage 1.0 (TID 10)] INFO  org.apache.spark.storage.memory.MemoryStore [] - Block broadcast_4_piece0 stored as bytes in memory (estimated size 8.3 KiB, free 1662.8 MiB)
2025-12-22T02:13:04,119 [dispatcher-BlockManagerMaster] INFO  org.apache.spark.storage.BlockManagerInfo [] - Added broadcast_4_piece0 in memory on 172.20.0.6:34907 (size: 8.3 KiB, free: 1663.1 MiB)
2025-12-22T02:13:04,121 [Executor task launch worker for task 4.0 in stage 1.0 (TID 10)] INFO  org.apache.spark.broadcast.TorrentBroadcast [] - Reading broadcast variable 4 took 19 ms
2025-12-22T02:13:04,121 [Executor task launch worker for task 0.0 in stage 1.0 (TID 6)] INFO  org.apache.spark.storage.memory.MemoryStore [] - Block broadcast_4_piece0 stored as bytes in memory (estimated size 8.3 KiB, free 1662.8 MiB)
2025-12-22T02:13:04,124 [Executor task launch worker for task 5.0 in stage 1.0 (TID 11)] INFO  org.apache.spark.storage.memory.MemoryStore [] - Block broadcast_4_piece0 stored as bytes in memory (estimated size 8.3 KiB, free 1662.8 MiB)
2025-12-22T02:13:04,124 [Executor task launch worker for task 4.0 in stage 1.0 (TID 10)] INFO  org.apache.spark.storage.memory.MemoryStore [] - Block broadcast_4 stored as values in memory (estimated size 17.0 KiB, free 1662.7 MiB)
2025-12-22T02:13:04,126 [dispatcher-BlockManagerMaster] INFO  org.apache.spark.storage.BlockManagerInfo [] - Added broadcast_4_piece0 in memory on 172.20.0.4:44999 (size: 8.3 KiB, free: 1663.1 MiB)
2025-12-22T02:13:04,128 [Executor task launch worker for task 0.0 in stage 1.0 (TID 6)] INFO  org.apache.spark.broadcast.TorrentBroadcast [] - Reading broadcast variable 4 took 19 ms
2025-12-22T02:13:04,128 [dispatcher-BlockManagerMaster] INFO  org.apache.spark.storage.BlockManagerInfo [] - Added broadcast_4_piece0 in memory on 172.20.0.5:45841 (size: 8.3 KiB, free: 1663.1 MiB)
2025-12-22T02:13:04,130 [Executor task launch worker for task 0.0 in stage 1.0 (TID 6)] INFO  org.apache.spark.storage.memory.MemoryStore [] - Block broadcast_4 stored as values in memory (estimated size 17.0 KiB, free 1662.7 MiB)
2025-12-22T02:13:04,131 [Executor task launch worker for task 5.0 in stage 1.0 (TID 11)] INFO  org.apache.spark.broadcast.TorrentBroadcast [] - Reading broadcast variable 4 took 26 ms
2025-12-22T02:13:04,136 [Executor task launch worker for task 5.0 in stage 1.0 (TID 11)] INFO  org.apache.spark.storage.memory.MemoryStore [] - Block broadcast_4 stored as values in memory (estimated size 17.0 KiB, free 1662.7 MiB)
2025-12-22T02:13:04,243 [Executor task launch worker for task 4.0 in stage 1.0 (TID 10)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator [] - Code generated in 32.368973 ms
2025-12-22T02:13:04,250 [Executor task launch worker for task 2.0 in stage 1.0 (TID 8)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator [] - Code generated in 35.062888 ms
2025-12-22T02:13:04,268 [Executor task launch worker for task 3.0 in stage 1.0 (TID 9)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator [] - Code generated in 45.130162 ms
2025-12-22T02:13:04,271 [Executor task launch worker for task 4.0 in stage 1.0 (TID 10)] INFO  org.apache.spark.sql.execution.datasources.FileScanRDD [] - Reading File path: s3a://landing/yelp/yelp_academic_dataset_business.json, range: 82038732-102548415, partition values: [empty row]
2025-12-22T02:13:04,271 [Executor task launch worker for task 1.0 in stage 1.0 (TID 7)] INFO  org.apache.spark.sql.execution.datasources.FileScanRDD [] - Reading File path: s3a://landing/yelp/yelp_academic_dataset_business.json, range: 20509683-41019366, partition values: [empty row]
2025-12-22T02:13:04,278 [Executor task launch worker for task 2.0 in stage 1.0 (TID 8)] INFO  org.apache.spark.sql.execution.datasources.FileScanRDD [] - Reading File path: s3a://landing/yelp/yelp_academic_dataset_business.json, range: 41019366-61529049, partition values: [empty row]
2025-12-22T02:13:04,280 [Executor task launch worker for task 5.0 in stage 1.0 (TID 11)] INFO  org.apache.spark.sql.execution.datasources.FileScanRDD [] - Reading File path: s3a://landing/yelp/yelp_academic_dataset_business.json, range: 102548415-118863795, partition values: [empty row]
2025-12-22T02:13:04,288 [Executor task launch worker for task 4.0 in stage 1.0 (TID 10)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator [] - Code generated in 12.552641 ms
2025-12-22T02:13:04,291 [Executor task launch worker for task 2.0 in stage 1.0 (TID 8)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator [] - Code generated in 10.98776 ms
2025-12-22T02:13:04,294 [Executor task launch worker for task 3.0 in stage 1.0 (TID 9)] INFO  org.apache.spark.sql.execution.datasources.FileScanRDD [] - Reading File path: s3a://landing/yelp/yelp_academic_dataset_business.json, range: 61529049-82038732, partition values: [empty row]
2025-12-22T02:13:04,295 [Executor task launch worker for task 0.0 in stage 1.0 (TID 6)] INFO  org.apache.spark.sql.execution.datasources.FileScanRDD [] - Reading File path: s3a://landing/yelp/yelp_academic_dataset_business.json, range: 0-20509683, partition values: [empty row]
2025-12-22T02:13:04,309 [Executor task launch worker for task 3.0 in stage 1.0 (TID 9)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator [] - Code generated in 11.970273 ms
2025-12-22T02:13:04,321 [Executor task launch worker for task 5.0 in stage 1.0 (TID 11)] INFO  org.apache.spark.broadcast.TorrentBroadcast [] - Started reading broadcast variable 3 with 1 pieces (estimated total size 4.0 MiB)
2025-12-22T02:13:04,322 [Executor task launch worker for task 1.0 in stage 1.0 (TID 7)] INFO  org.apache.spark.broadcast.TorrentBroadcast [] - Started reading broadcast variable 3 with 1 pieces (estimated total size 4.0 MiB)
2025-12-22T02:13:04,335 [Executor task launch worker for task 5.0 in stage 1.0 (TID 11)] INFO  org.apache.spark.storage.memory.MemoryStore [] - Block broadcast_3_piece0 stored as bytes in memory (estimated size 35.3 KiB, free 1662.7 MiB)
2025-12-22T02:13:04,336 [Executor task launch worker for task 1.0 in stage 1.0 (TID 7)] INFO  org.apache.spark.storage.memory.MemoryStore [] - Block broadcast_3_piece0 stored as bytes in memory (estimated size 35.3 KiB, free 1662.7 MiB)
2025-12-22T02:13:04,341 [dispatcher-BlockManagerMaster] INFO  org.apache.spark.storage.BlockManagerInfo [] - Added broadcast_3_piece0 in memory on 172.20.0.5:45841 (size: 35.3 KiB, free: 1663.1 MiB)
2025-12-22T02:13:04,342 [dispatcher-BlockManagerMaster] INFO  org.apache.spark.storage.BlockManagerInfo [] - Added broadcast_3_piece0 in memory on 172.20.0.6:34907 (size: 35.3 KiB, free: 1663.1 MiB)
2025-12-22T02:13:04,344 [Executor task launch worker for task 5.0 in stage 1.0 (TID 11)] INFO  org.apache.spark.broadcast.TorrentBroadcast [] - Reading broadcast variable 3 took 22 ms
2025-12-22T02:13:04,347 [Executor task launch worker for task 1.0 in stage 1.0 (TID 7)] INFO  org.apache.spark.broadcast.TorrentBroadcast [] - Reading broadcast variable 3 took 25 ms
2025-12-22T02:13:04,352 [Executor task launch worker for task 3.0 in stage 1.0 (TID 9)] INFO  org.apache.spark.broadcast.TorrentBroadcast [] - Started reading broadcast variable 3 with 1 pieces (estimated total size 4.0 MiB)
2025-12-22T02:13:04,364 [Executor task launch worker for task 5.0 in stage 1.0 (TID 11)] INFO  org.apache.spark.storage.memory.MemoryStore [] - Block broadcast_3 stored as values in memory (estimated size 381.2 KiB, free 1662.3 MiB)
2025-12-22T02:13:04,372 [Executor task launch worker for task 3.0 in stage 1.0 (TID 9)] INFO  org.apache.spark.storage.memory.MemoryStore [] - Block broadcast_3_piece0 stored as bytes in memory (estimated size 35.3 KiB, free 1662.7 MiB)
2025-12-22T02:13:04,376 [Executor task launch worker for task 1.0 in stage 1.0 (TID 7)] INFO  org.apache.spark.storage.memory.MemoryStore [] - Block broadcast_3 stored as values in memory (estimated size 381.2 KiB, free 1662.3 MiB)
2025-12-22T02:13:04,387 [dispatcher-BlockManagerMaster] INFO  org.apache.spark.storage.BlockManagerInfo [] - Added broadcast_3_piece0 in memory on 172.20.0.4:44999 (size: 35.3 KiB, free: 1663.1 MiB)
2025-12-22T02:13:04,390 [Executor task launch worker for task 3.0 in stage 1.0 (TID 9)] INFO  org.apache.spark.broadcast.TorrentBroadcast [] - Reading broadcast variable 3 took 37 ms
2025-12-22T02:13:04,444 [Executor task launch worker for task 3.0 in stage 1.0 (TID 9)] INFO  org.apache.spark.storage.memory.MemoryStore [] - Block broadcast_3 stored as values in memory (estimated size 381.2 KiB, free 1662.3 MiB)
2025-12-22T02:13:05,302 [Executor task launch worker for task 5.0 in stage 1.0 (TID 11)] INFO  org.apache.spark.executor.Executor [] - Finished task 5.0 in stage 1.0 (TID 11). 1964 bytes result sent to driver
2025-12-22T02:13:05,317 [Executor task launch worker for task 4.0 in stage 1.0 (TID 10)] INFO  org.apache.spark.executor.Executor [] - Finished task 4.0 in stage 1.0 (TID 10). 2007 bytes result sent to driver
2025-12-22T02:13:05,317 [Executor task launch worker for task 1.0 in stage 1.0 (TID 7)] INFO  org.apache.spark.executor.Executor [] - Finished task 1.0 in stage 1.0 (TID 7). 2007 bytes result sent to driver
2025-12-22T02:13:05,318 [task-result-getter-2] INFO  org.apache.spark.scheduler.TaskSetManager [] - Finished task 5.0 in stage 1.0 (TID 11) in 1247 ms on 172.20.0.5 (executor 1) (1/6)
2025-12-22T02:13:05,327 [task-result-getter-3] INFO  org.apache.spark.scheduler.TaskSetManager [] - Finished task 1.0 in stage 1.0 (TID 7) in 1260 ms on 172.20.0.6 (executor 2) (2/6)
2025-12-22T02:13:05,333 [Executor task launch worker for task 2.0 in stage 1.0 (TID 8)] INFO  org.apache.spark.executor.Executor [] - Finished task 2.0 in stage 1.0 (TID 8). 1964 bytes result sent to driver
2025-12-22T02:13:05,335 [task-result-getter-0] INFO  org.apache.spark.scheduler.TaskSetManager [] - Finished task 4.0 in stage 1.0 (TID 10) in 1265 ms on 172.20.0.6 (executor 2) (3/6)
2025-12-22T02:13:05,340 [task-result-getter-1] INFO  org.apache.spark.scheduler.TaskSetManager [] - Finished task 2.0 in stage 1.0 (TID 8) in 1272 ms on 172.20.0.5 (executor 1) (4/6)
2025-12-22T02:13:05,412 [Executor task launch worker for task 0.0 in stage 1.0 (TID 6)] INFO  org.apache.spark.executor.Executor [] - Finished task 0.0 in stage 1.0 (TID 6). 1964 bytes result sent to driver
2025-12-22T02:13:05,412 [Executor task launch worker for task 3.0 in stage 1.0 (TID 9)] INFO  org.apache.spark.executor.Executor [] - Finished task 3.0 in stage 1.0 (TID 9). 1964 bytes result sent to driver
2025-12-22T02:13:05,417 [task-result-getter-2] INFO  org.apache.spark.scheduler.TaskSetManager [] - Finished task 0.0 in stage 1.0 (TID 6) in 1351 ms on 172.20.0.4 (executor 0) (5/6)
2025-12-22T02:13:05,417 [task-result-getter-3] INFO  org.apache.spark.scheduler.TaskSetManager [] - Finished task 3.0 in stage 1.0 (TID 9) in 1348 ms on 172.20.0.4 (executor 0) (6/6)
2025-12-22T02:13:05,417 [task-result-getter-3] INFO  org.apache.spark.scheduler.TaskSchedulerImpl [] - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2025-12-22T02:13:05,419 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.DAGScheduler [] - ShuffleMapStage 1 (count at NativeMethodAccessorImpl.java:0) finished in 1.381 s
2025-12-22T02:13:05,420 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.DAGScheduler [] - looking for newly runnable stages
2025-12-22T02:13:05,421 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.DAGScheduler [] - running: Set()
2025-12-22T02:13:05,421 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.DAGScheduler [] - waiting: Set()
2025-12-22T02:13:05,422 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.DAGScheduler [] - failed: Set()
2025-12-22T02:13:05,486 [Thread-4] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator [] - Code generated in 23.91547 ms
2025-12-22T02:13:05,525 [Thread-4] INFO  org.apache.spark.SparkContext [] - Starting job: count at NativeMethodAccessorImpl.java:0
2025-12-22T02:13:05,529 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.DAGScheduler [] - Got job 2 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
2025-12-22T02:13:05,529 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.DAGScheduler [] - Final stage: ResultStage 3 (count at NativeMethodAccessorImpl.java:0)
2025-12-22T02:13:05,529 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.DAGScheduler [] - Parents of final stage: List(ShuffleMapStage 2)
2025-12-22T02:13:05,530 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.DAGScheduler [] - Missing parents: List()
2025-12-22T02:13:05,532 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.DAGScheduler [] - Submitting ResultStage 3 (MapPartitionsRDD[15] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
2025-12-22T02:13:05,546 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.memory.MemoryStore [] - Block broadcast_5 stored as values in memory (estimated size 12.5 KiB, free 433.6 MiB)
2025-12-22T02:13:05,549 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.memory.MemoryStore [] - Block broadcast_5_piece0 stored as bytes in memory (estimated size 6.0 KiB, free 433.6 MiB)
2025-12-22T02:13:05,550 [dispatcher-BlockManagerMaster] INFO  org.apache.spark.storage.BlockManagerInfo [] - Added broadcast_5_piece0 in memory on e78e7707373c:41515 (size: 6.0 KiB, free: 434.3 MiB)
2025-12-22T02:13:05,552 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext [] - Created broadcast 5 from broadcast at DAGScheduler.scala:1580
2025-12-22T02:13:05,554 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.DAGScheduler [] - Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[15] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
2025-12-22T02:13:05,554 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.TaskSchedulerImpl [] - Adding task set 3.0 with 1 tasks resource profile 0
2025-12-22T02:13:05,562 [dispatcher-CoarseGrainedScheduler] INFO  org.apache.spark.scheduler.TaskSetManager [] - Starting task 0.0 in stage 3.0 (TID 12) (172.20.0.5, executor 1, partition 0, NODE_LOCAL, 7619 bytes) 
2025-12-22T02:13:05,567 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend [] - Got assigned task 12
2025-12-22T02:13:05,568 [Executor task launch worker for task 0.0 in stage 3.0 (TID 12)] INFO  org.apache.spark.executor.Executor [] - Running task 0.0 in stage 3.0 (TID 12)
2025-12-22T02:13:05,576 [Executor task launch worker for task 0.0 in stage 3.0 (TID 12)] INFO  org.apache.spark.MapOutputTrackerWorker [] - Updating epoch to 1 and clearing cache
2025-12-22T02:13:05,578 [Executor task launch worker for task 0.0 in stage 3.0 (TID 12)] INFO  org.apache.spark.broadcast.TorrentBroadcast [] - Started reading broadcast variable 5 with 1 pieces (estimated total size 4.0 MiB)
2025-12-22T02:13:05,589 [Executor task launch worker for task 0.0 in stage 3.0 (TID 12)] INFO  org.apache.spark.storage.memory.MemoryStore [] - Block broadcast_5_piece0 stored as bytes in memory (estimated size 6.0 KiB, free 1662.3 MiB)
2025-12-22T02:13:05,593 [dispatcher-BlockManagerMaster] INFO  org.apache.spark.storage.BlockManagerInfo [] - Added broadcast_5_piece0 in memory on 172.20.0.5:45841 (size: 6.0 KiB, free: 1663.1 MiB)
2025-12-22T02:13:05,595 [Executor task launch worker for task 0.0 in stage 3.0 (TID 12)] INFO  org.apache.spark.broadcast.TorrentBroadcast [] - Reading broadcast variable 5 took 16 ms
2025-12-22T02:13:05,597 [Executor task launch worker for task 0.0 in stage 3.0 (TID 12)] INFO  org.apache.spark.storage.memory.MemoryStore [] - Block broadcast_5 stored as values in memory (estimated size 12.5 KiB, free 1662.3 MiB)
2025-12-22T02:13:05,622 [Executor task launch worker for task 0.0 in stage 3.0 (TID 12)] INFO  org.apache.spark.MapOutputTrackerWorker [] - Don't have map outputs for shuffle 0, fetching them
2025-12-22T02:13:05,625 [Executor task launch worker for task 0.0 in stage 3.0 (TID 12)] INFO  org.apache.spark.MapOutputTrackerWorker [] - Doing the fetch; tracker endpoint = NettyRpcEndpointRef(spark://MapOutputTracker@e78e7707373c:44703)
2025-12-22T02:13:05,632 [dispatcher-event-loop-4] INFO  org.apache.spark.MapOutputTrackerMasterEndpoint [] - Asked to send map output locations for shuffle 0 to 172.20.0.5:38706
2025-12-22T02:13:05,689 [Executor task launch worker for task 0.0 in stage 3.0 (TID 12)] INFO  org.apache.spark.MapOutputTrackerWorker [] - Got the map output locations
2025-12-22T02:13:05,733 [Executor task launch worker for task 0.0 in stage 3.0 (TID 12)] INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator [] - Getting 6 (360.0 B) non-empty blocks including 2 (120.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 4 (240.0 B) remote blocks
2025-12-22T02:13:05,741 [Executor task launch worker for task 0.0 in stage 3.0 (TID 12)] INFO  org.apache.spark.network.client.TransportClientFactory [] - Successfully created connection to /172.20.0.6:34907 after 3 ms (0 ms spent in bootstraps)
2025-12-22T02:13:05,751 [Executor task launch worker for task 0.0 in stage 3.0 (TID 12)] INFO  org.apache.spark.network.client.TransportClientFactory [] - Successfully created connection to /172.20.0.4:44999 after 1 ms (0 ms spent in bootstraps)
2025-12-22T02:13:05,754 [Executor task launch worker for task 0.0 in stage 3.0 (TID 12)] INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator [] - Started 2 remote fetches in 41 ms
2025-12-22T02:13:05,782 [Executor task launch worker for task 0.0 in stage 3.0 (TID 12)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator [] - Code generated in 17.433512 ms
2025-12-22T02:13:05,811 [Executor task launch worker for task 0.0 in stage 3.0 (TID 12)] INFO  org.apache.spark.executor.Executor [] - Finished task 0.0 in stage 3.0 (TID 12). 4038 bytes result sent to driver
2025-12-22T02:13:05,825 [task-result-getter-0] INFO  org.apache.spark.scheduler.TaskSetManager [] - Finished task 0.0 in stage 3.0 (TID 12) in 265 ms on 172.20.0.5 (executor 1) (1/1)
2025-12-22T02:13:05,826 [task-result-getter-0] INFO  org.apache.spark.scheduler.TaskSchedulerImpl [] - Removed TaskSet 3.0, whose tasks have all completed, from pool 
2025-12-22T02:13:05,828 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.DAGScheduler [] - ResultStage 3 (count at NativeMethodAccessorImpl.java:0) finished in 0.284 s
2025-12-22T02:13:05,828 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.DAGScheduler [] - Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
2025-12-22T02:13:05,829 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.TaskSchedulerImpl [] - Killing all running tasks in stage 3: Stage finished
2025-12-22T02:13:05,829 [Thread-4] INFO  org.apache.spark.scheduler.DAGScheduler [] - Job 2 finished: count at NativeMethodAccessorImpl.java:0, took 0.303538 s
2025-12-22T02:13:05,843 [Thread-4] INFO  org.apache.spark.SparkContext [] - SparkContext is stopping with exitCode 0.
2025-12-22T02:13:05,861 [Thread-4] INFO  org.sparkproject.jetty.server.AbstractConnector [] - Stopped Spark@2d0e4a66{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2025-12-22T02:13:05,866 [Thread-4] INFO  org.apache.spark.ui.SparkUI [] - Stopped Spark web UI at http://e78e7707373c:4040
2025-12-22T02:13:05,874 [Thread-4] INFO  org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend [] - Shutting down all executors
2025-12-22T02:13:05,875 [dispatcher-CoarseGrainedScheduler] INFO  org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend$StandaloneDriverEndpoint [] - Asking each executor to shut down
2025-12-22T02:13:05,885 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend [] - Driver commanded a shutdown
2025-12-22T02:13:05,885 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend [] - Driver commanded a shutdown
2025-12-22T02:13:05,889 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend [] - Driver commanded a shutdown
2025-12-22T02:13:05,899 [dispatcher-event-loop-0] INFO  org.apache.spark.deploy.master.Master [] - Received unregister request from application app-20251222021252-0000
2025-12-22T02:13:05,902 [dispatcher-event-loop-0] INFO  org.apache.spark.deploy.master.Master [] - Removing app app-20251222021252-0000
2025-12-22T02:13:05,929 [CoarseGrainedExecutorBackend-stop-executor] INFO  org.apache.spark.storage.memory.MemoryStore [] - MemoryStore cleared
2025-12-22T02:13:05,930 [CoarseGrainedExecutorBackend-stop-executor] INFO  org.apache.spark.storage.BlockManager [] - BlockManager stopped
2025-12-22T02:13:05,931 [CoarseGrainedExecutorBackend-stop-executor] INFO  org.apache.spark.storage.memory.MemoryStore [] - MemoryStore cleared
2025-12-22T02:13:05,932 [CoarseGrainedExecutorBackend-stop-executor] INFO  org.apache.spark.storage.BlockManager [] - BlockManager stopped
2025-12-22T02:13:05,933 [CoarseGrainedExecutorBackend-stop-executor] INFO  org.apache.spark.storage.memory.MemoryStore [] - MemoryStore cleared
2025-12-22T02:13:05,934 [CoarseGrainedExecutorBackend-stop-executor] INFO  org.apache.spark.storage.BlockManager [] - BlockManager stopped
2025-12-22T02:13:05,933 [dispatcher-event-loop-6] INFO  org.apache.spark.MapOutputTrackerMasterEndpoint [] - MapOutputTrackerMasterEndpoint stopped!
2025-12-22T02:13:05,946 [dispatcher-event-loop-7] INFO  org.apache.spark.deploy.worker.Worker [] - Asked to kill executor app-20251222021252-0000/2
2025-12-22T02:13:05,950 [dispatcher-event-loop-7] INFO  org.apache.spark.deploy.worker.Worker [] - Asked to kill executor app-20251222021252-0000/0
2025-12-22T02:13:05,955 [shutdown-hook-0] INFO  org.apache.spark.util.ShutdownHookManager [] - Shutdown hook called
2025-12-22T02:13:05,958 [shutdown-hook-0] INFO  org.apache.spark.util.ShutdownHookManager [] - Shutdown hook called
2025-12-22T02:13:05,956 [dispatcher-event-loop-7] INFO  org.apache.spark.deploy.worker.Worker [] - Asked to kill executor app-20251222021252-0000/1
2025-12-22T02:13:05,950 [ExecutorRunner for app-20251222021252-0000/2] INFO  org.apache.spark.deploy.worker.ExecutorRunner [] - Runner thread for executor app-20251222021252-0000/2 interrupted
2025-12-22T02:13:05,961 [ExecutorRunner for app-20251222021252-0000/2] INFO  org.apache.spark.deploy.worker.ExecutorRunner [] - Killing process!
2025-12-22T02:13:05,954 [ExecutorRunner for app-20251222021252-0000/0] INFO  org.apache.spark.deploy.worker.ExecutorRunner [] - Runner thread for executor app-20251222021252-0000/0 interrupted
2025-12-22T02:13:05,967 [shutdown-hook-0] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl [] - Stopping s3a-file-system metrics system...
2025-12-22T02:13:05,967 [shutdown-hook-0] INFO  org.apache.spark.util.ShutdownHookManager [] - Shutdown hook called
2025-12-22T02:13:05,968 [shutdown-hook-0] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl [] - s3a-file-system metrics system stopped.
2025-12-22T02:13:05,968 [shutdown-hook-0] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl [] - s3a-file-system metrics system shutdown complete.
2025-12-22T02:13:05,971 [shutdown-hook-0] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl [] - Stopping s3a-file-system metrics system...
2025-12-22T02:13:05,972 [SIGTERM handler] ERROR org.apache.spark.executor.CoarseGrainedExecutorBackend [] - RECEIVED SIGNAL TERM
2025-12-22T02:13:05,973 [shutdown-hook-0] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl [] - s3a-file-system metrics system stopped.
2025-12-22T02:13:05,973 [shutdown-hook-0] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl [] - s3a-file-system metrics system shutdown complete.
2025-12-22T02:13:05,971 [ExecutorRunner for app-20251222021252-0000/1] INFO  org.apache.spark.deploy.worker.ExecutorRunner [] - Runner thread for executor app-20251222021252-0000/1 interrupted
2025-12-22T02:13:05,975 [ExecutorRunner for app-20251222021252-0000/0] INFO  org.apache.spark.deploy.worker.ExecutorRunner [] - Killing process!
2025-12-22T02:13:05,976 [shutdown-hook-0] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl [] - Stopping s3a-file-system metrics system...
2025-12-22T02:13:05,977 [shutdown-hook-0] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl [] - s3a-file-system metrics system stopped.
2025-12-22T02:13:05,978 [shutdown-hook-0] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl [] - s3a-file-system metrics system shutdown complete.
2025-12-22T02:13:05,976 [ExecutorRunner for app-20251222021252-0000/1] INFO  org.apache.spark.deploy.worker.ExecutorRunner [] - Killing process!
2025-12-22T02:13:05,983 [SIGTERM handler] ERROR org.apache.spark.executor.CoarseGrainedExecutorBackend [] - RECEIVED SIGNAL TERM
2025-12-22T02:13:05,984 [SIGTERM handler] ERROR org.apache.spark.executor.CoarseGrainedExecutorBackend [] - RECEIVED SIGNAL TERM
2025-12-22T02:13:05,988 [Thread-4] INFO  org.apache.spark.storage.memory.MemoryStore [] - MemoryStore cleared
2025-12-22T02:13:05,990 [Thread-4] INFO  org.apache.spark.storage.BlockManager [] - BlockManager stopped
2025-12-22T02:13:06,006 [Thread-4] INFO  org.apache.spark.storage.BlockManagerMaster [] - BlockManagerMaster stopped
2025-12-22T02:13:06,009 [dispatcher-event-loop-8] INFO  org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint [] - OutputCommitCoordinator stopped!
2025-12-22T02:13:06,025 [dispatcher-event-loop-4] INFO  org.apache.spark.deploy.master.Master [] - 172.20.0.3:48376 got disassociated, removing it.
2025-12-22T02:13:06,029 [dispatcher-event-loop-4] INFO  org.apache.spark.deploy.master.Master [] - e78e7707373c:44703 got disassociated, removing it.
2025-12-22T02:13:06,031 [Thread-4] INFO  org.apache.spark.SparkContext [] - Successfully stopped SparkContext
2025-12-22T02:13:06,065 [dispatcher-event-loop-7] WARN  org.apache.spark.deploy.master.Master [] - Got status update for unknown executor app-20251222021252-0000/1
2025-12-22T02:13:06,068 [dispatcher-event-loop-10] INFO  org.apache.spark.deploy.worker.Worker [] - Executor app-20251222021252-0000/1 finished with state KILLED exitStatus 0
2025-12-22T02:13:06,069 [dispatcher-event-loop-10] INFO  org.apache.spark.network.shuffle.ExternalShuffleBlockResolver [] - Clean up non-shuffle and non-RDD files associated with the finished executor 1
2025-12-22T02:13:06,071 [dispatcher-event-loop-10] INFO  org.apache.spark.network.shuffle.ExternalShuffleBlockResolver [] - Executor is not registered (appId=app-20251222021252-0000, execId=1)
2025-12-22T02:13:06,075 [worker-cleanup-thread] INFO  org.apache.spark.deploy.worker.Worker [] - Cleaning up local directories for application app-20251222021252-0000
2025-12-22T02:13:06,075 [dispatcher-event-loop-10] INFO  org.apache.spark.network.shuffle.ExternalShuffleBlockResolver [] - Application app-20251222021252-0000 removed, cleanupLocalDirs = true
2025-12-22T02:13:06,085 [dispatcher-event-loop-9] WARN  org.apache.spark.deploy.master.Master [] - Got status update for unknown executor app-20251222021252-0000/2
2025-12-22T02:13:06,086 [dispatcher-event-loop-10] INFO  org.apache.spark.deploy.worker.Worker [] - Executor app-20251222021252-0000/2 finished with state KILLED exitStatus 0
2025-12-22T02:13:06,089 [dispatcher-event-loop-10] INFO  org.apache.spark.network.shuffle.ExternalShuffleBlockResolver [] - Clean up non-shuffle and non-RDD files associated with the finished executor 2
2025-12-22T02:13:06,089 [dispatcher-event-loop-10] INFO  org.apache.spark.network.shuffle.ExternalShuffleBlockResolver [] - Executor is not registered (appId=app-20251222021252-0000, execId=2)
2025-12-22T02:13:06,090 [dispatcher-event-loop-12] WARN  org.apache.spark.deploy.master.Master [] - Got status update for unknown executor app-20251222021252-0000/0
2025-12-22T02:13:06,092 [dispatcher-event-loop-10] INFO  org.apache.spark.deploy.worker.Worker [] - Executor app-20251222021252-0000/0 finished with state KILLED exitStatus 0
2025-12-22T02:13:06,093 [worker-cleanup-thread] INFO  org.apache.spark.deploy.worker.Worker [] - Cleaning up local directories for application app-20251222021252-0000
2025-12-22T02:13:06,095 [dispatcher-event-loop-10] INFO  org.apache.spark.network.shuffle.ExternalShuffleBlockResolver [] - Clean up non-shuffle and non-RDD files associated with the finished executor 0
2025-12-22T02:13:06,095 [dispatcher-event-loop-10] INFO  org.apache.spark.network.shuffle.ExternalShuffleBlockResolver [] - Application app-20251222021252-0000 removed, cleanupLocalDirs = true
2025-12-22T02:13:06,097 [dispatcher-event-loop-10] INFO  org.apache.spark.network.shuffle.ExternalShuffleBlockResolver [] - Executor is not registered (appId=app-20251222021252-0000, execId=0)
2025-12-22T02:13:06,101 [dispatcher-event-loop-10] INFO  org.apache.spark.network.shuffle.ExternalShuffleBlockResolver [] - Application app-20251222021252-0000 removed, cleanupLocalDirs = true
2025-12-22T02:13:06,101 [worker-cleanup-thread] INFO  org.apache.spark.deploy.worker.Worker [] - Cleaning up local directories for application app-20251222021252-0000
2025-12-22T02:13:06,451 [shutdown-hook-0] INFO  org.apache.spark.util.ShutdownHookManager [] - Shutdown hook called
2025-12-22T02:13:06,452 [shutdown-hook-0] INFO  org.apache.spark.util.ShutdownHookManager [] - Deleting directory /tmp/spark-c417fe12-799e-460d-b475-3aa4fa8417da/pyspark-ee20aedf-1adb-4127-b587-2387dbd34294
2025-12-22T02:13:06,455 [shutdown-hook-0] INFO  org.apache.spark.util.ShutdownHookManager [] - Deleting directory /tmp/spark-2b8ca596-8f0c-4075-ab65-1fce54708818
2025-12-22T02:13:06,458 [shutdown-hook-0] INFO  org.apache.spark.util.ShutdownHookManager [] - Deleting directory /tmp/spark-c417fe12-799e-460d-b475-3aa4fa8417da
2025-12-22T02:13:06,464 [shutdown-hook-0] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl [] - Stopping s3a-file-system metrics system...
2025-12-22T02:13:06,465 [shutdown-hook-0] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl [] - s3a-file-system metrics system stopped.
2025-12-22T02:13:06,465 [shutdown-hook-0] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl [] - s3a-file-system metrics system shutdown complete.
2025-12-22T02:18:36,420 [Thread-4] INFO  org.apache.spark.SparkContext [] - Running Spark version 3.5.0
2025-12-22T02:18:36,423 [Thread-4] INFO  org.apache.spark.SparkContext [] - OS info Linux, 6.6.87.1-microsoft-standard-WSL2, amd64
2025-12-22T02:18:36,424 [Thread-4] INFO  org.apache.spark.SparkContext [] - Java version 17.0.10
2025-12-22T02:18:36,451 [Thread-4] INFO  org.apache.spark.resource.ResourceUtils [] - ==============================================================
2025-12-22T02:18:36,451 [Thread-4] INFO  org.apache.spark.resource.ResourceUtils [] - No custom resources configured for spark.driver.
2025-12-22T02:18:36,452 [Thread-4] INFO  org.apache.spark.resource.ResourceUtils [] - ==============================================================
2025-12-22T02:18:36,453 [Thread-4] INFO  org.apache.spark.SparkContext [] - Submitted application: etl-rides-json
2025-12-22T02:18:36,474 [Thread-4] INFO  org.apache.spark.resource.ResourceProfile [] - Default ResourceProfile created, executor resources: Map(memory -> name: memory, amount: 3072, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
2025-12-22T02:18:36,480 [Thread-4] INFO  org.apache.spark.resource.ResourceProfile [] - Limiting resource is cpu
2025-12-22T02:18:36,480 [Thread-4] INFO  org.apache.spark.resource.ResourceProfileManager [] - Added ResourceProfile id: 0
2025-12-22T02:18:36,523 [Thread-4] INFO  org.apache.spark.SecurityManager [] - Changing view acls to: root,spark
2025-12-22T02:18:36,523 [Thread-4] INFO  org.apache.spark.SecurityManager [] - Changing modify acls to: root,spark
2025-12-22T02:18:36,524 [Thread-4] INFO  org.apache.spark.SecurityManager [] - Changing view acls groups to: 
2025-12-22T02:18:36,524 [Thread-4] INFO  org.apache.spark.SecurityManager [] - Changing modify acls groups to: 
2025-12-22T02:18:36,525 [Thread-4] INFO  org.apache.spark.SecurityManager [] - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, spark; groups with view permissions: EMPTY; users with modify permissions: root, spark; groups with modify permissions: EMPTY
2025-12-22T02:18:36,565 [Thread-4] WARN  org.apache.hadoop.util.NativeCodeLoader [] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2025-12-22T02:18:36,814 [Thread-4] INFO  org.apache.spark.util.Utils [] - Successfully started service 'sparkDriver' on port 37021.
2025-12-22T02:18:36,842 [Thread-4] INFO  org.apache.spark.SparkEnv [] - Registering MapOutputTracker
2025-12-22T02:18:36,874 [Thread-4] INFO  org.apache.spark.SparkEnv [] - Registering BlockManagerMaster
2025-12-22T02:18:36,889 [Thread-4] INFO  org.apache.spark.storage.BlockManagerMasterEndpoint [] - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2025-12-22T02:18:36,890 [Thread-4] INFO  org.apache.spark.storage.BlockManagerMasterEndpoint [] - BlockManagerMasterEndpoint up
2025-12-22T02:18:36,896 [Thread-4] INFO  org.apache.spark.SparkEnv [] - Registering BlockManagerMasterHeartbeat
2025-12-22T02:18:36,921 [Thread-4] INFO  org.apache.spark.storage.DiskBlockManager [] - Created local directory at /tmp/blockmgr-3b20e72b-8290-45b7-a392-8f2c0a6bdd78
2025-12-22T02:18:36,936 [Thread-4] INFO  org.apache.spark.storage.memory.MemoryStore [] - MemoryStore started with capacity 434.4 MiB
2025-12-22T02:18:36,954 [Thread-4] INFO  org.apache.spark.SparkEnv [] - Registering OutputCommitCoordinator
2025-12-22T02:18:36,992 [Thread-4] INFO  org.sparkproject.jetty.util.log [] - Logging initialized @2269ms to org.sparkproject.jetty.util.log.Slf4jLog
2025-12-22T02:18:37,063 [Thread-4] INFO  org.apache.spark.ui.JettyUtils [] - Start Jetty 0.0.0.0:4040 for SparkUI
2025-12-22T02:18:37,076 [Thread-4] INFO  org.sparkproject.jetty.server.Server [] - jetty-9.4.52.v20230823; built: 2023-08-23T19:29:37.669Z; git: abdcda73818a1a2c705da276edb0bf6581e7997e; jvm 17.0.10+13-LTS
2025-12-22T02:18:37,093 [Thread-4] INFO  org.sparkproject.jetty.server.Server [] - Started @2371ms
2025-12-22T02:18:37,121 [Thread-4] INFO  org.sparkproject.jetty.server.AbstractConnector [] - Started ServerConnector@3436b5dd{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2025-12-22T02:18:37,121 [Thread-4] INFO  org.apache.spark.util.Utils [] - Successfully started service 'SparkUI' on port 4040.
2025-12-22T02:18:37,149 [Thread-4] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@43abff12{/,null,AVAILABLE,@Spark}
2025-12-22T02:18:37,241 [appclient-register-master-threadpool-0] INFO  org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint [] - Connecting to master spark://spark-master:7077...
2025-12-22T02:18:37,282 [netty-rpc-connection-0] INFO  org.apache.spark.network.client.TransportClientFactory [] - Successfully created connection to spark-master/172.20.0.3:7077 after 22 ms (0 ms spent in bootstraps)
2025-12-22T02:18:37,353 [dispatcher-event-loop-6] INFO  org.apache.spark.deploy.master.Master [] - Registering app etl-rides-json
2025-12-22T02:18:37,355 [dispatcher-event-loop-6] INFO  org.apache.spark.deploy.master.Master [] - Registered app etl-rides-json with ID app-20251222021837-0001
2025-12-22T02:18:37,357 [dispatcher-event-loop-6] INFO  org.apache.spark.deploy.master.Master [] - Start scheduling for app app-20251222021837-0001 with rpId: 0
2025-12-22T02:18:37,359 [dispatcher-event-loop-6] INFO  org.apache.spark.deploy.master.Master [] - Launching executor app-20251222021837-0001/0 on worker worker-20251222021118-172.20.0.4-42325
2025-12-22T02:18:37,360 [dispatcher-event-loop-6] INFO  org.apache.spark.deploy.master.Master [] - Launching executor app-20251222021837-0001/1 on worker worker-20251222021118-172.20.0.5-37529
2025-12-22T02:18:37,361 [dispatcher-event-loop-6] INFO  org.apache.spark.deploy.master.Master [] - Launching executor app-20251222021837-0001/2 on worker worker-20251222021118-172.20.0.6-36353
2025-12-22T02:18:37,364 [dispatcher-event-loop-12] INFO  org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend [] - Connected to Spark cluster with app ID app-20251222021837-0001
2025-12-22T02:18:37,368 [dispatcher-event-loop-6] INFO  org.apache.spark.deploy.worker.Worker [] - Asked to launch executor app-20251222021837-0001/0 for etl-rides-json
2025-12-22T02:18:37,368 [dispatcher-event-loop-2] INFO  org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint [] - Executor added: app-20251222021837-0001/0 on worker-20251222021118-172.20.0.4-42325 (172.20.0.4:42325) with 2 core(s)
2025-12-22T02:18:37,368 [dispatcher-event-loop-5] INFO  org.apache.spark.deploy.worker.Worker [] - Asked to launch executor app-20251222021837-0001/2 for etl-rides-json
2025-12-22T02:18:37,371 [dispatcher-event-loop-2] INFO  org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend [] - Granted executor ID app-20251222021837-0001/0 on hostPort 172.20.0.4:42325 with 2 core(s), 3.0 GiB RAM
2025-12-22T02:18:37,371 [dispatcher-event-loop-2] INFO  org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint [] - Executor added: app-20251222021837-0001/1 on worker-20251222021118-172.20.0.5-37529 (172.20.0.5:37529) with 2 core(s)
2025-12-22T02:18:37,372 [dispatcher-event-loop-2] INFO  org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend [] - Granted executor ID app-20251222021837-0001/1 on hostPort 172.20.0.5:37529 with 2 core(s), 3.0 GiB RAM
2025-12-22T02:18:37,372 [dispatcher-event-loop-2] INFO  org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint [] - Executor added: app-20251222021837-0001/2 on worker-20251222021118-172.20.0.6-36353 (172.20.0.6:36353) with 2 core(s)
2025-12-22T02:18:37,372 [dispatcher-event-loop-2] INFO  org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend [] - Granted executor ID app-20251222021837-0001/2 on hostPort 172.20.0.6:36353 with 2 core(s), 3.0 GiB RAM
2025-12-22T02:18:37,372 [dispatcher-event-loop-4] INFO  org.apache.spark.deploy.worker.Worker [] - Asked to launch executor app-20251222021837-0001/1 for etl-rides-json
2025-12-22T02:18:37,377 [Thread-4] INFO  org.apache.spark.util.Utils [] - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 38423.
2025-12-22T02:18:37,377 [Thread-4] INFO  org.apache.spark.network.netty.NettyBlockTransferService [] - Server created on e78e7707373c:38423
2025-12-22T02:18:37,378 [Thread-4] INFO  org.apache.spark.storage.BlockManager [] - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2025-12-22T02:18:37,383 [ExecutorRunner for app-20251222021837-0001/2] INFO  org.apache.spark.SecurityManager [] - Changing view acls to: spark
2025-12-22T02:18:37,383 [ExecutorRunner for app-20251222021837-0001/1] INFO  org.apache.spark.SecurityManager [] - Changing view acls to: spark
2025-12-22T02:18:37,383 [ExecutorRunner for app-20251222021837-0001/2] INFO  org.apache.spark.SecurityManager [] - Changing modify acls to: spark
2025-12-22T02:18:37,383 [ExecutorRunner for app-20251222021837-0001/1] INFO  org.apache.spark.SecurityManager [] - Changing modify acls to: spark
2025-12-22T02:18:37,383 [ExecutorRunner for app-20251222021837-0001/2] INFO  org.apache.spark.SecurityManager [] - Changing view acls groups to: 
2025-12-22T02:18:37,384 [ExecutorRunner for app-20251222021837-0001/1] INFO  org.apache.spark.SecurityManager [] - Changing view acls groups to: 
2025-12-22T02:18:37,384 [ExecutorRunner for app-20251222021837-0001/1] INFO  org.apache.spark.SecurityManager [] - Changing modify acls groups to: 
2025-12-22T02:18:37,384 [ExecutorRunner for app-20251222021837-0001/2] INFO  org.apache.spark.SecurityManager [] - Changing modify acls groups to: 
2025-12-22T02:18:37,384 [ExecutorRunner for app-20251222021837-0001/1] INFO  org.apache.spark.SecurityManager [] - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
2025-12-22T02:18:37,384 [ExecutorRunner for app-20251222021837-0001/2] INFO  org.apache.spark.SecurityManager [] - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
2025-12-22T02:18:37,384 [ExecutorRunner for app-20251222021837-0001/0] INFO  org.apache.spark.SecurityManager [] - Changing view acls to: spark
2025-12-22T02:18:37,385 [ExecutorRunner for app-20251222021837-0001/0] INFO  org.apache.spark.SecurityManager [] - Changing modify acls to: spark
2025-12-22T02:18:37,386 [ExecutorRunner for app-20251222021837-0001/0] INFO  org.apache.spark.SecurityManager [] - Changing view acls groups to: 
2025-12-22T02:18:37,386 [ExecutorRunner for app-20251222021837-0001/0] INFO  org.apache.spark.SecurityManager [] - Changing modify acls groups to: 
2025-12-22T02:18:37,387 [ExecutorRunner for app-20251222021837-0001/0] INFO  org.apache.spark.SecurityManager [] - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
2025-12-22T02:18:37,390 [Thread-4] INFO  org.apache.spark.storage.BlockManagerMaster [] - Registering BlockManager BlockManagerId(driver, e78e7707373c, 38423, None)
2025-12-22T02:18:37,396 [dispatcher-BlockManagerMaster] INFO  org.apache.spark.storage.BlockManagerMasterEndpoint [] - Registering block manager e78e7707373c:38423 with 434.4 MiB RAM, BlockManagerId(driver, e78e7707373c, 38423, None)
2025-12-22T02:18:37,400 [Thread-4] INFO  org.apache.spark.storage.BlockManagerMaster [] - Registered BlockManager BlockManagerId(driver, e78e7707373c, 38423, None)
2025-12-22T02:18:37,402 [Thread-4] INFO  org.apache.spark.storage.BlockManager [] - Initialized BlockManager: BlockManagerId(driver, e78e7707373c, 38423, None)
2025-12-22T02:18:37,407 [ExecutorRunner for app-20251222021837-0001/2] INFO  org.apache.spark.deploy.worker.ExecutorRunner [] - Launch command: "/opt/bitnami/java/bin/java" "-cp" "/opt/bitnami/spark/conf/:/opt/bitnami/spark/jars/*" "-Xmx3072M" "-Dspark.driver.port=37021" "-Djava.net.preferIPv6Addresses=false" "-XX:+IgnoreUnrecognizedVMOptions" "--add-opens=java.base/java.lang=ALL-UNNAMED" "--add-opens=java.base/java.lang.invoke=ALL-UNNAMED" "--add-opens=java.base/java.lang.reflect=ALL-UNNAMED" "--add-opens=java.base/java.io=ALL-UNNAMED" "--add-opens=java.base/java.net=ALL-UNNAMED" "--add-opens=java.base/java.nio=ALL-UNNAMED" "--add-opens=java.base/java.util=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED" "--add-opens=java.base/sun.nio.ch=ALL-UNNAMED" "--add-opens=java.base/sun.nio.cs=ALL-UNNAMED" "--add-opens=java.base/sun.security.action=ALL-UNNAMED" "--add-opens=java.base/sun.util.calendar=ALL-UNNAMED" "--add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED" "-Djdk.reflect.useDirectMethodHandle=false" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@e78e7707373c:37021" "--executor-id" "2" "--hostname" "172.20.0.6" "--cores" "2" "--app-id" "app-20251222021837-0001" "--worker-url" "spark://Worker@172.20.0.6:36353" "--resourceProfileId" "0"
2025-12-22T02:18:37,410 [ExecutorRunner for app-20251222021837-0001/1] INFO  org.apache.spark.deploy.worker.ExecutorRunner [] - Launch command: "/opt/bitnami/java/bin/java" "-cp" "/opt/bitnami/spark/conf/:/opt/bitnami/spark/jars/*" "-Xmx3072M" "-Dspark.driver.port=37021" "-Djava.net.preferIPv6Addresses=false" "-XX:+IgnoreUnrecognizedVMOptions" "--add-opens=java.base/java.lang=ALL-UNNAMED" "--add-opens=java.base/java.lang.invoke=ALL-UNNAMED" "--add-opens=java.base/java.lang.reflect=ALL-UNNAMED" "--add-opens=java.base/java.io=ALL-UNNAMED" "--add-opens=java.base/java.net=ALL-UNNAMED" "--add-opens=java.base/java.nio=ALL-UNNAMED" "--add-opens=java.base/java.util=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED" "--add-opens=java.base/sun.nio.ch=ALL-UNNAMED" "--add-opens=java.base/sun.nio.cs=ALL-UNNAMED" "--add-opens=java.base/sun.security.action=ALL-UNNAMED" "--add-opens=java.base/sun.util.calendar=ALL-UNNAMED" "--add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED" "-Djdk.reflect.useDirectMethodHandle=false" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@e78e7707373c:37021" "--executor-id" "1" "--hostname" "172.20.0.5" "--cores" "2" "--app-id" "app-20251222021837-0001" "--worker-url" "spark://Worker@172.20.0.5:37529" "--resourceProfileId" "0"
2025-12-22T02:18:37,412 [ExecutorRunner for app-20251222021837-0001/0] INFO  org.apache.spark.deploy.worker.ExecutorRunner [] - Launch command: "/opt/bitnami/java/bin/java" "-cp" "/opt/bitnami/spark/conf/:/opt/bitnami/spark/jars/*" "-Xmx3072M" "-Dspark.driver.port=37021" "-Djava.net.preferIPv6Addresses=false" "-XX:+IgnoreUnrecognizedVMOptions" "--add-opens=java.base/java.lang=ALL-UNNAMED" "--add-opens=java.base/java.lang.invoke=ALL-UNNAMED" "--add-opens=java.base/java.lang.reflect=ALL-UNNAMED" "--add-opens=java.base/java.io=ALL-UNNAMED" "--add-opens=java.base/java.net=ALL-UNNAMED" "--add-opens=java.base/java.nio=ALL-UNNAMED" "--add-opens=java.base/java.util=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED" "--add-opens=java.base/sun.nio.ch=ALL-UNNAMED" "--add-opens=java.base/sun.nio.cs=ALL-UNNAMED" "--add-opens=java.base/sun.security.action=ALL-UNNAMED" "--add-opens=java.base/sun.util.calendar=ALL-UNNAMED" "--add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED" "-Djdk.reflect.useDirectMethodHandle=false" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@e78e7707373c:37021" "--executor-id" "0" "--hostname" "172.20.0.4" "--cores" "2" "--app-id" "app-20251222021837-0001" "--worker-url" "spark://Worker@172.20.0.4:42325" "--resourceProfileId" "0"
2025-12-22T02:18:37,433 [dispatcher-event-loop-10] INFO  org.apache.spark.deploy.master.Master [] - Start scheduling for app app-20251222021837-0001 with rpId: 0
2025-12-22T02:18:37,444 [dispatcher-event-loop-10] INFO  org.apache.spark.deploy.master.Master [] - Start scheduling for app app-20251222021837-0001 with rpId: 0
2025-12-22T02:18:37,448 [dispatcher-event-loop-10] INFO  org.apache.spark.deploy.master.Master [] - Start scheduling for app app-20251222021837-0001 with rpId: 0
2025-12-22T02:18:37,459 [dispatcher-event-loop-9] INFO  org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint [] - Executor updated: app-20251222021837-0001/2 is now RUNNING
2025-12-22T02:18:37,464 [dispatcher-event-loop-8] INFO  org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint [] - Executor updated: app-20251222021837-0001/1 is now RUNNING
2025-12-22T02:18:37,466 [dispatcher-event-loop-7] INFO  org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint [] - Executor updated: app-20251222021837-0001/0 is now RUNNING
2025-12-22T02:18:37,750 [Thread-4] INFO  org.apache.spark.deploy.history.SingleEventLogFileWriter [] - Logging events to file:/opt/bitnami/spark/logs/events/app-20251222021837-0001.inprogress
2025-12-22T02:18:37,942 [Thread-4] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Stopped o.s.j.s.ServletContextHandler@43abff12{/,null,STOPPED,@Spark}
2025-12-22T02:18:37,944 [Thread-4] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@5a731c16{/jobs,null,AVAILABLE,@Spark}
2025-12-22T02:18:37,945 [Thread-4] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@59bfdc8d{/jobs/json,null,AVAILABLE,@Spark}
2025-12-22T02:18:37,947 [Thread-4] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@7d763815{/jobs/job,null,AVAILABLE,@Spark}
2025-12-22T02:18:37,949 [Thread-4] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@36ec83dd{/jobs/job/json,null,AVAILABLE,@Spark}
2025-12-22T02:18:37,950 [Thread-4] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@76f3790d{/stages,null,AVAILABLE,@Spark}
2025-12-22T02:18:37,954 [Thread-4] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@342329ea{/stages/json,null,AVAILABLE,@Spark}
2025-12-22T02:18:37,957 [Thread-4] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@23097faa{/stages/stage,null,AVAILABLE,@Spark}
2025-12-22T02:18:37,960 [Thread-4] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@6938b9e{/stages/stage/json,null,AVAILABLE,@Spark}
2025-12-22T02:18:37,962 [Thread-4] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@5ffb86a5{/stages/pool,null,AVAILABLE,@Spark}
2025-12-22T02:18:37,965 [Thread-4] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@62aa4a11{/stages/pool/json,null,AVAILABLE,@Spark}
2025-12-22T02:18:37,968 [Thread-4] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@6cd3294b{/storage,null,AVAILABLE,@Spark}
2025-12-22T02:18:37,970 [Thread-4] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@5bee5834{/storage/json,null,AVAILABLE,@Spark}
2025-12-22T02:18:37,977 [Thread-4] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@33a44455{/storage/rdd,null,AVAILABLE,@Spark}
2025-12-22T02:18:37,981 [Thread-4] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@5222277f{/storage/rdd/json,null,AVAILABLE,@Spark}
2025-12-22T02:18:37,983 [Thread-4] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@405b3489{/environment,null,AVAILABLE,@Spark}
2025-12-22T02:18:37,985 [Thread-4] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@5f8764a9{/environment/json,null,AVAILABLE,@Spark}
2025-12-22T02:18:37,988 [Thread-4] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@75be91a2{/executors,null,AVAILABLE,@Spark}
2025-12-22T02:18:37,990 [Thread-4] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@60d86130{/executors/json,null,AVAILABLE,@Spark}
2025-12-22T02:18:37,992 [Thread-4] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@4d609fb1{/executors/threadDump,null,AVAILABLE,@Spark}
2025-12-22T02:18:37,995 [Thread-4] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@1d86897b{/executors/threadDump/json,null,AVAILABLE,@Spark}
2025-12-22T02:18:37,998 [Thread-4] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@97d0e04{/executors/heapHistogram,null,AVAILABLE,@Spark}
2025-12-22T02:18:38,000 [Thread-4] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@3b051827{/executors/heapHistogram/json,null,AVAILABLE,@Spark}
2025-12-22T02:18:38,011 [Thread-4] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@5629c216{/static,null,AVAILABLE,@Spark}
2025-12-22T02:18:38,013 [Thread-4] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@52926fc3{/,null,AVAILABLE,@Spark}
2025-12-22T02:18:38,016 [Thread-4] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@419a8f8f{/api,null,AVAILABLE,@Spark}
2025-12-22T02:18:38,019 [Thread-4] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@3ddc4e7b{/jobs/job/kill,null,AVAILABLE,@Spark}
2025-12-22T02:18:38,022 [Thread-4] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@41da4c7c{/stages/stage/kill,null,AVAILABLE,@Spark}
2025-12-22T02:18:38,029 [Thread-4] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@5d88ee4e{/metrics/json,null,AVAILABLE,@Spark}
2025-12-22T02:18:38,030 [Thread-4] INFO  org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend [] - SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
2025-12-22T02:18:38,338 [Thread-4] INFO  org.apache.spark.sql.internal.SharedState [] - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
2025-12-22T02:18:38,343 [Thread-4] INFO  org.apache.spark.sql.internal.SharedState [] - Warehouse path is 'file:/opt/bitnami/spark/spark-warehouse'.
2025-12-22T02:18:38,366 [Thread-4] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@3846d7b8{/SQL,null,AVAILABLE,@Spark}
2025-12-22T02:18:38,368 [Thread-4] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@5c2cb748{/SQL/json,null,AVAILABLE,@Spark}
2025-12-22T02:18:38,370 [Thread-4] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@f18f3e8{/SQL/execution,null,AVAILABLE,@Spark}
2025-12-22T02:18:38,373 [Thread-4] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@340f9257{/SQL/execution/json,null,AVAILABLE,@Spark}
2025-12-22T02:18:38,376 [Thread-4] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@36fdb17c{/static/sql,null,AVAILABLE,@Spark}
2025-12-22T02:18:38,767 [main] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend [] - Started daemon with process name: 251@e7f2b1a13d24
2025-12-22T02:18:38,779 [main] INFO  org.apache.spark.util.SignalUtils [] - Registering signal handler for TERM
2025-12-22T02:18:38,780 [main] INFO  org.apache.spark.util.SignalUtils [] - Registering signal handler for HUP
2025-12-22T02:18:38,780 [main] INFO  org.apache.spark.util.SignalUtils [] - Registering signal handler for INT
2025-12-22T02:18:38,789 [main] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend [] - Started daemon with process name: 250@74f89a3203f2
2025-12-22T02:18:38,798 [main] INFO  org.apache.spark.util.SignalUtils [] - Registering signal handler for TERM
2025-12-22T02:18:38,799 [main] INFO  org.apache.spark.util.SignalUtils [] - Registering signal handler for HUP
2025-12-22T02:18:38,799 [main] INFO  org.apache.spark.util.SignalUtils [] - Registering signal handler for INT
2025-12-22T02:18:38,801 [main] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend [] - Started daemon with process name: 252@b7a722371209
2025-12-22T02:18:38,812 [main] INFO  org.apache.spark.util.SignalUtils [] - Registering signal handler for TERM
2025-12-22T02:18:38,813 [main] INFO  org.apache.spark.util.SignalUtils [] - Registering signal handler for HUP
2025-12-22T02:18:38,814 [main] INFO  org.apache.spark.util.SignalUtils [] - Registering signal handler for INT
2025-12-22T02:18:39,238 [main] WARN  org.apache.hadoop.util.NativeCodeLoader [] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2025-12-22T02:18:39,264 [main] WARN  org.apache.hadoop.util.NativeCodeLoader [] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2025-12-22T02:18:39,291 [main] WARN  org.apache.hadoop.util.NativeCodeLoader [] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2025-12-22T02:18:39,386 [main] INFO  org.apache.spark.SecurityManager [] - Changing view acls to: spark
2025-12-22T02:18:39,387 [main] INFO  org.apache.spark.SecurityManager [] - Changing modify acls to: spark
2025-12-22T02:18:39,389 [main] INFO  org.apache.spark.SecurityManager [] - Changing view acls groups to: 
2025-12-22T02:18:39,391 [main] INFO  org.apache.spark.SecurityManager [] - Changing modify acls groups to: 
2025-12-22T02:18:39,392 [main] INFO  org.apache.spark.SecurityManager [] - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
2025-12-22T02:18:39,401 [main] INFO  org.apache.spark.SecurityManager [] - Changing view acls to: spark
2025-12-22T02:18:39,402 [main] INFO  org.apache.spark.SecurityManager [] - Changing modify acls to: spark
2025-12-22T02:18:39,403 [main] INFO  org.apache.spark.SecurityManager [] - Changing view acls groups to: 
2025-12-22T02:18:39,404 [main] INFO  org.apache.spark.SecurityManager [] - Changing modify acls groups to: 
2025-12-22T02:18:39,405 [main] INFO  org.apache.spark.SecurityManager [] - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
2025-12-22T02:18:39,440 [main] INFO  org.apache.spark.SecurityManager [] - Changing view acls to: spark
2025-12-22T02:18:39,442 [main] INFO  org.apache.spark.SecurityManager [] - Changing modify acls to: spark
2025-12-22T02:18:39,443 [main] INFO  org.apache.spark.SecurityManager [] - Changing view acls groups to: 
2025-12-22T02:18:39,444 [main] INFO  org.apache.spark.SecurityManager [] - Changing modify acls groups to: 
2025-12-22T02:18:39,445 [main] INFO  org.apache.spark.SecurityManager [] - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
2025-12-22T02:18:39,532 [Thread-4] WARN  org.apache.hadoop.metrics2.impl.MetricsConfig [] - Cannot locate configuration: tried hadoop-metrics2-s3a-file-system.properties,hadoop-metrics2.properties
2025-12-22T02:18:39,550 [Thread-4] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl [] - Scheduled Metric snapshot period at 10 second(s).
2025-12-22T02:18:39,550 [Thread-4] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl [] - s3a-file-system metrics system started
2025-12-22T02:18:39,784 [netty-rpc-connection-0] INFO  org.apache.spark.network.client.TransportClientFactory [] - Successfully created connection to e78e7707373c/172.20.0.3:37021 after 93 ms (0 ms spent in bootstraps)
2025-12-22T02:18:39,786 [netty-rpc-connection-0] INFO  org.apache.spark.network.client.TransportClientFactory [] - Successfully created connection to e78e7707373c/172.20.0.3:37021 after 86 ms (0 ms spent in bootstraps)
2025-12-22T02:18:39,817 [netty-rpc-connection-0] INFO  org.apache.spark.network.client.TransportClientFactory [] - Successfully created connection to e78e7707373c/172.20.0.3:37021 after 93 ms (0 ms spent in bootstraps)
2025-12-22T02:18:39,996 [main] INFO  org.apache.spark.SecurityManager [] - Changing view acls to: spark
2025-12-22T02:18:39,997 [main] INFO  org.apache.spark.SecurityManager [] - Changing modify acls to: spark
2025-12-22T02:18:39,997 [main] INFO  org.apache.spark.SecurityManager [] - Changing view acls groups to: 
2025-12-22T02:18:39,997 [main] INFO  org.apache.spark.SecurityManager [] - Changing modify acls groups to: 
2025-12-22T02:18:39,997 [main] INFO  org.apache.spark.SecurityManager [] - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
2025-12-22T02:18:40,006 [main] INFO  org.apache.spark.SecurityManager [] - Changing view acls to: spark
2025-12-22T02:18:40,006 [main] INFO  org.apache.spark.SecurityManager [] - Changing modify acls to: spark
2025-12-22T02:18:40,006 [main] INFO  org.apache.spark.SecurityManager [] - Changing view acls groups to: 
2025-12-22T02:18:40,006 [main] INFO  org.apache.spark.SecurityManager [] - Changing modify acls groups to: 
2025-12-22T02:18:40,007 [main] INFO  org.apache.spark.SecurityManager [] - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
2025-12-22T02:18:40,034 [main] INFO  org.apache.spark.SecurityManager [] - Changing view acls to: spark
2025-12-22T02:18:40,035 [main] INFO  org.apache.spark.SecurityManager [] - Changing modify acls to: spark
2025-12-22T02:18:40,036 [main] INFO  org.apache.spark.SecurityManager [] - Changing view acls groups to: 
2025-12-22T02:18:40,036 [main] INFO  org.apache.spark.SecurityManager [] - Changing modify acls groups to: 
2025-12-22T02:18:40,036 [main] INFO  org.apache.spark.SecurityManager [] - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
2025-12-22T02:18:40,065 [netty-rpc-connection-0] INFO  org.apache.spark.network.client.TransportClientFactory [] - Successfully created connection to e78e7707373c/172.20.0.3:37021 after 2 ms (0 ms spent in bootstraps)
2025-12-22T02:18:40,071 [netty-rpc-connection-0] INFO  org.apache.spark.network.client.TransportClientFactory [] - Successfully created connection to e78e7707373c/172.20.0.3:37021 after 3 ms (0 ms spent in bootstraps)
2025-12-22T02:18:40,103 [netty-rpc-connection-0] INFO  org.apache.spark.network.client.TransportClientFactory [] - Successfully created connection to e78e7707373c/172.20.0.3:37021 after 3 ms (0 ms spent in bootstraps)
2025-12-22T02:18:40,155 [main] INFO  org.apache.spark.storage.DiskBlockManager [] - Created local directory at /tmp/spark-9a843cda-0109-4a98-94f0-ddd489474289/executor-ee099f6d-389a-49df-ae47-d69d51b85a88/blockmgr-57c0af1a-53dd-4f30-8481-a6fa0cc756a4
2025-12-22T02:18:40,156 [main] INFO  org.apache.spark.storage.DiskBlockManager [] - Created local directory at /tmp/spark-7ee3a3a3-8fc8-47ed-a33b-3f46111677ce/executor-23d0b95e-f862-4fe0-8d96-dd371c776b12/blockmgr-c280aa1d-b34a-4194-94af-2a739c04b57f
2025-12-22T02:18:40,190 [main] INFO  org.apache.spark.storage.DiskBlockManager [] - Created local directory at /tmp/spark-92f73c85-65cf-4360-ab95-59e73798545b/executor-263bf2b7-9289-4866-8af8-7ae7b6b68c5e/blockmgr-b67d28b0-82f5-49e0-a58b-31773689e4d9
2025-12-22T02:18:40,195 [main] INFO  org.apache.spark.storage.memory.MemoryStore [] - MemoryStore started with capacity 1663.2 MiB
2025-12-22T02:18:40,197 [main] INFO  org.apache.spark.storage.memory.MemoryStore [] - MemoryStore started with capacity 1663.2 MiB
2025-12-22T02:18:40,236 [main] INFO  org.apache.spark.storage.memory.MemoryStore [] - MemoryStore started with capacity 1663.2 MiB
2025-12-22T02:18:40,461 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend [] - Connecting to driver: spark://CoarseGrainedScheduler@e78e7707373c:37021
2025-12-22T02:18:40,462 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend [] - Connecting to driver: spark://CoarseGrainedScheduler@e78e7707373c:37021
2025-12-22T02:18:40,464 [main] INFO  org.apache.spark.deploy.worker.WorkerWatcher [] - Connecting to worker spark://Worker@172.20.0.4:42325
2025-12-22T02:18:40,466 [main] INFO  org.apache.spark.deploy.worker.WorkerWatcher [] - Connecting to worker spark://Worker@172.20.0.6:36353
2025-12-22T02:18:40,471 [netty-rpc-connection-1] INFO  org.apache.spark.network.client.TransportClientFactory [] - Successfully created connection to /172.20.0.4:42325 after 4 ms (0 ms spent in bootstraps)
2025-12-22T02:18:40,473 [netty-rpc-connection-1] INFO  org.apache.spark.network.client.TransportClientFactory [] - Successfully created connection to /172.20.0.6:36353 after 4 ms (0 ms spent in bootstraps)
2025-12-22T02:18:40,475 [dispatcher-Executor] INFO  org.apache.spark.resource.ResourceUtils [] - ==============================================================
2025-12-22T02:18:40,475 [dispatcher-event-loop-1] INFO  org.apache.spark.deploy.worker.WorkerWatcher [] - Successfully connected to spark://Worker@172.20.0.6:36353
2025-12-22T02:18:40,476 [dispatcher-Executor] INFO  org.apache.spark.resource.ResourceUtils [] - No custom resources configured for spark.executor.
2025-12-22T02:18:40,477 [dispatcher-Executor] INFO  org.apache.spark.resource.ResourceUtils [] - ==============================================================
2025-12-22T02:18:40,480 [dispatcher-event-loop-1] INFO  org.apache.spark.deploy.worker.WorkerWatcher [] - Successfully connected to spark://Worker@172.20.0.4:42325
2025-12-22T02:18:40,481 [dispatcher-Executor] INFO  org.apache.spark.resource.ResourceUtils [] - ==============================================================
2025-12-22T02:18:40,481 [dispatcher-Executor] INFO  org.apache.spark.resource.ResourceUtils [] - No custom resources configured for spark.executor.
2025-12-22T02:18:40,482 [dispatcher-Executor] INFO  org.apache.spark.resource.ResourceUtils [] - ==============================================================
2025-12-22T02:18:40,511 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend [] - Connecting to driver: spark://CoarseGrainedScheduler@e78e7707373c:37021
2025-12-22T02:18:40,514 [main] INFO  org.apache.spark.deploy.worker.WorkerWatcher [] - Connecting to worker spark://Worker@172.20.0.5:37529
2025-12-22T02:18:40,522 [netty-rpc-connection-1] INFO  org.apache.spark.network.client.TransportClientFactory [] - Successfully created connection to /172.20.0.5:37529 after 6 ms (0 ms spent in bootstraps)
2025-12-22T02:18:40,526 [dispatcher-CoarseGrainedScheduler] INFO  org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend$StandaloneDriverEndpoint [] - Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.20.0.6:40010) with ID 2,  ResourceProfileId 0
2025-12-22T02:18:40,526 [dispatcher-event-loop-1] INFO  org.apache.spark.deploy.worker.WorkerWatcher [] - Successfully connected to spark://Worker@172.20.0.5:37529
2025-12-22T02:18:40,528 [dispatcher-CoarseGrainedScheduler] INFO  org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend$StandaloneDriverEndpoint [] - Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.20.0.4:49456) with ID 0,  ResourceProfileId 0
2025-12-22T02:18:40,529 [dispatcher-Executor] INFO  org.apache.spark.resource.ResourceUtils [] - ==============================================================
2025-12-22T02:18:40,531 [dispatcher-Executor] INFO  org.apache.spark.resource.ResourceUtils [] - No custom resources configured for spark.executor.
2025-12-22T02:18:40,532 [dispatcher-Executor] INFO  org.apache.spark.resource.ResourceUtils [] - ==============================================================
2025-12-22T02:18:40,538 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend [] - Successfully registered with driver
2025-12-22T02:18:40,540 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend [] - Successfully registered with driver
2025-12-22T02:18:40,554 [dispatcher-Executor] INFO  org.apache.spark.executor.Executor [] - Starting executor ID 0 on host 172.20.0.4
2025-12-22T02:18:40,555 [dispatcher-Executor] INFO  org.apache.spark.executor.Executor [] - Starting executor ID 2 on host 172.20.0.6
2025-12-22T02:18:40,556 [dispatcher-Executor] INFO  org.apache.spark.executor.Executor [] - OS info Linux, 6.6.87.1-microsoft-standard-WSL2, amd64
2025-12-22T02:18:40,556 [dispatcher-Executor] INFO  org.apache.spark.executor.Executor [] - OS info Linux, 6.6.87.1-microsoft-standard-WSL2, amd64
2025-12-22T02:18:40,557 [dispatcher-Executor] INFO  org.apache.spark.executor.Executor [] - Java version 17.0.10
2025-12-22T02:18:40,558 [dispatcher-Executor] INFO  org.apache.spark.executor.Executor [] - Java version 17.0.10
2025-12-22T02:18:40,583 [dispatcher-CoarseGrainedScheduler] INFO  org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend$StandaloneDriverEndpoint [] - Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.20.0.5:60646) with ID 1,  ResourceProfileId 0
2025-12-22T02:18:40,613 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend [] - Successfully registered with driver
2025-12-22T02:18:40,619 [dispatcher-Executor] INFO  org.apache.spark.executor.Executor [] - Starting executor ID 1 on host 172.20.0.5
2025-12-22T02:18:40,621 [dispatcher-Executor] INFO  org.apache.spark.executor.Executor [] - OS info Linux, 6.6.87.1-microsoft-standard-WSL2, amd64
2025-12-22T02:18:40,621 [dispatcher-Executor] INFO  org.apache.spark.executor.Executor [] - Java version 17.0.10
2025-12-22T02:18:40,645 [dispatcher-Executor] INFO  org.apache.spark.util.Utils [] - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 40367.
2025-12-22T02:18:40,648 [dispatcher-Executor] INFO  org.apache.spark.network.netty.NettyBlockTransferService [] - Server created on 172.20.0.4:40367
2025-12-22T02:18:40,654 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManager [] - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2025-12-22T02:18:40,670 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManagerMaster [] - Registering BlockManager BlockManagerId(0, 172.20.0.4, 40367, None)
2025-12-22T02:18:40,672 [dispatcher-Executor] INFO  org.apache.spark.util.Utils [] - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 35919.
2025-12-22T02:18:40,673 [dispatcher-Executor] INFO  org.apache.spark.network.netty.NettyBlockTransferService [] - Server created on 172.20.0.6:35919
2025-12-22T02:18:40,677 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManager [] - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2025-12-22T02:18:40,694 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManagerMaster [] - Registering BlockManager BlockManagerId(2, 172.20.0.6, 35919, None)
2025-12-22T02:18:40,697 [dispatcher-BlockManagerMaster] INFO  org.apache.spark.storage.BlockManagerMasterEndpoint [] - Registering block manager 172.20.0.4:40367 with 1663.2 MiB RAM, BlockManagerId(0, 172.20.0.4, 40367, None)
2025-12-22T02:18:40,702 [dispatcher-Executor] INFO  org.apache.spark.util.Utils [] - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 45719.
2025-12-22T02:18:40,703 [dispatcher-Executor] INFO  org.apache.spark.network.netty.NettyBlockTransferService [] - Server created on 172.20.0.5:45719
2025-12-22T02:18:40,705 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManagerMaster [] - Registered BlockManager BlockManagerId(0, 172.20.0.4, 40367, None)
2025-12-22T02:18:40,705 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManager [] - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2025-12-22T02:18:40,707 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManager [] - Initialized BlockManager: BlockManagerId(0, 172.20.0.4, 40367, None)
2025-12-22T02:18:40,709 [dispatcher-BlockManagerMaster] INFO  org.apache.spark.storage.BlockManagerMasterEndpoint [] - Registering block manager 172.20.0.6:35919 with 1663.2 MiB RAM, BlockManagerId(2, 172.20.0.6, 35919, None)
2025-12-22T02:18:40,717 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManagerMaster [] - Registering BlockManager BlockManagerId(1, 172.20.0.5, 45719, None)
2025-12-22T02:18:40,719 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManagerMaster [] - Registered BlockManager BlockManagerId(2, 172.20.0.6, 35919, None)
2025-12-22T02:18:40,722 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManager [] - Initialized BlockManager: BlockManagerId(2, 172.20.0.6, 35919, None)
2025-12-22T02:18:40,729 [dispatcher-Executor] INFO  org.apache.spark.executor.Executor [] - Starting executor with user classpath (userClassPathFirst = false): ''
2025-12-22T02:18:40,731 [dispatcher-Executor] INFO  org.apache.spark.executor.Executor [] - Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@7c7fa1fd for default.
2025-12-22T02:18:40,735 [dispatcher-BlockManagerMaster] INFO  org.apache.spark.storage.BlockManagerMasterEndpoint [] - Registering block manager 172.20.0.5:45719 with 1663.2 MiB RAM, BlockManagerId(1, 172.20.0.5, 45719, None)
2025-12-22T02:18:40,741 [dispatcher-Executor] INFO  org.apache.spark.executor.Executor [] - Starting executor with user classpath (userClassPathFirst = false): ''
2025-12-22T02:18:40,741 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManagerMaster [] - Registered BlockManager BlockManagerId(1, 172.20.0.5, 45719, None)
2025-12-22T02:18:40,743 [dispatcher-Executor] INFO  org.apache.spark.executor.Executor [] - Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@7c7fa1fd for default.
2025-12-22T02:18:40,745 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManager [] - Initialized BlockManager: BlockManagerId(1, 172.20.0.5, 45719, None)
2025-12-22T02:18:40,759 [dispatcher-Executor] INFO  org.apache.spark.executor.Executor [] - Starting executor with user classpath (userClassPathFirst = false): ''
2025-12-22T02:18:40,761 [dispatcher-Executor] INFO  org.apache.spark.executor.Executor [] - Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@78d3a25 for default.
2025-12-22T02:18:40,765 [Thread-4] INFO  org.apache.spark.sql.execution.datasources.InMemoryFileIndex [] - It took 147 ms to list leaf files for 1 paths.
2025-12-22T02:18:40,855 [Thread-4] INFO  org.apache.spark.sql.execution.datasources.InMemoryFileIndex [] - It took 10 ms to list leaf files for 1 paths.
2025-12-22T02:18:42,225 [Thread-4] INFO  org.apache.spark.sql.execution.datasources.FileSourceStrategy [] - Pushed Filters: 
2025-12-22T02:18:42,226 [Thread-4] INFO  org.apache.spark.sql.execution.datasources.FileSourceStrategy [] - Post-Scan Filters: 
2025-12-22T02:18:42,348 [Thread-4] INFO  org.apache.spark.storage.memory.MemoryStore [] - Block broadcast_0 stored as values in memory (estimated size 203.9 KiB, free 434.2 MiB)
2025-12-22T02:18:42,388 [Thread-4] INFO  org.apache.spark.storage.memory.MemoryStore [] - Block broadcast_0_piece0 stored as bytes in memory (estimated size 35.4 KiB, free 434.2 MiB)
2025-12-22T02:18:42,391 [dispatcher-BlockManagerMaster] INFO  org.apache.spark.storage.BlockManagerInfo [] - Added broadcast_0_piece0 in memory on e78e7707373c:38423 (size: 35.4 KiB, free: 434.4 MiB)
2025-12-22T02:18:42,395 [Thread-4] INFO  org.apache.spark.SparkContext [] - Created broadcast 0 from json at NativeMethodAccessorImpl.java:0
2025-12-22T02:18:42,407 [Thread-4] INFO  org.apache.spark.sql.execution.FileSourceScanExec [] - Planning scan with bin packing, max size: 20509683 bytes, open cost is considered as scanning 4194304 bytes.
2025-12-22T02:18:42,510 [Thread-4] INFO  org.apache.spark.SparkContext [] - Starting job: json at NativeMethodAccessorImpl.java:0
2025-12-22T02:18:42,524 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.DAGScheduler [] - Got job 0 (json at NativeMethodAccessorImpl.java:0) with 6 output partitions
2025-12-22T02:18:42,525 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.DAGScheduler [] - Final stage: ResultStage 0 (json at NativeMethodAccessorImpl.java:0)
2025-12-22T02:18:42,526 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.DAGScheduler [] - Parents of final stage: List()
2025-12-22T02:18:42,526 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.DAGScheduler [] - Missing parents: List()
2025-12-22T02:18:42,529 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.DAGScheduler [] - Submitting ResultStage 0 (MapPartitionsRDD[3] at json at NativeMethodAccessorImpl.java:0), which has no missing parents
2025-12-22T02:18:42,586 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.memory.MemoryStore [] - Block broadcast_1 stored as values in memory (estimated size 17.2 KiB, free 434.1 MiB)
2025-12-22T02:18:42,603 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.memory.MemoryStore [] - Block broadcast_1_piece0 stored as bytes in memory (estimated size 8.2 KiB, free 434.1 MiB)
2025-12-22T02:18:42,604 [dispatcher-BlockManagerMaster] INFO  org.apache.spark.storage.BlockManagerInfo [] - Added broadcast_1_piece0 in memory on e78e7707373c:38423 (size: 8.2 KiB, free: 434.4 MiB)
2025-12-22T02:18:42,605 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext [] - Created broadcast 1 from broadcast at DAGScheduler.scala:1580
2025-12-22T02:18:42,618 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.DAGScheduler [] - Submitting 6 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at json at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5))
2025-12-22T02:18:42,621 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.TaskSchedulerImpl [] - Adding task set 0.0 with 6 tasks resource profile 0
2025-12-22T02:18:42,643 [dispatcher-CoarseGrainedScheduler] INFO  org.apache.spark.scheduler.TaskSetManager [] - Starting task 0.0 in stage 0.0 (TID 0) (172.20.0.4, executor 0, partition 0, PROCESS_LOCAL, 8236 bytes) 
2025-12-22T02:18:42,646 [dispatcher-CoarseGrainedScheduler] INFO  org.apache.spark.scheduler.TaskSetManager [] - Starting task 1.0 in stage 0.0 (TID 1) (172.20.0.5, executor 1, partition 1, PROCESS_LOCAL, 8236 bytes) 
2025-12-22T02:18:42,647 [dispatcher-CoarseGrainedScheduler] INFO  org.apache.spark.scheduler.TaskSetManager [] - Starting task 2.0 in stage 0.0 (TID 2) (172.20.0.6, executor 2, partition 2, PROCESS_LOCAL, 8236 bytes) 
2025-12-22T02:18:42,648 [dispatcher-CoarseGrainedScheduler] INFO  org.apache.spark.scheduler.TaskSetManager [] - Starting task 3.0 in stage 0.0 (TID 3) (172.20.0.4, executor 0, partition 3, PROCESS_LOCAL, 8236 bytes) 
2025-12-22T02:18:42,649 [dispatcher-CoarseGrainedScheduler] INFO  org.apache.spark.scheduler.TaskSetManager [] - Starting task 4.0 in stage 0.0 (TID 4) (172.20.0.5, executor 1, partition 4, PROCESS_LOCAL, 8236 bytes) 
2025-12-22T02:18:42,649 [dispatcher-CoarseGrainedScheduler] INFO  org.apache.spark.scheduler.TaskSetManager [] - Starting task 5.0 in stage 0.0 (TID 5) (172.20.0.6, executor 2, partition 5, PROCESS_LOCAL, 8236 bytes) 
2025-12-22T02:18:42,666 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend [] - Got assigned task 1
2025-12-22T02:18:42,667 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend [] - Got assigned task 2
2025-12-22T02:18:42,668 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend [] - Got assigned task 0
2025-12-22T02:18:42,675 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend [] - Got assigned task 5
2025-12-22T02:18:42,675 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend [] - Got assigned task 3
2025-12-22T02:18:42,675 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend [] - Got assigned task 4
2025-12-22T02:18:42,681 [Executor task launch worker for task 4.0 in stage 0.0 (TID 4)] INFO  org.apache.spark.executor.Executor [] - Running task 4.0 in stage 0.0 (TID 4)
2025-12-22T02:18:42,681 [Executor task launch worker for task 1.0 in stage 0.0 (TID 1)] INFO  org.apache.spark.executor.Executor [] - Running task 1.0 in stage 0.0 (TID 1)
2025-12-22T02:18:42,682 [Executor task launch worker for task 5.0 in stage 0.0 (TID 5)] INFO  org.apache.spark.executor.Executor [] - Running task 5.0 in stage 0.0 (TID 5)
2025-12-22T02:18:42,682 [Executor task launch worker for task 2.0 in stage 0.0 (TID 2)] INFO  org.apache.spark.executor.Executor [] - Running task 2.0 in stage 0.0 (TID 2)
2025-12-22T02:18:42,683 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.executor.Executor [] - Running task 0.0 in stage 0.0 (TID 0)
2025-12-22T02:18:42,683 [Executor task launch worker for task 3.0 in stage 0.0 (TID 3)] INFO  org.apache.spark.executor.Executor [] - Running task 3.0 in stage 0.0 (TID 3)
2025-12-22T02:18:42,829 [Executor task launch worker for task 4.0 in stage 0.0 (TID 4)] INFO  org.apache.spark.broadcast.TorrentBroadcast [] - Started reading broadcast variable 1 with 1 pieces (estimated total size 4.0 MiB)
2025-12-22T02:18:42,836 [Executor task launch worker for task 5.0 in stage 0.0 (TID 5)] INFO  org.apache.spark.broadcast.TorrentBroadcast [] - Started reading broadcast variable 1 with 1 pieces (estimated total size 4.0 MiB)
2025-12-22T02:18:42,836 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.broadcast.TorrentBroadcast [] - Started reading broadcast variable 1 with 1 pieces (estimated total size 4.0 MiB)
2025-12-22T02:18:42,887 [Executor task launch worker for task 5.0 in stage 0.0 (TID 5)] INFO  org.apache.spark.network.client.TransportClientFactory [] - Successfully created connection to e78e7707373c/172.20.0.3:38423 after 2 ms (0 ms spent in bootstraps)
2025-12-22T02:18:42,893 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.network.client.TransportClientFactory [] - Successfully created connection to e78e7707373c/172.20.0.3:38423 after 2 ms (0 ms spent in bootstraps)
2025-12-22T02:18:42,897 [Executor task launch worker for task 4.0 in stage 0.0 (TID 4)] INFO  org.apache.spark.network.client.TransportClientFactory [] - Successfully created connection to e78e7707373c/172.20.0.3:38423 after 3 ms (0 ms spent in bootstraps)
2025-12-22T02:18:42,943 [Executor task launch worker for task 5.0 in stage 0.0 (TID 5)] INFO  org.apache.spark.storage.memory.MemoryStore [] - Block broadcast_1_piece0 stored as bytes in memory (estimated size 8.2 KiB, free 1663.2 MiB)
2025-12-22T02:18:42,945 [Executor task launch worker for task 4.0 in stage 0.0 (TID 4)] INFO  org.apache.spark.storage.memory.MemoryStore [] - Block broadcast_1_piece0 stored as bytes in memory (estimated size 8.2 KiB, free 1663.2 MiB)
2025-12-22T02:18:42,946 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.storage.memory.MemoryStore [] - Block broadcast_1_piece0 stored as bytes in memory (estimated size 8.2 KiB, free 1663.2 MiB)
2025-12-22T02:18:42,953 [dispatcher-BlockManagerMaster] INFO  org.apache.spark.storage.BlockManagerInfo [] - Added broadcast_1_piece0 in memory on 172.20.0.5:45719 (size: 8.2 KiB, free: 1663.2 MiB)
2025-12-22T02:18:42,954 [dispatcher-BlockManagerMaster] INFO  org.apache.spark.storage.BlockManagerInfo [] - Added broadcast_1_piece0 in memory on 172.20.0.6:35919 (size: 8.2 KiB, free: 1663.2 MiB)
2025-12-22T02:18:42,955 [dispatcher-BlockManagerMaster] INFO  org.apache.spark.storage.BlockManagerInfo [] - Added broadcast_1_piece0 in memory on 172.20.0.4:40367 (size: 8.2 KiB, free: 1663.2 MiB)
2025-12-22T02:18:42,958 [Executor task launch worker for task 4.0 in stage 0.0 (TID 4)] INFO  org.apache.spark.broadcast.TorrentBroadcast [] - Reading broadcast variable 1 took 128 ms
2025-12-22T02:18:42,960 [Executor task launch worker for task 5.0 in stage 0.0 (TID 5)] INFO  org.apache.spark.broadcast.TorrentBroadcast [] - Reading broadcast variable 1 took 121 ms
2025-12-22T02:18:42,964 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.broadcast.TorrentBroadcast [] - Reading broadcast variable 1 took 125 ms
2025-12-22T02:18:43,027 [Executor task launch worker for task 5.0 in stage 0.0 (TID 5)] INFO  org.apache.spark.storage.memory.MemoryStore [] - Block broadcast_1 stored as values in memory (estimated size 17.2 KiB, free 1663.2 MiB)
2025-12-22T02:18:43,032 [Executor task launch worker for task 4.0 in stage 0.0 (TID 4)] INFO  org.apache.spark.storage.memory.MemoryStore [] - Block broadcast_1 stored as values in memory (estimated size 17.2 KiB, free 1663.2 MiB)
2025-12-22T02:18:43,037 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.storage.memory.MemoryStore [] - Block broadcast_1 stored as values in memory (estimated size 17.2 KiB, free 1663.2 MiB)
2025-12-22T02:18:43,498 [Executor task launch worker for task 5.0 in stage 0.0 (TID 5)] INFO  org.apache.spark.sql.execution.datasources.FileScanRDD [] - Reading File path: s3a://landing/yelp/yelp_academic_dataset_business.json, range: 102548415-118863795, partition values: [empty row]
2025-12-22T02:18:43,498 [Executor task launch worker for task 2.0 in stage 0.0 (TID 2)] INFO  org.apache.spark.sql.execution.datasources.FileScanRDD [] - Reading File path: s3a://landing/yelp/yelp_academic_dataset_business.json, range: 41019366-61529049, partition values: [empty row]
2025-12-22T02:18:43,524 [Executor task launch worker for task 1.0 in stage 0.0 (TID 1)] INFO  org.apache.spark.sql.execution.datasources.FileScanRDD [] - Reading File path: s3a://landing/yelp/yelp_academic_dataset_business.json, range: 20509683-41019366, partition values: [empty row]
2025-12-22T02:18:43,524 [Executor task launch worker for task 4.0 in stage 0.0 (TID 4)] INFO  org.apache.spark.sql.execution.datasources.FileScanRDD [] - Reading File path: s3a://landing/yelp/yelp_academic_dataset_business.json, range: 82038732-102548415, partition values: [empty row]
2025-12-22T02:18:43,558 [Executor task launch worker for task 3.0 in stage 0.0 (TID 3)] INFO  org.apache.spark.sql.execution.datasources.FileScanRDD [] - Reading File path: s3a://landing/yelp/yelp_academic_dataset_business.json, range: 61529049-82038732, partition values: [empty row]
2025-12-22T02:18:43,558 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.sql.execution.datasources.FileScanRDD [] - Reading File path: s3a://landing/yelp/yelp_academic_dataset_business.json, range: 0-20509683, partition values: [empty row]
2025-12-22T02:18:43,870 [Executor task launch worker for task 5.0 in stage 0.0 (TID 5)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator [] - Code generated in 224.396153 ms
2025-12-22T02:18:43,872 [Executor task launch worker for task 5.0 in stage 0.0 (TID 5)] INFO  org.apache.spark.broadcast.TorrentBroadcast [] - Started reading broadcast variable 0 with 1 pieces (estimated total size 4.0 MiB)
2025-12-22T02:18:43,882 [Executor task launch worker for task 5.0 in stage 0.0 (TID 5)] INFO  org.apache.spark.storage.memory.MemoryStore [] - Block broadcast_0_piece0 stored as bytes in memory (estimated size 35.4 KiB, free 1663.1 MiB)
2025-12-22T02:18:43,884 [dispatcher-BlockManagerMaster] INFO  org.apache.spark.storage.BlockManagerInfo [] - Added broadcast_0_piece0 in memory on 172.20.0.6:35919 (size: 35.4 KiB, free: 1663.2 MiB)
2025-12-22T02:18:43,886 [Executor task launch worker for task 5.0 in stage 0.0 (TID 5)] INFO  org.apache.spark.broadcast.TorrentBroadcast [] - Reading broadcast variable 0 took 13 ms
2025-12-22T02:18:43,928 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator [] - Code generated in 221.385015 ms
2025-12-22T02:18:43,929 [Executor task launch worker for task 1.0 in stage 0.0 (TID 1)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator [] - Code generated in 244.421701 ms
2025-12-22T02:18:43,932 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.broadcast.TorrentBroadcast [] - Started reading broadcast variable 0 with 1 pieces (estimated total size 4.0 MiB)
2025-12-22T02:18:43,933 [Executor task launch worker for task 1.0 in stage 0.0 (TID 1)] INFO  org.apache.spark.broadcast.TorrentBroadcast [] - Started reading broadcast variable 0 with 1 pieces (estimated total size 4.0 MiB)
2025-12-22T02:18:43,946 [Executor task launch worker for task 1.0 in stage 0.0 (TID 1)] INFO  org.apache.spark.storage.memory.MemoryStore [] - Block broadcast_0_piece0 stored as bytes in memory (estimated size 35.4 KiB, free 1663.1 MiB)
2025-12-22T02:18:43,947 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.storage.memory.MemoryStore [] - Block broadcast_0_piece0 stored as bytes in memory (estimated size 35.4 KiB, free 1663.1 MiB)
2025-12-22T02:18:43,951 [dispatcher-BlockManagerMaster] INFO  org.apache.spark.storage.BlockManagerInfo [] - Added broadcast_0_piece0 in memory on 172.20.0.5:45719 (size: 35.4 KiB, free: 1663.2 MiB)
2025-12-22T02:18:43,953 [dispatcher-BlockManagerMaster] INFO  org.apache.spark.storage.BlockManagerInfo [] - Added broadcast_0_piece0 in memory on 172.20.0.4:40367 (size: 35.4 KiB, free: 1663.2 MiB)
2025-12-22T02:18:43,954 [Executor task launch worker for task 1.0 in stage 0.0 (TID 1)] INFO  org.apache.spark.broadcast.TorrentBroadcast [] - Reading broadcast variable 0 took 21 ms
2025-12-22T02:18:43,956 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.broadcast.TorrentBroadcast [] - Reading broadcast variable 0 took 23 ms
2025-12-22T02:18:43,959 [Executor task launch worker for task 5.0 in stage 0.0 (TID 5)] INFO  org.apache.spark.storage.memory.MemoryStore [] - Block broadcast_0 stored as values in memory (estimated size 381.2 KiB, free 1662.8 MiB)
2025-12-22T02:18:44,022 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.storage.memory.MemoryStore [] - Block broadcast_0 stored as values in memory (estimated size 381.2 KiB, free 1662.8 MiB)
2025-12-22T02:18:44,035 [Executor task launch worker for task 1.0 in stage 0.0 (TID 1)] INFO  org.apache.spark.storage.memory.MemoryStore [] - Block broadcast_0 stored as values in memory (estimated size 381.2 KiB, free 1662.8 MiB)
2025-12-22T02:18:44,115 [Executor task launch worker for task 2.0 in stage 0.0 (TID 2)] WARN  org.apache.hadoop.metrics2.impl.MetricsConfig [] - Cannot locate configuration: tried hadoop-metrics2-s3a-file-system.properties,hadoop-metrics2.properties
2025-12-22T02:18:44,143 [Executor task launch worker for task 2.0 in stage 0.0 (TID 2)] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl [] - Scheduled Metric snapshot period at 10 second(s).
2025-12-22T02:18:44,143 [Executor task launch worker for task 2.0 in stage 0.0 (TID 2)] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl [] - s3a-file-system metrics system started
2025-12-22T02:18:44,161 [Executor task launch worker for task 3.0 in stage 0.0 (TID 3)] WARN  org.apache.hadoop.metrics2.impl.MetricsConfig [] - Cannot locate configuration: tried hadoop-metrics2-s3a-file-system.properties,hadoop-metrics2.properties
2025-12-22T02:18:44,180 [Executor task launch worker for task 3.0 in stage 0.0 (TID 3)] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl [] - Scheduled Metric snapshot period at 10 second(s).
2025-12-22T02:18:44,180 [Executor task launch worker for task 3.0 in stage 0.0 (TID 3)] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl [] - s3a-file-system metrics system started
2025-12-22T02:18:44,186 [Executor task launch worker for task 1.0 in stage 0.0 (TID 1)] WARN  org.apache.hadoop.metrics2.impl.MetricsConfig [] - Cannot locate configuration: tried hadoop-metrics2-s3a-file-system.properties,hadoop-metrics2.properties
2025-12-22T02:18:44,204 [Executor task launch worker for task 1.0 in stage 0.0 (TID 1)] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl [] - Scheduled Metric snapshot period at 10 second(s).
2025-12-22T02:18:44,205 [Executor task launch worker for task 1.0 in stage 0.0 (TID 1)] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl [] - s3a-file-system metrics system started
2025-12-22T02:18:46,447 [Executor task launch worker for task 5.0 in stage 0.0 (TID 5)] INFO  org.apache.spark.executor.Executor [] - Finished task 5.0 in stage 0.0 (TID 5). 4004 bytes result sent to driver
2025-12-22T02:18:46,492 [task-result-getter-0] INFO  org.apache.spark.scheduler.TaskSetManager [] - Finished task 5.0 in stage 0.0 (TID 5) in 3842 ms on 172.20.0.6 (executor 2) (1/6)
2025-12-22T02:18:46,709 [Executor task launch worker for task 2.0 in stage 0.0 (TID 2)] INFO  org.apache.spark.executor.Executor [] - Finished task 2.0 in stage 0.0 (TID 2). 4004 bytes result sent to driver
2025-12-22T02:18:46,724 [task-result-getter-1] INFO  org.apache.spark.scheduler.TaskSetManager [] - Finished task 2.0 in stage 0.0 (TID 2) in 4078 ms on 172.20.0.6 (executor 2) (2/6)
2025-12-22T02:18:46,848 [Executor task launch worker for task 3.0 in stage 0.0 (TID 3)] INFO  org.apache.spark.executor.Executor [] - Finished task 3.0 in stage 0.0 (TID 3). 4004 bytes result sent to driver
2025-12-22T02:18:46,858 [task-result-getter-2] INFO  org.apache.spark.scheduler.TaskSetManager [] - Finished task 3.0 in stage 0.0 (TID 3) in 4211 ms on 172.20.0.4 (executor 0) (3/6)
2025-12-22T02:18:46,879 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.executor.Executor [] - Finished task 0.0 in stage 0.0 (TID 0). 4004 bytes result sent to driver
2025-12-22T02:18:46,888 [task-result-getter-3] INFO  org.apache.spark.scheduler.TaskSetManager [] - Finished task 0.0 in stage 0.0 (TID 0) in 4254 ms on 172.20.0.4 (executor 0) (4/6)
2025-12-22T02:18:47,035 [Executor task launch worker for task 1.0 in stage 0.0 (TID 1)] INFO  org.apache.spark.executor.Executor [] - Finished task 1.0 in stage 0.0 (TID 1). 4004 bytes result sent to driver
2025-12-22T02:18:47,035 [Executor task launch worker for task 4.0 in stage 0.0 (TID 4)] INFO  org.apache.spark.executor.Executor [] - Finished task 4.0 in stage 0.0 (TID 4). 4004 bytes result sent to driver
2025-12-22T02:18:47,043 [task-result-getter-0] INFO  org.apache.spark.scheduler.TaskSetManager [] - Finished task 4.0 in stage 0.0 (TID 4) in 4395 ms on 172.20.0.5 (executor 1) (5/6)
2025-12-22T02:18:47,044 [task-result-getter-1] INFO  org.apache.spark.scheduler.TaskSetManager [] - Finished task 1.0 in stage 0.0 (TID 1) in 4399 ms on 172.20.0.5 (executor 1) (6/6)
2025-12-22T02:18:47,046 [task-result-getter-1] INFO  org.apache.spark.scheduler.TaskSchedulerImpl [] - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2025-12-22T02:18:47,046 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.DAGScheduler [] - ResultStage 0 (json at NativeMethodAccessorImpl.java:0) finished in 4.503 s
2025-12-22T02:18:47,051 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.DAGScheduler [] - Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
2025-12-22T02:18:47,051 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.TaskSchedulerImpl [] - Killing all running tasks in stage 0: Stage finished
2025-12-22T02:18:47,054 [Thread-4] INFO  org.apache.spark.scheduler.DAGScheduler [] - Job 0 finished: json at NativeMethodAccessorImpl.java:0, took 4.545500 s
2025-12-22T02:18:47,133 [Thread-4] WARN  org.apache.spark.sql.catalyst.util.SparkStringUtils [] - Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.
2025-12-22T02:18:47,173 [Thread-4] INFO  org.apache.spark.sql.execution.datasources.FileSourceStrategy [] - Pushed Filters: 
2025-12-22T02:18:47,174 [Thread-4] INFO  org.apache.spark.sql.execution.datasources.FileSourceStrategy [] - Post-Scan Filters: 
2025-12-22T02:18:47,179 [Thread-4] INFO  org.apache.spark.storage.memory.MemoryStore [] - Block broadcast_2 stored as values in memory (estimated size 203.6 KiB, free 433.9 MiB)
2025-12-22T02:18:47,191 [Thread-4] INFO  org.apache.spark.storage.memory.MemoryStore [] - Block broadcast_2_piece0 stored as bytes in memory (estimated size 35.3 KiB, free 433.9 MiB)
2025-12-22T02:18:47,192 [dispatcher-BlockManagerMaster] INFO  org.apache.spark.storage.BlockManagerInfo [] - Added broadcast_2_piece0 in memory on e78e7707373c:38423 (size: 35.3 KiB, free: 434.3 MiB)
2025-12-22T02:18:47,193 [Thread-4] INFO  org.apache.spark.SparkContext [] - Created broadcast 2 from javaToPython at NativeMethodAccessorImpl.java:0
2025-12-22T02:18:47,197 [Thread-4] INFO  org.apache.spark.sql.execution.FileSourceScanExec [] - Planning scan with bin packing, max size: 20509683 bytes, open cost is considered as scanning 4194304 bytes.
2025-12-22T02:18:47,336 [Thread-4] INFO  org.apache.spark.sql.execution.datasources.FileSourceStrategy [] - Pushed Filters: 
2025-12-22T02:18:47,337 [Thread-4] INFO  org.apache.spark.sql.execution.datasources.FileSourceStrategy [] - Post-Scan Filters: 
2025-12-22T02:18:47,675 [Thread-4] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator [] - Code generated in 169.073979 ms
2025-12-22T02:18:47,680 [Thread-4] INFO  org.apache.spark.storage.memory.MemoryStore [] - Block broadcast_3 stored as values in memory (estimated size 203.6 KiB, free 433.7 MiB)
2025-12-22T02:18:47,688 [Thread-4] INFO  org.apache.spark.storage.memory.MemoryStore [] - Block broadcast_3_piece0 stored as bytes in memory (estimated size 35.3 KiB, free 433.7 MiB)
2025-12-22T02:18:47,689 [dispatcher-BlockManagerMaster] INFO  org.apache.spark.storage.BlockManagerInfo [] - Added broadcast_3_piece0 in memory on e78e7707373c:38423 (size: 35.3 KiB, free: 434.3 MiB)
2025-12-22T02:18:47,690 [Thread-4] INFO  org.apache.spark.SparkContext [] - Created broadcast 3 from count at NativeMethodAccessorImpl.java:0
2025-12-22T02:18:47,692 [Thread-4] INFO  org.apache.spark.sql.execution.FileSourceScanExec [] - Planning scan with bin packing, max size: 20509683 bytes, open cost is considered as scanning 4194304 bytes.
2025-12-22T02:18:47,725 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.DAGScheduler [] - Registering RDD 12 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 0
2025-12-22T02:18:47,730 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.DAGScheduler [] - Got map stage job 1 (count at NativeMethodAccessorImpl.java:0) with 6 output partitions
2025-12-22T02:18:47,731 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.DAGScheduler [] - Final stage: ShuffleMapStage 1 (count at NativeMethodAccessorImpl.java:0)
2025-12-22T02:18:47,731 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.DAGScheduler [] - Parents of final stage: List()
2025-12-22T02:18:47,732 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.DAGScheduler [] - Missing parents: List()
2025-12-22T02:18:47,734 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.DAGScheduler [] - Submitting ShuffleMapStage 1 (MapPartitionsRDD[12] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
2025-12-22T02:18:47,749 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.memory.MemoryStore [] - Block broadcast_4 stored as values in memory (estimated size 17.0 KiB, free 433.7 MiB)
2025-12-22T02:18:47,751 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.memory.MemoryStore [] - Block broadcast_4_piece0 stored as bytes in memory (estimated size 8.3 KiB, free 433.7 MiB)
2025-12-22T02:18:47,752 [dispatcher-BlockManagerMaster] INFO  org.apache.spark.storage.BlockManagerInfo [] - Added broadcast_4_piece0 in memory on e78e7707373c:38423 (size: 8.3 KiB, free: 434.3 MiB)
2025-12-22T02:18:47,753 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext [] - Created broadcast 4 from broadcast at DAGScheduler.scala:1580
2025-12-22T02:18:47,754 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.DAGScheduler [] - Submitting 6 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[12] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5))
2025-12-22T02:18:47,754 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.TaskSchedulerImpl [] - Adding task set 1.0 with 6 tasks resource profile 0
2025-12-22T02:18:47,757 [dispatcher-CoarseGrainedScheduler] INFO  org.apache.spark.scheduler.TaskSetManager [] - Starting task 0.0 in stage 1.0 (TID 6) (172.20.0.4, executor 0, partition 0, PROCESS_LOCAL, 8225 bytes) 
2025-12-22T02:18:47,758 [dispatcher-CoarseGrainedScheduler] INFO  org.apache.spark.scheduler.TaskSetManager [] - Starting task 1.0 in stage 1.0 (TID 7) (172.20.0.5, executor 1, partition 1, PROCESS_LOCAL, 8225 bytes) 
2025-12-22T02:18:47,758 [dispatcher-CoarseGrainedScheduler] INFO  org.apache.spark.scheduler.TaskSetManager [] - Starting task 2.0 in stage 1.0 (TID 8) (172.20.0.6, executor 2, partition 2, PROCESS_LOCAL, 8225 bytes) 
2025-12-22T02:18:47,759 [dispatcher-CoarseGrainedScheduler] INFO  org.apache.spark.scheduler.TaskSetManager [] - Starting task 3.0 in stage 1.0 (TID 9) (172.20.0.4, executor 0, partition 3, PROCESS_LOCAL, 8225 bytes) 
2025-12-22T02:18:47,759 [dispatcher-CoarseGrainedScheduler] INFO  org.apache.spark.scheduler.TaskSetManager [] - Starting task 4.0 in stage 1.0 (TID 10) (172.20.0.5, executor 1, partition 4, PROCESS_LOCAL, 8225 bytes) 
2025-12-22T02:18:47,759 [dispatcher-CoarseGrainedScheduler] INFO  org.apache.spark.scheduler.TaskSetManager [] - Starting task 5.0 in stage 1.0 (TID 11) (172.20.0.6, executor 2, partition 5, PROCESS_LOCAL, 8225 bytes) 
2025-12-22T02:18:47,763 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend [] - Got assigned task 8
2025-12-22T02:18:47,763 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend [] - Got assigned task 6
2025-12-22T02:18:47,764 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend [] - Got assigned task 7
2025-12-22T02:18:47,764 [Executor task launch worker for task 2.0 in stage 1.0 (TID 8)] INFO  org.apache.spark.executor.Executor [] - Running task 2.0 in stage 1.0 (TID 8)
2025-12-22T02:18:47,764 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend [] - Got assigned task 11
2025-12-22T02:18:47,764 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend [] - Got assigned task 9
2025-12-22T02:18:47,764 [Executor task launch worker for task 0.0 in stage 1.0 (TID 6)] INFO  org.apache.spark.executor.Executor [] - Running task 0.0 in stage 1.0 (TID 6)
2025-12-22T02:18:47,765 [Executor task launch worker for task 1.0 in stage 1.0 (TID 7)] INFO  org.apache.spark.executor.Executor [] - Running task 1.0 in stage 1.0 (TID 7)
2025-12-22T02:18:47,765 [Executor task launch worker for task 5.0 in stage 1.0 (TID 11)] INFO  org.apache.spark.executor.Executor [] - Running task 5.0 in stage 1.0 (TID 11)
2025-12-22T02:18:47,767 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend [] - Got assigned task 10
2025-12-22T02:18:47,768 [Executor task launch worker for task 4.0 in stage 1.0 (TID 10)] INFO  org.apache.spark.executor.Executor [] - Running task 4.0 in stage 1.0 (TID 10)
2025-12-22T02:18:47,768 [Executor task launch worker for task 3.0 in stage 1.0 (TID 9)] INFO  org.apache.spark.executor.Executor [] - Running task 3.0 in stage 1.0 (TID 9)
2025-12-22T02:18:47,787 [Executor task launch worker for task 2.0 in stage 1.0 (TID 8)] INFO  org.apache.spark.broadcast.TorrentBroadcast [] - Started reading broadcast variable 4 with 1 pieces (estimated total size 4.0 MiB)
2025-12-22T02:18:47,789 [Executor task launch worker for task 0.0 in stage 1.0 (TID 6)] INFO  org.apache.spark.broadcast.TorrentBroadcast [] - Started reading broadcast variable 4 with 1 pieces (estimated total size 4.0 MiB)
2025-12-22T02:18:47,789 [Executor task launch worker for task 4.0 in stage 1.0 (TID 10)] INFO  org.apache.spark.broadcast.TorrentBroadcast [] - Started reading broadcast variable 4 with 1 pieces (estimated total size 4.0 MiB)
2025-12-22T02:18:47,798 [Executor task launch worker for task 4.0 in stage 1.0 (TID 10)] INFO  org.apache.spark.storage.memory.MemoryStore [] - Block broadcast_4_piece0 stored as bytes in memory (estimated size 8.3 KiB, free 1662.8 MiB)
2025-12-22T02:18:47,798 [Executor task launch worker for task 2.0 in stage 1.0 (TID 8)] INFO  org.apache.spark.storage.memory.MemoryStore [] - Block broadcast_4_piece0 stored as bytes in memory (estimated size 8.3 KiB, free 1662.8 MiB)
2025-12-22T02:18:47,799 [Executor task launch worker for task 0.0 in stage 1.0 (TID 6)] INFO  org.apache.spark.storage.memory.MemoryStore [] - Block broadcast_4_piece0 stored as bytes in memory (estimated size 8.3 KiB, free 1662.8 MiB)
2025-12-22T02:18:47,803 [dispatcher-BlockManagerMaster] INFO  org.apache.spark.storage.BlockManagerInfo [] - Added broadcast_4_piece0 in memory on 172.20.0.5:45719 (size: 8.3 KiB, free: 1663.1 MiB)
2025-12-22T02:18:47,804 [dispatcher-BlockManagerMaster] INFO  org.apache.spark.storage.BlockManagerInfo [] - Added broadcast_4_piece0 in memory on 172.20.0.6:35919 (size: 8.3 KiB, free: 1663.1 MiB)
2025-12-22T02:18:47,805 [dispatcher-BlockManagerMaster] INFO  org.apache.spark.storage.BlockManagerInfo [] - Added broadcast_4_piece0 in memory on 172.20.0.4:40367 (size: 8.3 KiB, free: 1663.1 MiB)
2025-12-22T02:18:47,805 [Executor task launch worker for task 4.0 in stage 1.0 (TID 10)] INFO  org.apache.spark.broadcast.TorrentBroadcast [] - Reading broadcast variable 4 took 15 ms
2025-12-22T02:18:47,806 [Executor task launch worker for task 2.0 in stage 1.0 (TID 8)] INFO  org.apache.spark.broadcast.TorrentBroadcast [] - Reading broadcast variable 4 took 18 ms
2025-12-22T02:18:47,807 [Executor task launch worker for task 0.0 in stage 1.0 (TID 6)] INFO  org.apache.spark.broadcast.TorrentBroadcast [] - Reading broadcast variable 4 took 17 ms
2025-12-22T02:18:47,808 [Executor task launch worker for task 2.0 in stage 1.0 (TID 8)] INFO  org.apache.spark.storage.memory.MemoryStore [] - Block broadcast_4 stored as values in memory (estimated size 17.0 KiB, free 1662.7 MiB)
2025-12-22T02:18:47,808 [Executor task launch worker for task 4.0 in stage 1.0 (TID 10)] INFO  org.apache.spark.storage.memory.MemoryStore [] - Block broadcast_4 stored as values in memory (estimated size 17.0 KiB, free 1662.7 MiB)
2025-12-22T02:18:47,809 [Executor task launch worker for task 0.0 in stage 1.0 (TID 6)] INFO  org.apache.spark.storage.memory.MemoryStore [] - Block broadcast_4 stored as values in memory (estimated size 17.0 KiB, free 1662.7 MiB)
2025-12-22T02:18:47,895 [Executor task launch worker for task 2.0 in stage 1.0 (TID 8)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator [] - Code generated in 20.31297 ms
2025-12-22T02:18:47,905 [Executor task launch worker for task 1.0 in stage 1.0 (TID 7)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator [] - Code generated in 28.120083 ms
2025-12-22T02:18:47,907 [Executor task launch worker for task 3.0 in stage 1.0 (TID 9)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator [] - Code generated in 29.50061 ms
2025-12-22T02:18:47,910 [Executor task launch worker for task 2.0 in stage 1.0 (TID 8)] INFO  org.apache.spark.sql.execution.datasources.FileScanRDD [] - Reading File path: s3a://landing/yelp/yelp_academic_dataset_business.json, range: 41019366-61529049, partition values: [empty row]
2025-12-22T02:18:47,911 [Executor task launch worker for task 5.0 in stage 1.0 (TID 11)] INFO  org.apache.spark.sql.execution.datasources.FileScanRDD [] - Reading File path: s3a://landing/yelp/yelp_academic_dataset_business.json, range: 102548415-118863795, partition values: [empty row]
2025-12-22T02:18:47,920 [Executor task launch worker for task 2.0 in stage 1.0 (TID 8)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator [] - Code generated in 8.37243 ms
2025-12-22T02:18:47,922 [Executor task launch worker for task 0.0 in stage 1.0 (TID 6)] INFO  org.apache.spark.sql.execution.datasources.FileScanRDD [] - Reading File path: s3a://landing/yelp/yelp_academic_dataset_business.json, range: 0-20509683, partition values: [empty row]
2025-12-22T02:18:47,922 [Executor task launch worker for task 3.0 in stage 1.0 (TID 9)] INFO  org.apache.spark.sql.execution.datasources.FileScanRDD [] - Reading File path: s3a://landing/yelp/yelp_academic_dataset_business.json, range: 61529049-82038732, partition values: [empty row]
2025-12-22T02:18:47,928 [Executor task launch worker for task 4.0 in stage 1.0 (TID 10)] INFO  org.apache.spark.sql.execution.datasources.FileScanRDD [] - Reading File path: s3a://landing/yelp/yelp_academic_dataset_business.json, range: 82038732-102548415, partition values: [empty row]
2025-12-22T02:18:47,929 [Executor task launch worker for task 1.0 in stage 1.0 (TID 7)] INFO  org.apache.spark.sql.execution.datasources.FileScanRDD [] - Reading File path: s3a://landing/yelp/yelp_academic_dataset_business.json, range: 20509683-41019366, partition values: [empty row]
2025-12-22T02:18:47,934 [Executor task launch worker for task 3.0 in stage 1.0 (TID 9)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator [] - Code generated in 9.963109 ms
2025-12-22T02:18:47,938 [Executor task launch worker for task 2.0 in stage 1.0 (TID 8)] INFO  org.apache.spark.broadcast.TorrentBroadcast [] - Started reading broadcast variable 3 with 1 pieces (estimated total size 4.0 MiB)
2025-12-22T02:18:47,944 [Executor task launch worker for task 4.0 in stage 1.0 (TID 10)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator [] - Code generated in 13.944128 ms
2025-12-22T02:18:47,948 [Executor task launch worker for task 2.0 in stage 1.0 (TID 8)] INFO  org.apache.spark.storage.memory.MemoryStore [] - Block broadcast_3_piece0 stored as bytes in memory (estimated size 35.3 KiB, free 1662.7 MiB)
2025-12-22T02:18:47,951 [dispatcher-BlockManagerMaster] INFO  org.apache.spark.storage.BlockManagerInfo [] - Added broadcast_3_piece0 in memory on 172.20.0.6:35919 (size: 35.3 KiB, free: 1663.1 MiB)
2025-12-22T02:18:47,953 [Executor task launch worker for task 2.0 in stage 1.0 (TID 8)] INFO  org.apache.spark.broadcast.TorrentBroadcast [] - Reading broadcast variable 3 took 14 ms
2025-12-22T02:18:47,955 [Executor task launch worker for task 0.0 in stage 1.0 (TID 6)] INFO  org.apache.spark.broadcast.TorrentBroadcast [] - Started reading broadcast variable 3 with 1 pieces (estimated total size 4.0 MiB)
2025-12-22T02:18:47,962 [Executor task launch worker for task 0.0 in stage 1.0 (TID 6)] INFO  org.apache.spark.network.client.TransportClientFactory [] - Successfully created connection to /172.20.0.6:35919 after 2 ms (0 ms spent in bootstraps)
2025-12-22T02:18:47,966 [Executor task launch worker for task 2.0 in stage 1.0 (TID 8)] INFO  org.apache.spark.storage.memory.MemoryStore [] - Block broadcast_3 stored as values in memory (estimated size 381.2 KiB, free 1662.3 MiB)
2025-12-22T02:18:47,971 [Executor task launch worker for task 1.0 in stage 1.0 (TID 7)] INFO  org.apache.spark.broadcast.TorrentBroadcast [] - Started reading broadcast variable 3 with 1 pieces (estimated total size 4.0 MiB)
2025-12-22T02:18:47,978 [Executor task launch worker for task 1.0 in stage 1.0 (TID 7)] INFO  org.apache.spark.network.client.TransportClientFactory [] - Successfully created connection to /172.20.0.6:35919 after 1 ms (0 ms spent in bootstraps)
2025-12-22T02:18:47,991 [Executor task launch worker for task 0.0 in stage 1.0 (TID 6)] INFO  org.apache.spark.storage.memory.MemoryStore [] - Block broadcast_3_piece0 stored as bytes in memory (estimated size 35.3 KiB, free 1662.7 MiB)
2025-12-22T02:18:47,994 [Executor task launch worker for task 1.0 in stage 1.0 (TID 7)] INFO  org.apache.spark.storage.memory.MemoryStore [] - Block broadcast_3_piece0 stored as bytes in memory (estimated size 35.3 KiB, free 1662.7 MiB)
2025-12-22T02:18:47,995 [dispatcher-BlockManagerMaster] INFO  org.apache.spark.storage.BlockManagerInfo [] - Added broadcast_3_piece0 in memory on 172.20.0.4:40367 (size: 35.3 KiB, free: 1663.1 MiB)
2025-12-22T02:18:47,997 [dispatcher-BlockManagerMaster] INFO  org.apache.spark.storage.BlockManagerInfo [] - Added broadcast_3_piece0 in memory on 172.20.0.5:45719 (size: 35.3 KiB, free: 1663.1 MiB)
2025-12-22T02:18:47,998 [Executor task launch worker for task 0.0 in stage 1.0 (TID 6)] INFO  org.apache.spark.broadcast.TorrentBroadcast [] - Reading broadcast variable 3 took 42 ms
2025-12-22T02:18:47,999 [Executor task launch worker for task 1.0 in stage 1.0 (TID 7)] INFO  org.apache.spark.broadcast.TorrentBroadcast [] - Reading broadcast variable 3 took 28 ms
2025-12-22T02:18:48,013 [Executor task launch worker for task 0.0 in stage 1.0 (TID 6)] INFO  org.apache.spark.storage.memory.MemoryStore [] - Block broadcast_3 stored as values in memory (estimated size 381.2 KiB, free 1662.3 MiB)
2025-12-22T02:18:48,047 [Executor task launch worker for task 1.0 in stage 1.0 (TID 7)] INFO  org.apache.spark.storage.memory.MemoryStore [] - Block broadcast_3 stored as values in memory (estimated size 381.2 KiB, free 1662.3 MiB)
2025-12-22T02:18:48,555 [Executor task launch worker for task 5.0 in stage 1.0 (TID 11)] INFO  org.apache.spark.executor.Executor [] - Finished task 5.0 in stage 1.0 (TID 11). 2007 bytes result sent to driver
2025-12-22T02:18:48,569 [task-result-getter-2] INFO  org.apache.spark.scheduler.TaskSetManager [] - Finished task 5.0 in stage 1.0 (TID 11) in 810 ms on 172.20.0.6 (executor 2) (1/6)
2025-12-22T02:18:48,591 [Executor task launch worker for task 2.0 in stage 1.0 (TID 8)] INFO  org.apache.spark.executor.Executor [] - Finished task 2.0 in stage 1.0 (TID 8). 1964 bytes result sent to driver
2025-12-22T02:18:48,597 [task-result-getter-3] INFO  org.apache.spark.scheduler.TaskSetManager [] - Finished task 2.0 in stage 1.0 (TID 8) in 838 ms on 172.20.0.6 (executor 2) (2/6)
2025-12-22T02:18:48,802 [Executor task launch worker for task 3.0 in stage 1.0 (TID 9)] INFO  org.apache.spark.executor.Executor [] - Finished task 3.0 in stage 1.0 (TID 9). 1964 bytes result sent to driver
2025-12-22T02:18:48,802 [Executor task launch worker for task 0.0 in stage 1.0 (TID 6)] INFO  org.apache.spark.executor.Executor [] - Finished task 0.0 in stage 1.0 (TID 6). 1964 bytes result sent to driver
2025-12-22T02:18:48,807 [task-result-getter-0] INFO  org.apache.spark.scheduler.TaskSetManager [] - Finished task 3.0 in stage 1.0 (TID 9) in 1049 ms on 172.20.0.4 (executor 0) (3/6)
2025-12-22T02:18:48,808 [task-result-getter-1] INFO  org.apache.spark.scheduler.TaskSetManager [] - Finished task 0.0 in stage 1.0 (TID 6) in 1052 ms on 172.20.0.4 (executor 0) (4/6)
2025-12-22T02:18:48,919 [Executor task launch worker for task 1.0 in stage 1.0 (TID 7)] INFO  org.apache.spark.executor.Executor [] - Finished task 1.0 in stage 1.0 (TID 7). 2007 bytes result sent to driver
2025-12-22T02:18:48,920 [Executor task launch worker for task 4.0 in stage 1.0 (TID 10)] INFO  org.apache.spark.executor.Executor [] - Finished task 4.0 in stage 1.0 (TID 10). 2007 bytes result sent to driver
2025-12-22T02:18:48,923 [task-result-getter-2] INFO  org.apache.spark.scheduler.TaskSetManager [] - Finished task 1.0 in stage 1.0 (TID 7) in 1166 ms on 172.20.0.5 (executor 1) (5/6)
2025-12-22T02:18:48,924 [task-result-getter-3] INFO  org.apache.spark.scheduler.TaskSetManager [] - Finished task 4.0 in stage 1.0 (TID 10) in 1165 ms on 172.20.0.5 (executor 1) (6/6)
2025-12-22T02:18:48,924 [task-result-getter-3] INFO  org.apache.spark.scheduler.TaskSchedulerImpl [] - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2025-12-22T02:18:48,925 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.DAGScheduler [] - ShuffleMapStage 1 (count at NativeMethodAccessorImpl.java:0) finished in 1.186 s
2025-12-22T02:18:48,926 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.DAGScheduler [] - looking for newly runnable stages
2025-12-22T02:18:48,926 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.DAGScheduler [] - running: Set()
2025-12-22T02:18:48,927 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.DAGScheduler [] - waiting: Set()
2025-12-22T02:18:48,927 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.DAGScheduler [] - failed: Set()
2025-12-22T02:18:48,983 [Thread-4] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator [] - Code generated in 14.59444 ms
2025-12-22T02:18:49,028 [Thread-4] INFO  org.apache.spark.SparkContext [] - Starting job: count at NativeMethodAccessorImpl.java:0
2025-12-22T02:18:49,030 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.DAGScheduler [] - Got job 2 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
2025-12-22T02:18:49,031 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.DAGScheduler [] - Final stage: ResultStage 3 (count at NativeMethodAccessorImpl.java:0)
2025-12-22T02:18:49,031 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.DAGScheduler [] - Parents of final stage: List(ShuffleMapStage 2)
2025-12-22T02:18:49,031 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.DAGScheduler [] - Missing parents: List()
2025-12-22T02:18:49,032 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.DAGScheduler [] - Submitting ResultStage 3 (MapPartitionsRDD[15] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
2025-12-22T02:18:49,049 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.memory.MemoryStore [] - Block broadcast_5 stored as values in memory (estimated size 12.5 KiB, free 433.6 MiB)
2025-12-22T02:18:49,054 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.memory.MemoryStore [] - Block broadcast_5_piece0 stored as bytes in memory (estimated size 6.0 KiB, free 433.6 MiB)
2025-12-22T02:18:49,056 [dispatcher-BlockManagerMaster] INFO  org.apache.spark.storage.BlockManagerInfo [] - Added broadcast_5_piece0 in memory on e78e7707373c:38423 (size: 6.0 KiB, free: 434.3 MiB)
2025-12-22T02:18:49,058 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext [] - Created broadcast 5 from broadcast at DAGScheduler.scala:1580
2025-12-22T02:18:49,059 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.DAGScheduler [] - Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[15] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
2025-12-22T02:18:49,059 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.TaskSchedulerImpl [] - Adding task set 3.0 with 1 tasks resource profile 0
2025-12-22T02:18:49,071 [dispatcher-CoarseGrainedScheduler] INFO  org.apache.spark.scheduler.TaskSetManager [] - Starting task 0.0 in stage 3.0 (TID 12) (172.20.0.5, executor 1, partition 0, NODE_LOCAL, 7619 bytes) 
2025-12-22T02:18:49,076 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend [] - Got assigned task 12
2025-12-22T02:18:49,077 [Executor task launch worker for task 0.0 in stage 3.0 (TID 12)] INFO  org.apache.spark.executor.Executor [] - Running task 0.0 in stage 3.0 (TID 12)
2025-12-22T02:18:49,085 [Executor task launch worker for task 0.0 in stage 3.0 (TID 12)] INFO  org.apache.spark.MapOutputTrackerWorker [] - Updating epoch to 1 and clearing cache
2025-12-22T02:18:49,089 [Executor task launch worker for task 0.0 in stage 3.0 (TID 12)] INFO  org.apache.spark.broadcast.TorrentBroadcast [] - Started reading broadcast variable 5 with 1 pieces (estimated total size 4.0 MiB)
2025-12-22T02:18:49,101 [Executor task launch worker for task 0.0 in stage 3.0 (TID 12)] INFO  org.apache.spark.storage.memory.MemoryStore [] - Block broadcast_5_piece0 stored as bytes in memory (estimated size 6.0 KiB, free 1662.3 MiB)
2025-12-22T02:18:49,106 [dispatcher-BlockManagerMaster] INFO  org.apache.spark.storage.BlockManagerInfo [] - Added broadcast_5_piece0 in memory on 172.20.0.5:45719 (size: 6.0 KiB, free: 1663.1 MiB)
2025-12-22T02:18:49,108 [Executor task launch worker for task 0.0 in stage 3.0 (TID 12)] INFO  org.apache.spark.broadcast.TorrentBroadcast [] - Reading broadcast variable 5 took 18 ms
2025-12-22T02:18:49,110 [Executor task launch worker for task 0.0 in stage 3.0 (TID 12)] INFO  org.apache.spark.storage.memory.MemoryStore [] - Block broadcast_5 stored as values in memory (estimated size 12.5 KiB, free 1662.3 MiB)
2025-12-22T02:18:49,138 [Executor task launch worker for task 0.0 in stage 3.0 (TID 12)] INFO  org.apache.spark.MapOutputTrackerWorker [] - Don't have map outputs for shuffle 0, fetching them
2025-12-22T02:18:49,141 [Executor task launch worker for task 0.0 in stage 3.0 (TID 12)] INFO  org.apache.spark.MapOutputTrackerWorker [] - Doing the fetch; tracker endpoint = NettyRpcEndpointRef(spark://MapOutputTracker@e78e7707373c:37021)
2025-12-22T02:18:49,151 [dispatcher-event-loop-2] INFO  org.apache.spark.MapOutputTrackerMasterEndpoint [] - Asked to send map output locations for shuffle 0 to 172.20.0.5:60646
2025-12-22T02:18:49,210 [Executor task launch worker for task 0.0 in stage 3.0 (TID 12)] INFO  org.apache.spark.MapOutputTrackerWorker [] - Got the map output locations
2025-12-22T02:18:49,244 [Executor task launch worker for task 0.0 in stage 3.0 (TID 12)] INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator [] - Getting 6 (360.0 B) non-empty blocks including 2 (120.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 4 (240.0 B) remote blocks
2025-12-22T02:18:49,254 [Executor task launch worker for task 0.0 in stage 3.0 (TID 12)] INFO  org.apache.spark.network.client.TransportClientFactory [] - Successfully created connection to /172.20.0.4:40367 after 1 ms (0 ms spent in bootstraps)
2025-12-22T02:18:49,256 [Executor task launch worker for task 0.0 in stage 3.0 (TID 12)] INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator [] - Started 2 remote fetches in 25 ms
2025-12-22T02:18:49,281 [Executor task launch worker for task 0.0 in stage 3.0 (TID 12)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator [] - Code generated in 18.032337 ms
2025-12-22T02:18:49,298 [Executor task launch worker for task 0.0 in stage 3.0 (TID 12)] INFO  org.apache.spark.executor.Executor [] - Finished task 0.0 in stage 3.0 (TID 12). 4038 bytes result sent to driver
2025-12-22T02:18:49,303 [task-result-getter-0] INFO  org.apache.spark.scheduler.TaskSetManager [] - Finished task 0.0 in stage 3.0 (TID 12) in 233 ms on 172.20.0.5 (executor 1) (1/1)
2025-12-22T02:18:49,303 [task-result-getter-0] INFO  org.apache.spark.scheduler.TaskSchedulerImpl [] - Removed TaskSet 3.0, whose tasks have all completed, from pool 
2025-12-22T02:18:49,304 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.DAGScheduler [] - ResultStage 3 (count at NativeMethodAccessorImpl.java:0) finished in 0.258 s
2025-12-22T02:18:49,304 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.DAGScheduler [] - Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
2025-12-22T02:18:49,304 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.TaskSchedulerImpl [] - Killing all running tasks in stage 3: Stage finished
2025-12-22T02:18:49,304 [Thread-4] INFO  org.apache.spark.scheduler.DAGScheduler [] - Job 2 finished: count at NativeMethodAccessorImpl.java:0, took 0.276093 s
2025-12-22T02:18:49,311 [Thread-4] INFO  org.apache.spark.SparkContext [] - SparkContext is stopping with exitCode 0.
2025-12-22T02:18:49,325 [Thread-4] INFO  org.sparkproject.jetty.server.AbstractConnector [] - Stopped Spark@3436b5dd{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2025-12-22T02:18:49,330 [Thread-4] INFO  org.apache.spark.ui.SparkUI [] - Stopped Spark web UI at http://e78e7707373c:4040
2025-12-22T02:18:49,337 [Thread-4] INFO  org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend [] - Shutting down all executors
2025-12-22T02:18:49,337 [dispatcher-CoarseGrainedScheduler] INFO  org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend$StandaloneDriverEndpoint [] - Asking each executor to shut down
2025-12-22T02:18:49,343 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend [] - Driver commanded a shutdown
2025-12-22T02:18:49,344 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend [] - Driver commanded a shutdown
2025-12-22T02:18:49,344 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend [] - Driver commanded a shutdown
2025-12-22T02:18:49,349 [dispatcher-event-loop-7] INFO  org.apache.spark.deploy.master.Master [] - Received unregister request from application app-20251222021837-0001
2025-12-22T02:18:49,350 [dispatcher-event-loop-7] INFO  org.apache.spark.deploy.master.Master [] - Removing app app-20251222021837-0001
2025-12-22T02:18:49,354 [dispatcher-event-loop-10] INFO  org.apache.spark.deploy.worker.Worker [] - Asked to kill executor app-20251222021837-0001/1
2025-12-22T02:18:49,354 [dispatcher-event-loop-10] INFO  org.apache.spark.deploy.worker.Worker [] - Asked to kill executor app-20251222021837-0001/2
2025-12-22T02:18:49,355 [ExecutorRunner for app-20251222021837-0001/1] INFO  org.apache.spark.deploy.worker.ExecutorRunner [] - Runner thread for executor app-20251222021837-0001/1 interrupted
2025-12-22T02:18:49,355 [ExecutorRunner for app-20251222021837-0001/1] INFO  org.apache.spark.deploy.worker.ExecutorRunner [] - Killing process!
2025-12-22T02:18:49,355 [ExecutorRunner for app-20251222021837-0001/2] INFO  org.apache.spark.deploy.worker.ExecutorRunner [] - Runner thread for executor app-20251222021837-0001/2 interrupted
2025-12-22T02:18:49,356 [ExecutorRunner for app-20251222021837-0001/2] INFO  org.apache.spark.deploy.worker.ExecutorRunner [] - Killing process!
2025-12-22T02:18:49,357 [dispatcher-event-loop-10] INFO  org.apache.spark.deploy.worker.Worker [] - Asked to kill executor app-20251222021837-0001/0
2025-12-22T02:18:49,357 [ExecutorRunner for app-20251222021837-0001/0] INFO  org.apache.spark.deploy.worker.ExecutorRunner [] - Runner thread for executor app-20251222021837-0001/0 interrupted
2025-12-22T02:18:49,358 [ExecutorRunner for app-20251222021837-0001/0] INFO  org.apache.spark.deploy.worker.ExecutorRunner [] - Killing process!
2025-12-22T02:18:49,358 [SIGTERM handler] ERROR org.apache.spark.executor.CoarseGrainedExecutorBackend [] - RECEIVED SIGNAL TERM
2025-12-22T02:18:49,358 [SIGTERM handler] ERROR org.apache.spark.executor.CoarseGrainedExecutorBackend [] - RECEIVED SIGNAL TERM
2025-12-22T02:18:49,360 [SIGTERM handler] ERROR org.apache.spark.executor.CoarseGrainedExecutorBackend [] - RECEIVED SIGNAL TERM
2025-12-22T02:18:49,364 [shutdown-hook-0] INFO  org.apache.spark.storage.DiskBlockManager [] - Shutdown hook called
2025-12-22T02:18:49,365 [dispatcher-event-loop-7] INFO  org.apache.spark.MapOutputTrackerMasterEndpoint [] - MapOutputTrackerMasterEndpoint stopped!
2025-12-22T02:18:49,365 [shutdown-hook-0] INFO  org.apache.spark.util.ShutdownHookManager [] - Shutdown hook called
2025-12-22T02:18:49,367 [shutdown-hook-0] INFO  org.apache.spark.util.ShutdownHookManager [] - Shutdown hook called
2025-12-22T02:18:49,369 [shutdown-hook-0] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl [] - Stopping s3a-file-system metrics system...
2025-12-22T02:18:49,370 [shutdown-hook-0] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl [] - s3a-file-system metrics system stopped.
2025-12-22T02:18:49,371 [shutdown-hook-0] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl [] - s3a-file-system metrics system shutdown complete.
2025-12-22T02:18:49,371 [shutdown-hook-0] INFO  org.apache.spark.util.ShutdownHookManager [] - Shutdown hook called
2025-12-22T02:18:49,371 [shutdown-hook-0] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl [] - Stopping s3a-file-system metrics system...
2025-12-22T02:18:49,372 [shutdown-hook-0] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl [] - s3a-file-system metrics system stopped.
2025-12-22T02:18:49,372 [shutdown-hook-0] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl [] - s3a-file-system metrics system shutdown complete.
2025-12-22T02:18:49,373 [CoarseGrainedExecutorBackend-stop-executor] INFO  org.apache.spark.storage.memory.MemoryStore [] - MemoryStore cleared
2025-12-22T02:18:49,373 [CoarseGrainedExecutorBackend-stop-executor] INFO  org.apache.spark.storage.BlockManager [] - BlockManager stopped
2025-12-22T02:18:49,373 [shutdown-hook-0] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl [] - Stopping s3a-file-system metrics system...
2025-12-22T02:18:49,374 [shutdown-hook-0] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl [] - s3a-file-system metrics system stopped.
2025-12-22T02:18:49,374 [shutdown-hook-0] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl [] - s3a-file-system metrics system shutdown complete.
2025-12-22T02:18:49,375 [CoarseGrainedExecutorBackend-stop-executor] INFO  org.apache.spark.storage.memory.MemoryStore [] - MemoryStore cleared
2025-12-22T02:18:49,375 [CoarseGrainedExecutorBackend-stop-executor] INFO  org.apache.spark.storage.BlockManager [] - BlockManager stopped
2025-12-22T02:18:49,376 [CoarseGrainedExecutorBackend-stop-executor] INFO  org.apache.spark.storage.memory.MemoryStore [] - MemoryStore cleared
2025-12-22T02:18:49,377 [CoarseGrainedExecutorBackend-stop-executor] INFO  org.apache.spark.storage.BlockManager [] - BlockManager stopped
2025-12-22T02:18:49,391 [Thread-4] INFO  org.apache.spark.storage.memory.MemoryStore [] - MemoryStore cleared
2025-12-22T02:18:49,391 [Thread-4] INFO  org.apache.spark.storage.BlockManager [] - BlockManager stopped
2025-12-22T02:18:49,400 [Thread-4] INFO  org.apache.spark.storage.BlockManagerMaster [] - BlockManagerMaster stopped
2025-12-22T02:18:49,403 [dispatcher-event-loop-8] INFO  org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint [] - OutputCommitCoordinator stopped!
2025-12-22T02:18:49,406 [dispatcher-event-loop-12] INFO  org.apache.spark.deploy.master.Master [] - 172.20.0.3:40164 got disassociated, removing it.
2025-12-22T02:18:49,406 [dispatcher-event-loop-12] INFO  org.apache.spark.deploy.master.Master [] - e78e7707373c:37021 got disassociated, removing it.
2025-12-22T02:18:49,413 [Thread-4] INFO  org.apache.spark.SparkContext [] - Successfully stopped SparkContext
2025-12-22T02:18:49,424 [dispatcher-event-loop-0] INFO  org.apache.spark.deploy.worker.Worker [] - Executor app-20251222021837-0001/2 finished with state KILLED exitStatus 143
2025-12-22T02:18:49,424 [dispatcher-event-loop-0] INFO  org.apache.spark.network.shuffle.ExternalShuffleBlockResolver [] - Clean up non-shuffle and non-RDD files associated with the finished executor 2
2025-12-22T02:18:49,425 [dispatcher-event-loop-0] INFO  org.apache.spark.network.shuffle.ExternalShuffleBlockResolver [] - Executor is not registered (appId=app-20251222021837-0001, execId=2)
2025-12-22T02:18:49,425 [dispatcher-event-loop-0] INFO  org.apache.spark.network.shuffle.ExternalShuffleBlockResolver [] - Application app-20251222021837-0001 removed, cleanupLocalDirs = true
2025-12-22T02:18:49,425 [worker-cleanup-thread] INFO  org.apache.spark.deploy.worker.Worker [] - Cleaning up local directories for application app-20251222021837-0001
2025-12-22T02:18:49,425 [dispatcher-event-loop-2] WARN  org.apache.spark.deploy.master.Master [] - Got status update for unknown executor app-20251222021837-0001/2
2025-12-22T02:18:49,433 [dispatcher-event-loop-1] INFO  org.apache.spark.deploy.worker.Worker [] - Executor app-20251222021837-0001/0 finished with state KILLED exitStatus 143
2025-12-22T02:18:49,434 [dispatcher-event-loop-1] INFO  org.apache.spark.network.shuffle.ExternalShuffleBlockResolver [] - Clean up non-shuffle and non-RDD files associated with the finished executor 0
2025-12-22T02:18:49,434 [dispatcher-event-loop-1] INFO  org.apache.spark.network.shuffle.ExternalShuffleBlockResolver [] - Executor is not registered (appId=app-20251222021837-0001, execId=0)
2025-12-22T02:18:49,435 [dispatcher-event-loop-1] INFO  org.apache.spark.network.shuffle.ExternalShuffleBlockResolver [] - Application app-20251222021837-0001 removed, cleanupLocalDirs = true
2025-12-22T02:18:49,435 [worker-cleanup-thread] INFO  org.apache.spark.deploy.worker.Worker [] - Cleaning up local directories for application app-20251222021837-0001
2025-12-22T02:18:49,436 [dispatcher-event-loop-1] WARN  org.apache.spark.deploy.master.Master [] - Got status update for unknown executor app-20251222021837-0001/0
2025-12-22T02:18:49,437 [dispatcher-event-loop-0] INFO  org.apache.spark.deploy.worker.Worker [] - Executor app-20251222021837-0001/1 finished with state KILLED exitStatus 143
2025-12-22T02:18:49,438 [dispatcher-event-loop-0] INFO  org.apache.spark.network.shuffle.ExternalShuffleBlockResolver [] - Clean up non-shuffle and non-RDD files associated with the finished executor 1
2025-12-22T02:18:49,438 [dispatcher-event-loop-0] INFO  org.apache.spark.network.shuffle.ExternalShuffleBlockResolver [] - Executor is not registered (appId=app-20251222021837-0001, execId=1)
2025-12-22T02:18:49,438 [dispatcher-event-loop-0] INFO  org.apache.spark.network.shuffle.ExternalShuffleBlockResolver [] - Application app-20251222021837-0001 removed, cleanupLocalDirs = true
2025-12-22T02:18:49,438 [worker-cleanup-thread] INFO  org.apache.spark.deploy.worker.Worker [] - Cleaning up local directories for application app-20251222021837-0001
2025-12-22T02:18:49,438 [dispatcher-event-loop-0] WARN  org.apache.spark.deploy.master.Master [] - Got status update for unknown executor app-20251222021837-0001/1
2025-12-22T02:18:49,615 [shutdown-hook-0] INFO  org.apache.spark.util.ShutdownHookManager [] - Shutdown hook called
2025-12-22T02:18:49,616 [shutdown-hook-0] INFO  org.apache.spark.util.ShutdownHookManager [] - Deleting directory /tmp/spark-6a055ea7-cb95-417e-a15e-3957b41902cc/pyspark-4a3382fa-896f-4035-9a71-d766710044df
2025-12-22T02:18:49,628 [shutdown-hook-0] INFO  org.apache.spark.util.ShutdownHookManager [] - Deleting directory /tmp/spark-0495275d-c8c6-4d65-ab36-88316183fcfa
2025-12-22T02:18:49,631 [shutdown-hook-0] INFO  org.apache.spark.util.ShutdownHookManager [] - Deleting directory /tmp/spark-6a055ea7-cb95-417e-a15e-3957b41902cc
2025-12-22T02:18:49,637 [shutdown-hook-0] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl [] - Stopping s3a-file-system metrics system...
2025-12-22T02:18:49,637 [shutdown-hook-0] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl [] - s3a-file-system metrics system stopped.
2025-12-22T02:18:49,637 [shutdown-hook-0] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl [] - s3a-file-system metrics system shutdown complete.
2025-12-22T12:22:48,166 [dispatcher-event-loop-13] WARN  org.apache.spark.deploy.master.Master [] - Removing worker-20251222021118-172.20.0.6-36353 because we got no heartbeat in 60 seconds
2025-12-22T12:22:48,171 [dispatcher-event-loop-13] INFO  org.apache.spark.deploy.master.Master [] - Removing worker worker-20251222021118-172.20.0.6-36353 on 172.20.0.6:36353
2025-12-22T12:22:48,176 [dispatcher-event-loop-13] INFO  org.apache.spark.deploy.master.Master [] - Telling app of lost worker: worker-20251222021118-172.20.0.6-36353
2025-12-22T12:22:48,182 [dispatcher-event-loop-13] WARN  org.apache.spark.deploy.master.Master [] - Removing worker-20251222021118-172.20.0.5-37529 because we got no heartbeat in 60 seconds
2025-12-22T12:22:48,182 [dispatcher-event-loop-13] INFO  org.apache.spark.deploy.master.Master [] - Removing worker worker-20251222021118-172.20.0.5-37529 on 172.20.0.5:37529
2025-12-22T12:22:48,183 [dispatcher-event-loop-13] INFO  org.apache.spark.deploy.master.Master [] - Telling app of lost worker: worker-20251222021118-172.20.0.5-37529
2025-12-22T12:22:48,183 [dispatcher-event-loop-13] WARN  org.apache.spark.deploy.master.Master [] - Removing worker-20251222021118-172.20.0.4-42325 because we got no heartbeat in 60 seconds
2025-12-22T12:22:48,184 [dispatcher-event-loop-13] INFO  org.apache.spark.deploy.master.Master [] - Removing worker worker-20251222021118-172.20.0.4-42325 on 172.20.0.4:42325
2025-12-22T12:22:48,184 [dispatcher-event-loop-13] INFO  org.apache.spark.deploy.master.Master [] - Telling app of lost worker: worker-20251222021118-172.20.0.4-42325
2025-12-22T12:22:48,863 [dispatcher-event-loop-3] WARN  org.apache.spark.deploy.master.Master [] - Got heartbeat from unregistered worker worker-20251222021118-172.20.0.4-42325. Asking it to re-register.
2025-12-22T12:22:48,919 [dispatcher-event-loop-7] INFO  org.apache.spark.deploy.worker.Worker [] - Master with url spark://e78e7707373c:7077 requested this worker to reconnect.
2025-12-22T12:22:48,925 [worker-register-master-threadpool-1] INFO  org.apache.spark.deploy.worker.Worker [] - Connecting to master spark-master:7077...
2025-12-22T12:22:48,937 [dispatcher-event-loop-2] INFO  org.apache.spark.deploy.master.Master [] - Registering worker 172.20.0.4:42325 with 2 cores, 3.0 GiB RAM
2025-12-22T12:22:48,943 [dispatcher-event-loop-8] INFO  org.apache.spark.deploy.worker.Worker [] - Successfully registered with master spark://e78e7707373c:7077
2025-12-22T12:22:48,978 [dispatcher-event-loop-5] WARN  org.apache.spark.deploy.master.Master [] - Got heartbeat from unregistered worker worker-20251222021118-172.20.0.5-37529. Asking it to re-register.
2025-12-22T12:22:49,012 [dispatcher-event-loop-7] INFO  org.apache.spark.deploy.worker.Worker [] - Master with url spark://e78e7707373c:7077 requested this worker to reconnect.
2025-12-22T12:22:49,017 [worker-register-master-threadpool-1] INFO  org.apache.spark.deploy.worker.Worker [] - Connecting to master spark-master:7077...
2025-12-22T12:22:49,021 [dispatcher-event-loop-6] WARN  org.apache.spark.deploy.master.Master [] - Got heartbeat from unregistered worker worker-20251222021118-172.20.0.6-36353. Asking it to re-register.
2025-12-22T12:22:49,030 [dispatcher-event-loop-4] INFO  org.apache.spark.deploy.master.Master [] - Registering worker 172.20.0.5:37529 with 2 cores, 3.0 GiB RAM
2025-12-22T12:22:49,041 [dispatcher-event-loop-6] INFO  org.apache.spark.deploy.worker.Worker [] - Successfully registered with master spark://e78e7707373c:7077
2025-12-22T12:22:49,057 [dispatcher-event-loop-6] INFO  org.apache.spark.deploy.worker.Worker [] - Master with url spark://e78e7707373c:7077 requested this worker to reconnect.
2025-12-22T12:22:49,062 [worker-register-master-threadpool-1] INFO  org.apache.spark.deploy.worker.Worker [] - Connecting to master spark-master:7077...
2025-12-22T12:22:49,077 [dispatcher-event-loop-11] INFO  org.apache.spark.deploy.master.Master [] - Registering worker 172.20.0.6:36353 with 2 cores, 3.0 GiB RAM
2025-12-22T12:22:49,084 [dispatcher-event-loop-9] INFO  org.apache.spark.deploy.worker.Worker [] - Successfully registered with master spark://e78e7707373c:7077
2025-12-22T17:23:43,508 [dispatcher-event-loop-13] WARN  org.apache.spark.deploy.master.Master [] - Removing worker-20251222021118-172.20.0.5-37529 because we got no heartbeat in 60 seconds
2025-12-22T17:23:43,510 [dispatcher-event-loop-13] INFO  org.apache.spark.deploy.master.Master [] - Removing worker worker-20251222021118-172.20.0.5-37529 on 172.20.0.5:37529
2025-12-22T17:23:43,510 [dispatcher-event-loop-13] INFO  org.apache.spark.deploy.master.Master [] - Telling app of lost worker: worker-20251222021118-172.20.0.5-37529
2025-12-22T17:23:43,512 [dispatcher-event-loop-13] WARN  org.apache.spark.deploy.master.Master [] - Removing worker-20251222021118-172.20.0.4-42325 because we got no heartbeat in 60 seconds
2025-12-22T17:23:43,512 [dispatcher-event-loop-13] INFO  org.apache.spark.deploy.master.Master [] - Removing worker worker-20251222021118-172.20.0.4-42325 on 172.20.0.4:42325
2025-12-22T17:23:43,512 [dispatcher-event-loop-13] INFO  org.apache.spark.deploy.master.Master [] - Telling app of lost worker: worker-20251222021118-172.20.0.4-42325
2025-12-22T17:23:43,512 [dispatcher-event-loop-13] WARN  org.apache.spark.deploy.master.Master [] - Removing worker-20251222021118-172.20.0.6-36353 because we got no heartbeat in 60 seconds
2025-12-22T17:23:43,513 [dispatcher-event-loop-13] INFO  org.apache.spark.deploy.master.Master [] - Removing worker worker-20251222021118-172.20.0.6-36353 on 172.20.0.6:36353
2025-12-22T17:23:43,513 [dispatcher-event-loop-13] INFO  org.apache.spark.deploy.master.Master [] - Telling app of lost worker: worker-20251222021118-172.20.0.6-36353
2025-12-22T17:23:44,221 [dispatcher-event-loop-0] WARN  org.apache.spark.deploy.master.Master [] - Got heartbeat from unregistered worker worker-20251222021118-172.20.0.4-42325. Asking it to re-register.
2025-12-22T17:23:44,255 [dispatcher-event-loop-7] INFO  org.apache.spark.deploy.worker.Worker [] - Master with url spark://e78e7707373c:7077 requested this worker to reconnect.
2025-12-22T17:23:44,269 [worker-register-master-threadpool-2] INFO  org.apache.spark.deploy.worker.Worker [] - Connecting to master spark-master:7077...
2025-12-22T17:23:44,286 [dispatcher-event-loop-2] INFO  org.apache.spark.deploy.master.Master [] - Registering worker 172.20.0.4:42325 with 2 cores, 3.0 GiB RAM
2025-12-22T17:23:44,293 [dispatcher-event-loop-9] INFO  org.apache.spark.deploy.worker.Worker [] - Successfully registered with master spark://e78e7707373c:7077
2025-12-22T17:23:44,336 [dispatcher-event-loop-5] WARN  org.apache.spark.deploy.master.Master [] - Got heartbeat from unregistered worker worker-20251222021118-172.20.0.5-37529. Asking it to re-register.
2025-12-22T17:23:44,367 [dispatcher-event-loop-7] INFO  org.apache.spark.deploy.worker.Worker [] - Master with url spark://e78e7707373c:7077 requested this worker to reconnect.
2025-12-22T17:23:44,379 [dispatcher-event-loop-9] WARN  org.apache.spark.deploy.master.Master [] - Got heartbeat from unregistered worker worker-20251222021118-172.20.0.6-36353. Asking it to re-register.
2025-12-22T17:23:44,383 [worker-register-master-threadpool-2] INFO  org.apache.spark.deploy.worker.Worker [] - Connecting to master spark-master:7077...
2025-12-22T17:23:44,396 [dispatcher-event-loop-7] INFO  org.apache.spark.deploy.master.Master [] - Registering worker 172.20.0.5:37529 with 2 cores, 3.0 GiB RAM
2025-12-22T17:23:44,402 [dispatcher-event-loop-8] INFO  org.apache.spark.deploy.worker.Worker [] - Successfully registered with master spark://e78e7707373c:7077
2025-12-22T17:23:44,419 [dispatcher-event-loop-6] INFO  org.apache.spark.deploy.worker.Worker [] - Master with url spark://e78e7707373c:7077 requested this worker to reconnect.
2025-12-22T17:23:44,433 [worker-register-master-threadpool-2] INFO  org.apache.spark.deploy.worker.Worker [] - Connecting to master spark-master:7077...
2025-12-22T17:23:44,446 [dispatcher-event-loop-0] INFO  org.apache.spark.deploy.master.Master [] - Registering worker 172.20.0.6:36353 with 2 cores, 3.0 GiB RAM
2025-12-22T17:23:44,454 [dispatcher-event-loop-9] INFO  org.apache.spark.deploy.worker.Worker [] - Successfully registered with master spark://e78e7707373c:7077
2025-12-22T18:44:02,924 [dispatcher-event-loop-4] WARN  org.apache.spark.deploy.master.Master [] - Removing worker-20251222021118-172.20.0.4-42325 because we got no heartbeat in 60 seconds
2025-12-22T18:44:02,925 [dispatcher-event-loop-4] INFO  org.apache.spark.deploy.master.Master [] - Removing worker worker-20251222021118-172.20.0.4-42325 on 172.20.0.4:42325
2025-12-22T18:44:02,925 [dispatcher-event-loop-4] INFO  org.apache.spark.deploy.master.Master [] - Telling app of lost worker: worker-20251222021118-172.20.0.4-42325
2025-12-22T18:44:02,926 [dispatcher-event-loop-4] WARN  org.apache.spark.deploy.master.Master [] - Removing worker-20251222021118-172.20.0.6-36353 because we got no heartbeat in 60 seconds
2025-12-22T18:44:02,926 [dispatcher-event-loop-4] INFO  org.apache.spark.deploy.master.Master [] - Removing worker worker-20251222021118-172.20.0.6-36353 on 172.20.0.6:36353
2025-12-22T18:44:02,926 [dispatcher-event-loop-4] INFO  org.apache.spark.deploy.master.Master [] - Telling app of lost worker: worker-20251222021118-172.20.0.6-36353
2025-12-22T18:44:02,926 [dispatcher-event-loop-4] WARN  org.apache.spark.deploy.master.Master [] - Removing worker-20251222021118-172.20.0.5-37529 because we got no heartbeat in 60 seconds
2025-12-22T18:44:02,927 [dispatcher-event-loop-4] INFO  org.apache.spark.deploy.master.Master [] - Removing worker worker-20251222021118-172.20.0.5-37529 on 172.20.0.5:37529
2025-12-22T18:44:02,927 [dispatcher-event-loop-4] INFO  org.apache.spark.deploy.master.Master [] - Telling app of lost worker: worker-20251222021118-172.20.0.5-37529
2025-12-22T18:44:03,638 [dispatcher-event-loop-12] WARN  org.apache.spark.deploy.master.Master [] - Got heartbeat from unregistered worker worker-20251222021118-172.20.0.4-42325. Asking it to re-register.
2025-12-22T18:44:03,644 [dispatcher-event-loop-7] INFO  org.apache.spark.deploy.worker.Worker [] - Master with url spark://e78e7707373c:7077 requested this worker to reconnect.
2025-12-22T18:44:03,654 [worker-register-master-threadpool-3] INFO  org.apache.spark.deploy.worker.Worker [] - Connecting to master spark-master:7077...
2025-12-22T18:44:03,659 [dispatcher-event-loop-5] INFO  org.apache.spark.deploy.master.Master [] - Registering worker 172.20.0.4:42325 with 2 cores, 3.0 GiB RAM
2025-12-22T18:44:03,662 [dispatcher-event-loop-8] INFO  org.apache.spark.deploy.worker.Worker [] - Successfully registered with master spark://e78e7707373c:7077
2025-12-22T18:44:03,752 [dispatcher-event-loop-3] WARN  org.apache.spark.deploy.master.Master [] - Got heartbeat from unregistered worker worker-20251222021118-172.20.0.5-37529. Asking it to re-register.
2025-12-22T18:44:03,758 [dispatcher-event-loop-7] INFO  org.apache.spark.deploy.worker.Worker [] - Master with url spark://e78e7707373c:7077 requested this worker to reconnect.
2025-12-22T18:44:03,760 [worker-register-master-threadpool-3] INFO  org.apache.spark.deploy.worker.Worker [] - Connecting to master spark-master:7077...
2025-12-22T18:44:03,765 [dispatcher-event-loop-13] INFO  org.apache.spark.deploy.master.Master [] - Registering worker 172.20.0.5:37529 with 2 cores, 3.0 GiB RAM
2025-12-22T18:44:03,768 [dispatcher-event-loop-6] INFO  org.apache.spark.deploy.worker.Worker [] - Successfully registered with master spark://e78e7707373c:7077
2025-12-22T18:44:03,796 [dispatcher-event-loop-2] WARN  org.apache.spark.deploy.master.Master [] - Got heartbeat from unregistered worker worker-20251222021118-172.20.0.6-36353. Asking it to re-register.
2025-12-22T18:44:03,801 [dispatcher-event-loop-6] INFO  org.apache.spark.deploy.worker.Worker [] - Master with url spark://e78e7707373c:7077 requested this worker to reconnect.
2025-12-22T18:44:03,803 [worker-register-master-threadpool-3] INFO  org.apache.spark.deploy.worker.Worker [] - Connecting to master spark-master:7077...
2025-12-22T18:44:03,807 [dispatcher-event-loop-12] INFO  org.apache.spark.deploy.master.Master [] - Registering worker 172.20.0.6:36353 with 2 cores, 3.0 GiB RAM
2025-12-22T18:44:03,811 [dispatcher-event-loop-8] INFO  org.apache.spark.deploy.worker.Worker [] - Successfully registered with master spark://e78e7707373c:7077
2025-12-22T21:44:35,739 [dispatcher-event-loop-5] WARN  org.apache.spark.deploy.master.Master [] - Removing worker-20251222021118-172.20.0.4-42325 because we got no heartbeat in 60 seconds
2025-12-22T21:44:35,745 [dispatcher-event-loop-5] INFO  org.apache.spark.deploy.master.Master [] - Removing worker worker-20251222021118-172.20.0.4-42325 on 172.20.0.4:42325
2025-12-22T21:44:35,746 [dispatcher-event-loop-5] INFO  org.apache.spark.deploy.master.Master [] - Telling app of lost worker: worker-20251222021118-172.20.0.4-42325
2025-12-22T21:44:35,750 [dispatcher-event-loop-5] WARN  org.apache.spark.deploy.master.Master [] - Removing worker-20251222021118-172.20.0.6-36353 because we got no heartbeat in 60 seconds
2025-12-22T21:44:35,751 [dispatcher-event-loop-5] INFO  org.apache.spark.deploy.master.Master [] - Removing worker worker-20251222021118-172.20.0.6-36353 on 172.20.0.6:36353
2025-12-22T21:44:35,751 [dispatcher-event-loop-5] INFO  org.apache.spark.deploy.master.Master [] - Telling app of lost worker: worker-20251222021118-172.20.0.6-36353
2025-12-22T21:44:35,752 [dispatcher-event-loop-5] WARN  org.apache.spark.deploy.master.Master [] - Removing worker-20251222021118-172.20.0.5-37529 because we got no heartbeat in 60 seconds
2025-12-22T21:44:35,752 [dispatcher-event-loop-5] INFO  org.apache.spark.deploy.master.Master [] - Removing worker worker-20251222021118-172.20.0.5-37529 on 172.20.0.5:37529
2025-12-22T21:44:35,752 [dispatcher-event-loop-5] INFO  org.apache.spark.deploy.master.Master [] - Telling app of lost worker: worker-20251222021118-172.20.0.5-37529
2025-12-22T21:44:36,442 [dispatcher-event-loop-1] WARN  org.apache.spark.deploy.master.Master [] - Got heartbeat from unregistered worker worker-20251222021118-172.20.0.4-42325. Asking it to re-register.
2025-12-22T21:44:36,477 [dispatcher-event-loop-1] WARN  org.apache.spark.deploy.master.Master [] - Got heartbeat from unregistered worker worker-20251222021118-172.20.0.4-42325. Asking it to re-register.
2025-12-22T21:44:36,517 [dispatcher-event-loop-13] INFO  org.apache.spark.deploy.worker.Worker [] - Master with url spark://e78e7707373c:7077 requested this worker to reconnect.
2025-12-22T21:44:36,534 [dispatcher-event-loop-13] INFO  org.apache.spark.deploy.worker.Worker [] - Master with url spark://e78e7707373c:7077 requested this worker to reconnect.
2025-12-22T21:44:36,536 [dispatcher-event-loop-6] WARN  org.apache.spark.deploy.master.Master [] - Got heartbeat from unregistered worker worker-20251222021118-172.20.0.4-42325. Asking it to re-register.
2025-12-22T21:44:36,535 [worker-register-master-threadpool-4] INFO  org.apache.spark.deploy.worker.Worker [] - Connecting to master spark-master:7077...
2025-12-22T21:44:36,557 [dispatcher-event-loop-8] WARN  org.apache.spark.deploy.master.Master [] - Got heartbeat from unregistered worker worker-20251222021118-172.20.0.5-37529. Asking it to re-register.
2025-12-22T21:44:36,569 [dispatcher-event-loop-3] INFO  org.apache.spark.deploy.master.Master [] - Registering worker 172.20.0.4:42325 with 2 cores, 3.0 GiB RAM
2025-12-22T21:44:36,590 [dispatcher-event-loop-10] WARN  org.apache.spark.deploy.master.Master [] - Got heartbeat from unregistered worker worker-20251222021118-172.20.0.5-37529. Asking it to re-register.
2025-12-22T21:44:36,592 [dispatcher-event-loop-0] INFO  org.apache.spark.deploy.worker.Worker [] - Master with url spark://e78e7707373c:7077 requested this worker to reconnect.
2025-12-22T21:44:36,603 [dispatcher-event-loop-13] WARN  org.apache.spark.deploy.master.Master [] - Got heartbeat from unregistered worker worker-20251222021118-172.20.0.6-36353. Asking it to re-register.
2025-12-22T21:44:36,607 [dispatcher-event-loop-0] INFO  org.apache.spark.deploy.worker.Worker [] - Master with url spark://e78e7707373c:7077 requested this worker to reconnect.
2025-12-22T21:44:36,610 [dispatcher-event-loop-13] INFO  org.apache.spark.deploy.worker.Worker [] - Not spawning another attempt to register with the master, since there is an attempt scheduled already.
2025-12-22T21:44:36,610 [dispatcher-event-loop-13] INFO  org.apache.spark.deploy.worker.Worker [] - Master with url spark://e78e7707373c:7077 requested this worker to reconnect.
2025-12-22T21:44:36,610 [dispatcher-event-loop-13] INFO  org.apache.spark.deploy.worker.Worker [] - Not spawning another attempt to register with the master, since there is an attempt scheduled already.
2025-12-22T21:44:36,611 [dispatcher-event-loop-13] INFO  org.apache.spark.deploy.worker.Worker [] - Successfully registered with master spark://e78e7707373c:7077
2025-12-22T21:44:36,610 [worker-register-master-threadpool-4] INFO  org.apache.spark.deploy.worker.Worker [] - Connecting to master spark-master:7077...
2025-12-22T21:44:36,636 [dispatcher-event-loop-2] WARN  org.apache.spark.deploy.master.Master [] - Got heartbeat from unregistered worker worker-20251222021118-172.20.0.6-36353. Asking it to re-register.
2025-12-22T21:44:36,641 [dispatcher-event-loop-5] INFO  org.apache.spark.deploy.master.Master [] - Registering worker 172.20.0.5:37529 with 2 cores, 3.0 GiB RAM
2025-12-22T21:44:36,637 [dispatcher-event-loop-13] INFO  org.apache.spark.deploy.worker.Worker [] - Master with url spark://e78e7707373c:7077 requested this worker to reconnect.
2025-12-22T21:44:36,650 [dispatcher-event-loop-13] INFO  org.apache.spark.deploy.worker.Worker [] - Master with url spark://e78e7707373c:7077 requested this worker to reconnect.
2025-12-22T21:44:36,651 [worker-register-master-threadpool-4] INFO  org.apache.spark.deploy.worker.Worker [] - Connecting to master spark-master:7077...
2025-12-22T21:44:36,668 [dispatcher-event-loop-1] INFO  org.apache.spark.deploy.master.Master [] - Registering worker 172.20.0.6:36353 with 2 cores, 3.0 GiB RAM
2025-12-22T21:44:36,684 [dispatcher-event-loop-0] INFO  org.apache.spark.deploy.worker.Worker [] - Not spawning another attempt to register with the master, since there is an attempt scheduled already.
2025-12-22T21:44:36,685 [dispatcher-event-loop-0] INFO  org.apache.spark.deploy.worker.Worker [] - Successfully registered with master spark://e78e7707373c:7077
2025-12-22T21:44:36,692 [dispatcher-event-loop-13] INFO  org.apache.spark.deploy.worker.Worker [] - Not spawning another attempt to register with the master, since there is an attempt scheduled already.
2025-12-22T21:44:36,693 [dispatcher-event-loop-13] INFO  org.apache.spark.deploy.worker.Worker [] - Successfully registered with master spark://e78e7707373c:7077
2025-12-23T11:17:04,461 [dispatcher-event-loop-1] WARN  org.apache.spark.deploy.master.Master [] - Removing worker-20251222021118-172.20.0.4-42325 because we got no heartbeat in 60 seconds
2025-12-23T11:17:04,467 [dispatcher-event-loop-1] INFO  org.apache.spark.deploy.master.Master [] - Removing worker worker-20251222021118-172.20.0.4-42325 on 172.20.0.4:42325
2025-12-23T11:17:04,467 [dispatcher-event-loop-1] INFO  org.apache.spark.deploy.master.Master [] - Telling app of lost worker: worker-20251222021118-172.20.0.4-42325
2025-12-23T11:17:04,468 [dispatcher-event-loop-1] WARN  org.apache.spark.deploy.master.Master [] - Removing worker-20251222021118-172.20.0.6-36353 because we got no heartbeat in 60 seconds
2025-12-23T11:17:04,469 [dispatcher-event-loop-1] INFO  org.apache.spark.deploy.master.Master [] - Removing worker worker-20251222021118-172.20.0.6-36353 on 172.20.0.6:36353
2025-12-23T11:17:04,469 [dispatcher-event-loop-1] INFO  org.apache.spark.deploy.master.Master [] - Telling app of lost worker: worker-20251222021118-172.20.0.6-36353
2025-12-23T11:17:04,469 [dispatcher-event-loop-1] WARN  org.apache.spark.deploy.master.Master [] - Removing worker-20251222021118-172.20.0.5-37529 because we got no heartbeat in 60 seconds
2025-12-23T11:17:04,469 [dispatcher-event-loop-1] INFO  org.apache.spark.deploy.master.Master [] - Removing worker worker-20251222021118-172.20.0.5-37529 on 172.20.0.5:37529
2025-12-23T11:17:04,469 [dispatcher-event-loop-1] INFO  org.apache.spark.deploy.master.Master [] - Telling app of lost worker: worker-20251222021118-172.20.0.5-37529
2025-12-23T11:17:05,173 [dispatcher-event-loop-6] WARN  org.apache.spark.deploy.master.Master [] - Got heartbeat from unregistered worker worker-20251222021118-172.20.0.4-42325. Asking it to re-register.
2025-12-23T11:17:05,179 [dispatcher-event-loop-3] INFO  org.apache.spark.deploy.worker.Worker [] - Master with url spark://e78e7707373c:7077 requested this worker to reconnect.
2025-12-23T11:17:05,187 [worker-register-master-threadpool-5] INFO  org.apache.spark.deploy.worker.Worker [] - Connecting to master spark-master:7077...
2025-12-23T11:17:05,196 [dispatcher-event-loop-8] INFO  org.apache.spark.deploy.master.Master [] - Registering worker 172.20.0.4:42325 with 2 cores, 3.0 GiB RAM
2025-12-23T11:17:05,200 [dispatcher-event-loop-6] INFO  org.apache.spark.deploy.worker.Worker [] - Successfully registered with master spark://e78e7707373c:7077
2025-12-23T11:17:05,289 [dispatcher-event-loop-4] WARN  org.apache.spark.deploy.master.Master [] - Got heartbeat from unregistered worker worker-20251222021118-172.20.0.5-37529. Asking it to re-register.
2025-12-23T11:17:05,295 [dispatcher-event-loop-1] INFO  org.apache.spark.deploy.worker.Worker [] - Master with url spark://e78e7707373c:7077 requested this worker to reconnect.
2025-12-23T11:17:05,304 [worker-register-master-threadpool-5] INFO  org.apache.spark.deploy.worker.Worker [] - Connecting to master spark-master:7077...
2025-12-23T11:17:05,306 [dispatcher-event-loop-2] WARN  org.apache.spark.deploy.master.Master [] - Got heartbeat from unregistered worker worker-20251222021118-172.20.0.5-37529. Asking it to re-register.
2025-12-23T11:17:05,309 [dispatcher-event-loop-4] INFO  org.apache.spark.deploy.worker.Worker [] - Master with url spark://e78e7707373c:7077 requested this worker to reconnect.
2025-12-23T11:17:05,310 [dispatcher-event-loop-4] INFO  org.apache.spark.deploy.worker.Worker [] - Not spawning another attempt to register with the master, since there is an attempt scheduled already.
2025-12-23T11:17:05,311 [dispatcher-event-loop-5] INFO  org.apache.spark.deploy.master.Master [] - Registering worker 172.20.0.5:37529 with 2 cores, 3.0 GiB RAM
2025-12-23T11:17:05,314 [dispatcher-event-loop-5] INFO  org.apache.spark.deploy.worker.Worker [] - Successfully registered with master spark://e78e7707373c:7077
2025-12-23T11:17:05,332 [dispatcher-event-loop-6] WARN  org.apache.spark.deploy.master.Master [] - Got heartbeat from unregistered worker worker-20251222021118-172.20.0.6-36353. Asking it to re-register.
2025-12-23T11:17:05,337 [dispatcher-event-loop-1] INFO  org.apache.spark.deploy.worker.Worker [] - Master with url spark://e78e7707373c:7077 requested this worker to reconnect.
2025-12-23T11:17:05,347 [worker-register-master-threadpool-5] INFO  org.apache.spark.deploy.worker.Worker [] - Connecting to master spark-master:7077...
2025-12-23T11:17:05,348 [dispatcher-event-loop-8] WARN  org.apache.spark.deploy.master.Master [] - Got heartbeat from unregistered worker worker-20251222021118-172.20.0.6-36353. Asking it to re-register.
2025-12-23T11:17:05,350 [dispatcher-event-loop-4] INFO  org.apache.spark.deploy.worker.Worker [] - Master with url spark://e78e7707373c:7077 requested this worker to reconnect.
2025-12-23T11:17:05,350 [dispatcher-event-loop-4] INFO  org.apache.spark.deploy.worker.Worker [] - Not spawning another attempt to register with the master, since there is an attempt scheduled already.
2025-12-23T11:17:05,352 [dispatcher-event-loop-13] INFO  org.apache.spark.deploy.master.Master [] - Registering worker 172.20.0.6:36353 with 2 cores, 3.0 GiB RAM
2025-12-23T11:17:05,356 [dispatcher-event-loop-13] INFO  org.apache.spark.deploy.worker.Worker [] - Successfully registered with master spark://e78e7707373c:7077
2025-12-23T17:19:30,706 [dispatcher-event-loop-9] WARN  org.apache.spark.deploy.master.Master [] - Removing worker-20251222021118-172.20.0.6-36353 because we got no heartbeat in 60 seconds
2025-12-23T17:19:30,714 [dispatcher-event-loop-9] INFO  org.apache.spark.deploy.master.Master [] - Removing worker worker-20251222021118-172.20.0.6-36353 on 172.20.0.6:36353
2025-12-23T17:19:30,716 [dispatcher-event-loop-9] INFO  org.apache.spark.deploy.master.Master [] - Telling app of lost worker: worker-20251222021118-172.20.0.6-36353
2025-12-23T17:19:30,723 [dispatcher-event-loop-9] WARN  org.apache.spark.deploy.master.Master [] - Removing worker-20251222021118-172.20.0.5-37529 because we got no heartbeat in 60 seconds
2025-12-23T17:19:30,724 [dispatcher-event-loop-9] INFO  org.apache.spark.deploy.master.Master [] - Removing worker worker-20251222021118-172.20.0.5-37529 on 172.20.0.5:37529
2025-12-23T17:19:30,727 [dispatcher-event-loop-9] INFO  org.apache.spark.deploy.master.Master [] - Telling app of lost worker: worker-20251222021118-172.20.0.5-37529
2025-12-23T17:19:30,728 [dispatcher-event-loop-9] WARN  org.apache.spark.deploy.master.Master [] - Removing worker-20251222021118-172.20.0.4-42325 because we got no heartbeat in 60 seconds
2025-12-23T17:19:30,729 [dispatcher-event-loop-9] INFO  org.apache.spark.deploy.master.Master [] - Removing worker worker-20251222021118-172.20.0.4-42325 on 172.20.0.4:42325
2025-12-23T17:19:30,729 [dispatcher-event-loop-9] INFO  org.apache.spark.deploy.master.Master [] - Telling app of lost worker: worker-20251222021118-172.20.0.4-42325
2025-12-23T17:20:24,925 [dispatcher-event-loop-3] WARN  org.apache.spark.deploy.master.Master [] - Got heartbeat from unregistered worker worker-20251222021118-172.20.0.4-42325. Asking it to re-register.
2025-12-23T17:20:24,971 [dispatcher-event-loop-3] WARN  org.apache.spark.deploy.master.Master [] - Got heartbeat from unregistered worker worker-20251222021118-172.20.0.4-42325. Asking it to re-register.
2025-12-23T17:20:24,972 [dispatcher-event-loop-3] WARN  org.apache.spark.deploy.master.Master [] - Got heartbeat from unregistered worker worker-20251222021118-172.20.0.4-42325. Asking it to re-register.
2025-12-23T17:20:24,973 [dispatcher-event-loop-3] WARN  org.apache.spark.deploy.master.Master [] - Got heartbeat from unregistered worker worker-20251222021118-172.20.0.4-42325. Asking it to re-register.
2025-12-23T17:20:24,986 [dispatcher-event-loop-13] WARN  org.apache.spark.deploy.master.Master [] - Got heartbeat from unregistered worker worker-20251222021118-172.20.0.4-42325. Asking it to re-register.
2025-12-23T17:20:25,002 [dispatcher-event-loop-0] WARN  org.apache.spark.deploy.master.Master [] - Got heartbeat from unregistered worker worker-20251222021118-172.20.0.5-37529. Asking it to re-register.
2025-12-23T17:20:25,025 [dispatcher-event-loop-8] INFO  org.apache.spark.deploy.worker.Worker [] - Master with url spark://e78e7707373c:7077 requested this worker to reconnect.
2025-12-23T17:20:25,043 [dispatcher-event-loop-10] WARN  org.apache.spark.deploy.master.Master [] - Got heartbeat from unregistered worker worker-20251222021118-172.20.0.5-37529. Asking it to re-register.
2025-12-23T17:20:25,044 [dispatcher-event-loop-10] WARN  org.apache.spark.deploy.master.Master [] - Got heartbeat from unregistered worker worker-20251222021118-172.20.0.5-37529. Asking it to re-register.
2025-12-23T17:20:25,043 [dispatcher-event-loop-0] INFO  org.apache.spark.deploy.worker.Worker [] - Master with url spark://e78e7707373c:7077 requested this worker to reconnect.
2025-12-23T17:20:25,052 [dispatcher-event-loop-11] WARN  org.apache.spark.deploy.master.Master [] - Got heartbeat from unregistered worker worker-20251222021118-172.20.0.6-36353. Asking it to re-register.
2025-12-23T17:20:25,070 [worker-register-master-threadpool-6] INFO  org.apache.spark.deploy.worker.Worker [] - Connecting to master spark-master:7077...
2025-12-23T17:20:25,081 [dispatcher-event-loop-12] WARN  org.apache.spark.deploy.master.Master [] - Got heartbeat from unregistered worker worker-20251222021118-172.20.0.5-37529. Asking it to re-register.
2025-12-23T17:20:25,082 [dispatcher-event-loop-12] WARN  org.apache.spark.deploy.master.Master [] - Got heartbeat from unregistered worker worker-20251222021118-172.20.0.5-37529. Asking it to re-register.
2025-12-23T17:20:25,084 [worker-register-master-threadpool-6] INFO  org.apache.spark.deploy.worker.Worker [] - Connecting to master spark-master:7077...
2025-12-23T17:20:25,085 [dispatcher-event-loop-9] INFO  org.apache.spark.deploy.worker.Worker [] - Master with url spark://e78e7707373c:7077 requested this worker to reconnect.
2025-12-23T17:20:25,086 [dispatcher-event-loop-9] INFO  org.apache.spark.deploy.worker.Worker [] - Not spawning another attempt to register with the master, since there is an attempt scheduled already.
2025-12-23T17:20:25,086 [dispatcher-event-loop-9] INFO  org.apache.spark.deploy.worker.Worker [] - Master with url spark://e78e7707373c:7077 requested this worker to reconnect.
2025-12-23T17:20:25,086 [dispatcher-event-loop-9] INFO  org.apache.spark.deploy.worker.Worker [] - Not spawning another attempt to register with the master, since there is an attempt scheduled already.
2025-12-23T17:20:25,090 [dispatcher-event-loop-6] INFO  org.apache.spark.deploy.worker.Worker [] - Master with url spark://e78e7707373c:7077 requested this worker to reconnect.
2025-12-23T17:20:25,090 [dispatcher-event-loop-6] INFO  org.apache.spark.deploy.worker.Worker [] - Not spawning another attempt to register with the master, since there is an attempt scheduled already.
2025-12-23T17:20:25,096 [dispatcher-event-loop-13] INFO  org.apache.spark.deploy.worker.Worker [] - Master with url spark://e78e7707373c:7077 requested this worker to reconnect.
2025-12-23T17:20:25,097 [dispatcher-event-loop-13] INFO  org.apache.spark.deploy.worker.Worker [] - Not spawning another attempt to register with the master, since there is an attempt scheduled already.
2025-12-23T17:20:25,093 [dispatcher-event-loop-8] INFO  org.apache.spark.deploy.worker.Worker [] - Master with url spark://e78e7707373c:7077 requested this worker to reconnect.
2025-12-23T17:20:25,100 [dispatcher-event-loop-8] INFO  org.apache.spark.deploy.worker.Worker [] - Not spawning another attempt to register with the master, since there is an attempt scheduled already.
2025-12-23T17:20:25,101 [dispatcher-event-loop-8] INFO  org.apache.spark.deploy.worker.Worker [] - Master with url spark://e78e7707373c:7077 requested this worker to reconnect.
2025-12-23T17:20:25,101 [dispatcher-event-loop-8] INFO  org.apache.spark.deploy.worker.Worker [] - Not spawning another attempt to register with the master, since there is an attempt scheduled already.
2025-12-23T17:20:25,105 [dispatcher-event-loop-8] INFO  org.apache.spark.deploy.worker.Worker [] - Master with url spark://e78e7707373c:7077 requested this worker to reconnect.
2025-12-23T17:20:25,105 [dispatcher-event-loop-8] INFO  org.apache.spark.deploy.worker.Worker [] - Not spawning another attempt to register with the master, since there is an attempt scheduled already.
2025-12-23T17:20:25,108 [dispatcher-event-loop-8] INFO  org.apache.spark.deploy.worker.Worker [] - Master with url spark://e78e7707373c:7077 requested this worker to reconnect.
2025-12-23T17:20:25,109 [dispatcher-event-loop-8] INFO  org.apache.spark.deploy.worker.Worker [] - Not spawning another attempt to register with the master, since there is an attempt scheduled already.
2025-12-23T17:20:25,134 [dispatcher-event-loop-9] INFO  org.apache.spark.deploy.master.Master [] - Registering worker 172.20.0.4:42325 with 2 cores, 3.0 GiB RAM
2025-12-23T17:20:25,139 [dispatcher-event-loop-9] INFO  org.apache.spark.deploy.master.Master [] - Registering worker 172.20.0.5:37529 with 2 cores, 3.0 GiB RAM
2025-12-23T17:20:25,148 [dispatcher-event-loop-0] INFO  org.apache.spark.deploy.worker.Worker [] - Successfully registered with master spark://e78e7707373c:7077
2025-12-23T17:20:25,155 [dispatcher-event-loop-3] WARN  org.apache.spark.deploy.master.Master [] - Got heartbeat from unregistered worker worker-20251222021118-172.20.0.6-36353. Asking it to re-register.
2025-12-23T17:20:25,156 [dispatcher-event-loop-3] WARN  org.apache.spark.deploy.master.Master [] - Got heartbeat from unregistered worker worker-20251222021118-172.20.0.6-36353. Asking it to re-register.
2025-12-23T17:20:25,157 [dispatcher-event-loop-3] WARN  org.apache.spark.deploy.master.Master [] - Got heartbeat from unregistered worker worker-20251222021118-172.20.0.6-36353. Asking it to re-register.
2025-12-23T17:20:25,166 [dispatcher-event-loop-3] WARN  org.apache.spark.deploy.master.Master [] - Got heartbeat from unregistered worker worker-20251222021118-172.20.0.6-36353. Asking it to re-register.
2025-12-23T17:20:25,171 [dispatcher-event-loop-3] WARN  org.apache.spark.deploy.master.Master [] - Got heartbeat from unregistered worker worker-20251222021118-172.20.0.6-36353. Asking it to re-register.
2025-12-23T17:20:25,165 [dispatcher-event-loop-7] INFO  org.apache.spark.deploy.worker.Worker [] - Master with url spark://e78e7707373c:7077 requested this worker to reconnect.
2025-12-23T17:20:25,209 [worker-register-master-threadpool-6] INFO  org.apache.spark.deploy.worker.Worker [] - Connecting to master spark-master:7077...
2025-12-23T17:20:25,212 [dispatcher-event-loop-7] INFO  org.apache.spark.deploy.worker.Worker [] - Master with url spark://e78e7707373c:7077 requested this worker to reconnect.
2025-12-23T17:20:25,212 [dispatcher-event-loop-7] INFO  org.apache.spark.deploy.worker.Worker [] - Not spawning another attempt to register with the master, since there is an attempt scheduled already.
2025-12-23T17:20:25,217 [dispatcher-event-loop-12] INFO  org.apache.spark.deploy.worker.Worker [] - Master with url spark://e78e7707373c:7077 requested this worker to reconnect.
2025-12-23T17:20:25,221 [dispatcher-event-loop-12] INFO  org.apache.spark.deploy.worker.Worker [] - Not spawning another attempt to register with the master, since there is an attempt scheduled already.
2025-12-23T17:20:25,221 [dispatcher-event-loop-12] INFO  org.apache.spark.deploy.worker.Worker [] - Master with url spark://e78e7707373c:7077 requested this worker to reconnect.
2025-12-23T17:20:25,221 [dispatcher-event-loop-12] INFO  org.apache.spark.deploy.worker.Worker [] - Not spawning another attempt to register with the master, since there is an attempt scheduled already.
2025-12-23T17:20:25,221 [dispatcher-event-loop-12] INFO  org.apache.spark.deploy.worker.Worker [] - Master with url spark://e78e7707373c:7077 requested this worker to reconnect.
2025-12-23T17:20:25,222 [dispatcher-event-loop-12] INFO  org.apache.spark.deploy.worker.Worker [] - Not spawning another attempt to register with the master, since there is an attempt scheduled already.
2025-12-23T17:20:25,226 [dispatcher-event-loop-11] INFO  org.apache.spark.deploy.worker.Worker [] - Master with url spark://e78e7707373c:7077 requested this worker to reconnect.
2025-12-23T17:20:25,227 [dispatcher-event-loop-11] INFO  org.apache.spark.deploy.worker.Worker [] - Not spawning another attempt to register with the master, since there is an attempt scheduled already.
2025-12-23T17:20:25,152 [dispatcher-event-loop-11] INFO  org.apache.spark.deploy.worker.Worker [] - Successfully registered with master spark://e78e7707373c:7077
2025-12-23T17:20:25,237 [dispatcher-event-loop-1] INFO  org.apache.spark.deploy.master.Master [] - Registering worker 172.20.0.6:36353 with 2 cores, 3.0 GiB RAM
2025-12-23T17:20:25,251 [dispatcher-event-loop-0] INFO  org.apache.spark.deploy.worker.Worker [] - Successfully registered with master spark://e78e7707373c:7077
